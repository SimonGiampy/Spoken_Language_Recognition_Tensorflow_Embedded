{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import wav audio samples into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create base dataset csv file with columns:\n",
    "language, speaker, audio_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "(53, 960000)\n",
      "['alessandro' 'donia' 'elena' 'francesco' 'gabriele' 'lorenzo' 'omar'\n",
      " 'thiago']\n",
      "['ara' 'eng' 'esp' 'ita' 'por']\n",
      "  language     speaker                                     audio_raw_data\n",
      "0      ita  alessandro  [21, -4, -25, -74, -23, -43, -177, -195, -236,...\n",
      "1      por      thiago  [-561, -550, -536, -539, -545, -573, -573, -58...\n",
      "2      ita       elena  [43, 41, 39, 39, 39, 38, 39, 31, 34, 38, 34, 3...\n",
      "3      eng     lorenzo  [-653, -649, -667, -681, -701, -673, -694, -70...\n",
      "4      esp       elena  [-415, -409, -412, -411, -407, -413, -421, -43...\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sample_length = 60 * 16000 # 16kHz sampling of 60 seconds of audio\n",
    "\n",
    "# print size of list of audio files\n",
    "folder = os.getcwd() + \"/../rec/\"\n",
    "audio_files_list = os.listdir(folder)\n",
    "print(len(audio_files_list))\n",
    "\n",
    "# memorize audio recordings and thei associated language and speaker\n",
    "audio_recs = np.zeros( (len(audio_files_list), sample_length), dtype=\"int16\")\n",
    "languages = []\n",
    "speakers = []\n",
    "print(audio_recs.shape)\n",
    "\n",
    "# create starting point: dataset with all the audio recordings\n",
    "for i, audio in enumerate(audio_files_list):\n",
    "    sample_rate, audio_rec = wavfile.read(folder + audio)\n",
    "    audio_recs[i] = audio_rec\n",
    "    languages.append(audio[4:7])\n",
    "    speakers.append(audio[8 : len(audio) - 7])\n",
    "\n",
    "# print unique speakers and languages\n",
    "print(np.unique(speakers))\n",
    "print(np.unique(languages))\n",
    "\n",
    "\n",
    "# Create a dictionary with the structured data\n",
    "data_dictionary = {\n",
    "    'language': languages,\n",
    "    'speaker': speakers,\n",
    "    'audio_raw_data': audio_recs.tolist()\n",
    "}\n",
    "\n",
    "'''\n",
    "# Specify the data types for each column\n",
    "data_types = {\n",
    "    'audio_raw_data': 'object',\n",
    "    'language': 'str'\n",
    "}\n",
    "'''\n",
    "dataset = pd.DataFrame(data_dictionary)\n",
    "# Save the DataFrame to a CSV file\n",
    "#df.to_csv('dataset0.csv', index=False)\n",
    "\n",
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio splits =  (1590, 89600)\n",
      "file n:  0  with length  960000\n",
      "file n:  1  with length  960000\n",
      "file n:  2  with length  960000\n",
      "file n:  3  with length  960000\n",
      "file n:  4  with length  960000\n",
      "file n:  5  with length  960000\n",
      "file n:  6  with length  960000\n",
      "file n:  7  with length  960000\n",
      "file n:  8  with length  960000\n",
      "file n:  9  with length  960000\n",
      "file n:  10  with length  960000\n",
      "file n:  11  with length  960000\n",
      "file n:  12  with length  960000\n",
      "file n:  13  with length  960000\n",
      "file n:  14  with length  960000\n",
      "file n:  15  with length  960000\n",
      "file n:  16  with length  960000\n",
      "file n:  17  with length  960000\n",
      "file n:  18  with length  960000\n",
      "file n:  19  with length  960000\n",
      "file n:  20  with length  960000\n",
      "file n:  21  with length  960000\n",
      "file n:  22  with length  960000\n",
      "file n:  23  with length  960000\n",
      "file n:  24  with length  960000\n",
      "file n:  25  with length  960000\n",
      "file n:  26  with length  960000\n",
      "file n:  27  with length  960000\n",
      "file n:  28  with length  960000\n",
      "file n:  29  with length  960000\n",
      "file n:  30  with length  960000\n",
      "file n:  31  with length  960000\n",
      "file n:  32  with length  960000\n",
      "file n:  33  with length  960000\n",
      "file n:  34  with length  960000\n",
      "file n:  35  with length  960000\n",
      "file n:  36  with length  960000\n",
      "file n:  37  with length  960000\n",
      "file n:  38  with length  960000\n",
      "file n:  39  with length  960000\n",
      "file n:  40  with length  960000\n",
      "file n:  41  with length  960000\n",
      "file n:  42  with length  960000\n",
      "file n:  43  with length  960000\n",
      "file n:  44  with length  960000\n",
      "file n:  45  with length  960000\n",
      "file n:  46  with length  960000\n",
      "file n:  47  with length  960000\n",
      "file n:  48  with length  960000\n",
      "file n:  49  with length  960000\n",
      "file n:  50  with length  960000\n",
      "file n:  51  with length  960000\n",
      "file n:  52  with length  960000\n"
     ]
    }
   ],
   "source": [
    "window = 5.6 # seconds of audio in input\n",
    "hop = 1.875 # overlapping window time in seconds\n",
    "frequency = 16000\n",
    "\n",
    "# create dataset where the audio files are split in windows\n",
    "\n",
    "audio_splits = np.empty( (int(60 // hop - window // hop) * len(audio_files_list), int(frequency * window) ), dtype=\"int16\" )\n",
    "print(\"audio splits = \", audio_splits.shape)\n",
    "languages = []\n",
    "speakers = []\n",
    "split_index = 0\n",
    "\n",
    "for index, sample in dataset.iterrows():\n",
    "    #raw_data = np.array(literal_eval(sample[\"audio_raw_data\"]), dtype=\"int16\")\n",
    "    #raw_data = np.fromstring( (sample[\"audio_raw_data\"].replace(' ', ''))[1:-1], dtype=\"int16\", sep=',')\n",
    "    raw_data = sample[\"audio_raw_data\"]\n",
    "    print(\"file n: \", index, \" with length \", len(raw_data))\n",
    "    for time in range(0, int((60-window) * frequency), int(hop * frequency)):\n",
    "        audio_splits[split_index] = raw_data[time : int(time + window * frequency) ]\n",
    "        languages.append(sample[\"language\"])\n",
    "        speakers.append(sample[\"speaker\"])\n",
    "        split_index = split_index + 1\n",
    "        \n",
    "\n",
    "# Create a dictionary with the structured data\n",
    "data_dictionary = {\n",
    "    'audio_raw_data': audio_splits.tolist(),\n",
    "    'language': languages,\n",
    "    'speaker': speakers\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "dataset_windowed = pd.DataFrame(data_dictionary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Validation - Test splitting criteria\n",
    "\n",
    "Create training and validation dataset by splitting the data based on the speaker and language:\n",
    "\n",
    "- all the speakers having 1 or 2 languages associated will have their data split 75-25 between training and validation. Each audio sample is split in a piece of 45 seconds (used for training) and another separate piece of 15 seconds.\n",
    "- speakers having more than 2 languages associated will have 75% of languages in training and 25% of languages in validation. Each audio sample here is taken entirely without splitting, and placed in the corresponding dataset.\n",
    "\n",
    "The data collected are audio samples of 60 seconds. The split between training and validation is done in such a way to have completely separated data frames between the sets. \n",
    "This way the audio frames computed will never overlap between training and validation. This is important in order to have validation data that is unseen in training set. T\n",
    "his is due to the frames of the audio samples computed in sequences of frame_size with some overlap (hop_size). \n",
    "In order to have zero overlap between frames in the 2 datasets, we divide an audio samples in 2 separate non-overlapping pieces, where the frames are computed.\n",
    "\n",
    "This way the validation set can be used to estimate:\n",
    "- known speakers speaking in languages that have been already heard from them\n",
    "- known speakers speaking in languages that were never heard from them -> useful to understand quality of model's knowledge\n",
    "\n",
    "The test set will be created ad-hoc when a lot of data is collected. A few separate test sets will be created, needed to evaluate the performance of the model in different scenarios:\n",
    "\n",
    "1. known speakers in heard languages -> evaluate model performance in tested scenarios\n",
    "2. known speakers in un-heard languages -> evaluate performance for recognizing language instead of the speaker vocal characteristics\n",
    "3. unknown speakers -> evaluate performance for recognizing language from an unseen speaker\n",
    "\n",
    "The forecast for the test task is having the performance in the case 3 being lower than the case 2. Having separate test sets is useful in order to have an unbiased estimate of the model's performance on different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alessandro' 'donia' 'elena' 'francesco' 'gabriele' 'lorenzo' 'omar'\n",
      " 'thiago']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_ratio = 0.75 # 75% of training, 25% of validation\n",
    "\n",
    "classes_list = [\"ita\", \"eng\"] # substitute with np.unique(languages) to obtain whole set of languages\n",
    "speakers_list = np.unique(speakers)\n",
    "print(speakers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples considered:  1050\n",
      "entire dataset:  (1590, 3)\n"
     ]
    }
   ],
   "source": [
    "# select the samples that are in dataset_windowed and whose language is in classes_list\n",
    "valid_samples = []\n",
    "for sample in dataset_windowed.iterrows():\n",
    "    if sample[1]['language'] in classes_list:\n",
    "        valid_samples.append(sample[1])\n",
    "\n",
    "valid_samples = pd.DataFrame(valid_samples)\n",
    "\n",
    "print(\"samples considered: \", len(valid_samples))\n",
    "print(\"entire dataset: \", dataset_windowed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker:  alessandro  speaks:  ['eng' 'ita']\n",
      "samples quantity:  (210, 3)\n",
      "langs_spoken:  ['eng' 'ita']\n",
      "choice value:  [0.31184309]\n",
      "selected  210  samples from speaker  alessandro\n",
      "added  159  samples to training\n",
      "added  51  samples to validation\n",
      "\n",
      "speaker:  donia  speaks:  []\n",
      "samples quantity:  (0, 3)\n",
      "langs_spoken:  []\n",
      "skipping speaker:  donia\n",
      "\n",
      "speaker:  elena  speaks:  ['eng' 'ita']\n",
      "samples quantity:  (300, 3)\n",
      "langs_spoken:  ['eng' 'ita']\n",
      "choice value:  [0.6799766]\n",
      "selected  300  samples from speaker  elena\n",
      "adding  150  samples of language  eng  to training\n",
      "adding  150  samples of language  ita  to validation\n",
      "\n",
      "speaker:  francesco  speaks:  ['eng' 'ita']\n",
      "samples quantity:  (120, 3)\n",
      "langs_spoken:  ['eng' 'ita']\n",
      "choice value:  [0.29999873]\n",
      "selected  120  samples from speaker  francesco\n",
      "added  89  samples to training\n",
      "added  31  samples to validation\n",
      "\n",
      "speaker:  gabriele  speaks:  ['eng' 'ita']\n",
      "samples quantity:  (120, 3)\n",
      "langs_spoken:  ['eng' 'ita']\n",
      "choice value:  [0.96788489]\n",
      "selected  120  samples from speaker  gabriele\n",
      "adding  120  samples to validation\n",
      "\n",
      "speaker:  lorenzo  speaks:  ['eng' 'ita']\n",
      "samples quantity:  (180, 3)\n",
      "langs_spoken:  ['eng' 'ita']\n",
      "choice value:  [0.03774063]\n",
      "selected  180  samples from speaker  lorenzo\n",
      "added  129  samples to training\n",
      "added  51  samples to validation\n",
      "\n",
      "speaker:  omar  speaks:  ['eng']\n",
      "samples quantity:  (60, 3)\n",
      "langs_spoken:  ['eng']\n",
      "choice value:  [0.00303142]\n",
      "selected  60  samples from speaker  omar\n",
      "added  42  samples to training\n",
      "added  18  samples to validation\n",
      "\n",
      "speaker:  thiago  speaks:  ['eng']\n",
      "samples quantity:  (60, 3)\n",
      "langs_spoken:  ['eng']\n",
      "choice value:  [0.96691648]\n",
      "selected  60  samples from speaker  thiago\n",
      "adding  60  samples to validation\n",
      "\n",
      "dataset_train:  569\n",
      "dataset_validation:  481\n",
      "training ratio:  54.19047619047619 %\n",
      "validation ratio:  45.80952380952381 %\n",
      "total number of samples:  1050\n"
     ]
    }
   ],
   "source": [
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "\n",
    "for speaker in speakers_list:\n",
    "\t# take slice of the dataset containing the samples associated to one speaker\n",
    "\tdata_speaker = valid_samples[ valid_samples[\"speaker\"] == speaker]\n",
    "\tprint(\"speaker: \", speaker, \" speaks: \", np.unique(data_speaker[\"language\"]) )\n",
    "\tprint(\"samples quantity: \", data_speaker.shape)\n",
    "\n",
    "\t# compute number of languages spoken by the speaker\n",
    "\tlangs_spoken = np.unique(data_speaker[\"language\"])\n",
    "\n",
    "\tprint(\"langs_spoken: \", langs_spoken)\n",
    "\n",
    "\tif (langs_spoken.shape[0] == 0):\n",
    "\t\t# if the speaker doesn't speak any of the supported languages than doesn't add any sample\n",
    "\t\tprint(\"skipping speaker: \", speaker)\n",
    "\t\tprint(\"\")\n",
    "\t\tcontinue # skip to next speaker\n",
    "\t\n",
    "\tchoice = np.random.uniform(0, 1, size=1)\n",
    "\tprint(\"choice value: \", choice)\n",
    "\n",
    "\tsamples_number = len(data_speaker)\n",
    "\tprint(\"selected \", samples_number, \" samples from speaker \", speaker)\n",
    "\n",
    "\tif (choice < 0.5 or (choice >= 0.5 and choice < 0.85 and langs_spoken.shape[0] == 1)):\n",
    "\t\t# pick which samples go in training and which in validation\n",
    "\t\t\n",
    "\t\trandom_split = np.random.uniform(0, 1, size=samples_number)\n",
    "\t\t\n",
    "\t\tcount_valid = 0\n",
    "\t\tcount_train = 0\n",
    "\t\tdata_speaker = np.array(data_speaker)\n",
    "\t\tfor i in range(samples_number):\n",
    "\t\t\t# add one sample at a time in the datasets lists\n",
    "\t\t\tif (random_split[i] < split_ratio):\n",
    "\t\t\t\tdataset_train.append(data_speaker[i])\n",
    "\t\t\t\tcount_train += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tdataset_validation.append(data_speaker[i])\n",
    "\t\t\t\tcount_valid += 1\n",
    "\t\t\n",
    "\t\tprint(\"added \", count_train, \" samples to training\")\n",
    "\t\tprint(\"added \", count_valid, \" samples to validation\")\n",
    "\n",
    "\telif (choice >= 0.5 and choice < 0.85):\n",
    "\t\t# data from one language goes in validation, the rest in training\n",
    "\n",
    "\t\tif (langs_spoken.shape[0] > 1):\n",
    "\t\t\t# if the speaker speaks more than one language\n",
    "\t\t\trandom_split = np.random.uniform(0, 1, size=1)\n",
    "\n",
    "\t\t\tlang_choice = langs_spoken[int(random_split * langs_spoken.shape[0])]\n",
    "\n",
    "\t\t\tfor lang in langs_spoken:\n",
    "\t\t\t\tif (lang == lang_choice):\n",
    "\t\t\t\t\tadd_valid = data_speaker[ data_speaker[\"language\"] == lang ]\n",
    "\t\t\t\t\tadd_valid = np.array(add_valid)\n",
    "\t\t\t\t\tprint(\"adding \", add_valid.shape[0], \" samples of language \", lang, \" to validation\")\n",
    "\t\t\t\t\tdataset_validation.extend(add_valid)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tadd_train = data_speaker[ data_speaker[\"language\"] == lang ]\n",
    "\t\t\t\t\tadd_train = np.array(add_train)\n",
    "\t\t\t\t\tprint(\"adding \", add_train.shape[0], \" samples of language \", lang, \" to training\")\n",
    "\t\t\t\t\tdataset_train.extend(add_train)\n",
    "\n",
    "\t\telse: \n",
    "\t\t\t# if the speaker doesn't speak any of the supported languages than doesn't add any sample\n",
    "\t\t\tpass # do nothing\n",
    "\telse:\n",
    "\t\t# data from this speaker goes entirely in validation\n",
    "\t\tprint(\"adding \", samples_number, \" samples to validation\")\n",
    "\t\tdata_speaker = np.array(data_speaker)\n",
    "\t\tdataset_validation.extend(data_speaker)\n",
    "\t\n",
    "\tprint(\"\")\n",
    "\n",
    "\n",
    "len_train = len(dataset_train)\n",
    "len_valid = len(dataset_validation)\n",
    "total = len_train + len_valid\n",
    "print(\"dataset_train: \", len_train)\n",
    "print(\"dataset_validation: \", len_valid)\n",
    "print(\"training ratio: \", len_train / total * 100.0, \"%\")\n",
    "print(\"validation ratio: \", len_valid / total * 100.0, \"%\")\n",
    "print(\"total number of samples: \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset_train to dataframe and save it into a csv file\n",
    "# convert dataset_validation to dataframe and save it into a csv file\n",
    "folder = os.path.dirname(os.getcwd()) + \"/datasets/\"\n",
    "\n",
    "train_df = pd.DataFrame(dataset_train)\n",
    "train_df.to_csv(folder + 'dataset_train.csv', index=False)\n",
    "\n",
    "valid_df = pd.DataFrame(dataset_validation)\n",
    "valid_df.to_csv(folder + 'dataset_validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
