{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network for Keyword Spotting on Microncontrollers\n",
        "\n",
        "This notebook provides the code for training a Neural Network to be able to recognize spoken workds. This task is commonly referred as Keyword Spotting (KWS).\n",
        "\n",
        "The goal of this notebook is to build a small enough model to be executed on microcontrollers, where computational power, energy consumption and memory availability are constraints to be taken into account.\n",
        "\n",
        "## A note on datasets\n",
        "\n",
        "In order to train the network in this notebook, you need to have a dataset ready to be processed. This notebook requires an audio dataset made of 1-second long audio samples converted into MFCC Spectrograms in the shape of (49,40,1), meaning that each spectrogram must be an image of size 49x40 with only 1 channel (black/white), and saved in a .npz file.\n",
        "\n",
        "A notebook to convert audio data into a dataset ready to be processed by this notebook is provided."
      ],
      "metadata": {
        "id": "UtA5YPo9jQHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries Import\n",
        "\n",
        "First of all, let's import the needed libraries."
      ],
      "metadata": {
        "id": "3IWygOvCLBmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow==2.8.2\n",
        "\n",
        "#Tensorflow import>\n",
        "import tensorflow as tf\n",
        "#Numpy import\n",
        "import numpy as np\n",
        "#Matplotlib import\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "#Math import\n",
        "import math\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import shutil\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCcpq2MXjPgG",
        "outputId": "c157d083-f9ef-4e94-cd88-ac03ad6d615b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.8.2 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (23.3.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.32.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.54.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\n",
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before continuing, let's set the seed to the random numbers generator. This will allow us to have reproducible results between different executions of this notebook."
      ],
      "metadata": {
        "id": "O6bzD5MuMVIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seed for reproducibility\n",
        "\n",
        "seed = 22 #Choose a fixed seed to have reproducible results (22=Gonzales o Chiesa)\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "metadata": {
        "id": "fSDdFpuQU8n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Import and Loading\n",
        "\n",
        "If the datast that you want to use is located in your Google Drive, execute the following cell to get access to the drive."
      ],
      "metadata": {
        "id": "X-91TM9JLvKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pavFcZoKxXea",
        "outputId": "5a2f8eed-c349-43fe-b938-0fdadac964d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unpack the dataset:"
      ],
      "metadata": {
        "id": "oODxdDLiL5pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#If the dataset is in your Google Drive:\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/sheila_normalized_dataset.zip\", \"dataset\")\n",
        "#If the dataset has to be uploaded:\n",
        "#shutil.unpack_archive(\"/content/sheila_normalized_dataset.zip\", \"dataset\")"
      ],
      "metadata": {
        "id": "m6mGEbnGeX-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the .json file associated to the dataset:"
      ],
      "metadata": {
        "id": "9Lm0ISmfL8-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "with open(\"dataset/content/dataset_info.json\", 'r') as openfile:\n",
        "\n",
        "    # Reading from json file\n",
        "    dataset_info = json.load(openfile)\n",
        "\n",
        "print(dataset_info)\n",
        "\n",
        "wanted_words = dataset_info['classes']\n",
        "n_train_samples = dataset_info['train_samples_num']\n",
        "n_testing_samples = dataset_info['testing_samples_num']\n",
        "n_validation_samples = dataset_info['validation_samples_num']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooi8mPnFelhA",
        "outputId": "6bacd529-8999-43f1-f7a8-8e1ad77ced57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'classes': ['silence', 'unknown', 'sheila'], 'train_samples_num': 8109, 'testing_samples_num': 1015, 'validation_samples_num': 1013, 'representative_samples_num': 103, 'data_shape': [49, 40, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains training, testing and validation sets. It also provides a representative dataset if a quantization of the model needs to be performed.\n",
        "\n",
        "Load each set into X (inputs) and y (outputs) arrays."
      ],
      "metadata": {
        "id": "vXZllnpxoNEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading .npz files\n",
        "train_dir = \"/content/dataset/content/train.npz\"\n",
        "training_npz = np.load(train_dir)\n",
        "x_train, y_train = training_npz['arr_0'], training_npz['arr_1']\n",
        "\n",
        "val_dir = \"/content/dataset/content/validation.npz\"\n",
        "validation_npz = np.load(val_dir)\n",
        "x_val, y_val = validation_npz['arr_0'], validation_npz['arr_1']\n",
        "\n",
        "testing_dir = \"/content/dataset/content/testing.npz\"\n",
        "testing_npz = np.load(testing_dir)\n",
        "x_test, y_test = testing_npz['arr_0'], testing_npz['arr_1']\n",
        "\n",
        "representative_dir = \"/content/dataset/content/representative.npz\"\n",
        "representative_npz = np.load(representative_dir)\n",
        "x_rep, y_rep = representative_npz['arr_0'], representative_npz['arr_1']"
      ],
      "metadata": {
        "id": "-ZWTz_pQfvII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Design\n",
        "\n",
        "The next section will allow you to design a Neural Network. There is no golden rule, so feel free to experiment with different architectures.\n",
        "\n",
        "Since MFCC spectrograms can be considered images, we will perform an image classification task, trying to associate each spectrogram with the word it represents. Convolutional Neural Networks have shown very good results in accomplishing image classification tasks."
      ],
      "metadata": {
        "id": "lNU6YtAJNHhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing to do is define a Data Generator: it is a function that takes care of sending the data to the Neural Network during training and evaluation."
      ],
      "metadata": {
        "id": "myEtH6R9Npui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tfk.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, labels, n_samples, batch_size, dim, n_channels,\n",
        "                 n_classes, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.n_samples = n_samples\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(self.n_samples / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # Find list of IDs\n",
        "        samples_list_temp = indexes\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(samples_list_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(self.n_samples)\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, samples_list_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, 49, 40, 1)) #*self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, sample in enumerate(samples_list_temp):\n",
        "            # Store sample\n",
        "            mfcc = self.data[sample].reshape(49, 40, 1)\n",
        "            X[i,] = mfcc\n",
        "            # Store class\n",
        "            y[i] = self.labels[sample]\n",
        "\n",
        "        return X, tfk.utils.to_categorical(y, num_classes=self.n_classes)"
      ],
      "metadata": {
        "id": "TRVMV4WbbS7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we instantiate the generators for each set: training, testing and validation.\n",
        "\n",
        "In this section we also specify the batch size to be used during training. The batch size is the number of training samples that the network processes before updating its weights."
      ],
      "metadata": {
        "id": "Lz-OrYtYN5qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "n_classes = len(wanted_words)\n",
        "spectrogram_size = (49,40,)\n",
        "spectrogram_channels = 1\n",
        "\n",
        "# Parameters\n",
        "params = {'dim': spectrogram_size,\n",
        "          'batch_size': batch_size,\n",
        "          'n_classes': n_classes,\n",
        "          'n_channels': spectrogram_channels,\n",
        "          'shuffle': True}\n",
        "\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(x_train, y_train, n_samples=n_train_samples, **params)\n",
        "validation_generator = DataGenerator(x_val, y_val, n_samples=n_validation_samples, **params)\n",
        "testing_generator = DataGenerator(x_test, y_test, n_samples=n_testing_samples, **params)\n",
        "\n",
        "example_spectrogram = training_generator.__getitem__(0)[0]\n",
        "print(\"Neural Network input shape: \" + str(example_spectrogram.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXKhaC10qYAm",
        "outputId": "d7d38580-720c-483b-b7db-2297e3ed081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network input shape: (8, 49, 40, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is now time to build the Neural Network."
      ],
      "metadata": {
        "id": "YFT_bvHWOS5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (49, 40, 1) #(*spectrogram_size, spectrogram_channels) #do not modify\n",
        "\n",
        "# Assign the name you want to your model\n",
        "model_name = 'Sheila-NormDoubleConvModel'\n",
        "\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "model = models.Sequential()\n",
        "#model.add(layers.Input(shape=(1960)))\n",
        "#model.add(layers.Reshape([49,40,1]))\n",
        "model.add(layers.Conv2D(4, (4, 10), strides = (2, 2), activation='relu', input_shape = input_shape))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(units=3,\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
        "                  use_bias = True,\n",
        "                  name='Output'))\n",
        "\n",
        "input_layer = tfkl.Input(shape=input_shape,\n",
        "                          name='Input')\n",
        "\n",
        "optimizer = tfk.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(),\n",
        "              optimizer=optimizer,\n",
        "              metrics='accuracy')\n",
        "\n"
      ],
      "metadata": {
        "id": "_lxcoqaqqgfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the network we just built and print a summary with the number of parameters, the layers and input/output shapes of each layer."
      ],
      "metadata": {
        "id": "pxQ7uC_iOYuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = build_model(input_shape)\n",
        "#model.build((-1,49,40,1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwVTxA87qj2B",
        "outputId": "478b9e2a-227f-4dd2-cd67-7b6d98f28e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 23, 16, 4)         164       \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 4)                0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " Output (Dense)              (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179\n",
            "Trainable params: 179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Neural Network\n",
        "\n",
        "This section will train the neural network."
      ],
      "metadata": {
        "id": "baRWCZy4OheD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we define some callback functions to be executed at the end of each epoch. Remember that an epoch is a single pass through the entire dataset during training."
      ],
      "metadata": {
        "id": "YH9sMo2WOoyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = \"/content/callback_folder\"\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "\n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
        "                                                     save_weights_only=False, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch\n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Visualize Learning on Tensorboard\n",
        "  # ---------------------------------\n",
        "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "  if not os.path.exists(tb_dir):\n",
        "      os.makedirs(tb_dir)\n",
        "\n",
        "  # By default shows losses and metrics for both training and validation\n",
        "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                               profile_batch=0,\n",
        "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
        "  callbacks.append(tb_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  return callbacks"
      ],
      "metadata": {
        "id": "uU5Izt4zMsjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a number of epochs to train you network, and then start the training."
      ],
      "metadata": {
        "id": "dZqPUdtiO0v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many epochs?\n",
        "epochs = 5\n",
        "\n",
        "# Callbacks creator\n",
        "model_callbacks = create_folders_and_callbacks(model_name)\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = training_generator,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    callbacks = model_callbacks\n",
        ").history"
      ],
      "metadata": {
        "id": "FBTz_U1KqokQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa051545-d875-497e-c3ec-debfb93612e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1013/1013 [==============================] - 5s 5ms/step - loss: 0.6193 - accuracy: 0.7217 - val_loss: 0.5766 - val_accuracy: 0.7312\n",
            "Epoch 2/5\n",
            "1013/1013 [==============================] - 4s 4ms/step - loss: 0.6074 - accuracy: 0.7332 - val_loss: 0.5700 - val_accuracy: 0.7272\n",
            "Epoch 3/5\n",
            "1013/1013 [==============================] - 4s 4ms/step - loss: 0.5976 - accuracy: 0.7349 - val_loss: 0.5595 - val_accuracy: 0.7440\n",
            "Epoch 4/5\n",
            "1013/1013 [==============================] - 6s 6ms/step - loss: 0.5898 - accuracy: 0.7475 - val_loss: 0.5559 - val_accuracy: 0.7381\n",
            "Epoch 5/5\n",
            "1013/1013 [==============================] - 4s 4ms/step - loss: 0.5835 - accuracy: 0.7449 - val_loss: 0.5490 - val_accuracy: 0.7411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model on the testing dataset:"
      ],
      "metadata": {
        "id": "t_nL3y-sPJ84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(1960))\n",
        "x = inputs\n",
        "x = layers.Reshape([49,40,1])(x)\n",
        "\n",
        "for layer in model.layers[:]:\n",
        "  x = model.get_layer(layer.name)(x)\n",
        "\n",
        "model2 = tf.keras.Model(inputs, x, name='model2')\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyTX9DkBbERS",
        "outputId": "a78302d4-4aa5-4885-d48f-9c51a120e051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1960)]            0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 49, 40, 1)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 16, 4)         164       \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 4)                0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " Output (Dense)              (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179\n",
            "Trainable params: 179\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics = model.evaluate(testing_generator, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83078e2d-5e17-4019-9e3a-ec0ce63a1a0a",
        "id": "Qr7ku40VPUC1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and exporting the trained model\n",
        "\n",
        "This last section takes care of saving and exporting the trained model in .h5 format, in order to process it through the Infineon ML Configurator Tool available in Modus Toolbox."
      ],
      "metadata": {
        "id": "zKVmbw3TO6zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(os.path.join('/content/models', model_name))"
      ],
      "metadata": {
        "id": "DWXaq62rp-il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tfk.models.load_model(os.path.join('/content/models', model_name))\n",
        "model_metrics = model.evaluate(testing_generator, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssuU7nT5np6v",
        "outputId": "e69c551e-cc57-4900-cc5f-4dc69db1cfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 4ms/step - loss: 0.5355 - accuracy: 0.7321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h5_model_name = model_name + '.h5'\n",
        "tfk.models.save_model(model, os.path.join('/content/models', h5_model_name))"
      ],
      "metadata": {
        "id": "E6uXucqztD95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion for TFLite Micro\n",
        "The following section will convert the code for a microcontroller with a float and a 8 bit quantization.\n",
        "\n",
        "This is not to be done if you want to use the Infineon IFX engine, because it will take care of this conversion step."
      ],
      "metadata": {
        "id": "54_zmMBuC1nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float model export:\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
        "tflite_model = converter.convert()\n",
        "print(\"Float model size:\", open(os.path.join('/content/models', model_name + '.tflite'), \"wb\").write(tflite_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW5Cz9BMC8qA",
        "outputId": "5f427b2e-a6bb-4d14-f6db-9b335ed1ab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model size: 3656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized model export:\n",
        "\n",
        "# Definition of Representative Dataset generator:\n",
        "def representative_data_gen():\n",
        "  for sample in x_rep:\n",
        "    data = sample.reshape(-1, 49, 40, spectrogram_channels).astype(np.float32)\n",
        "    yield [data]\n",
        "\n",
        "#def representative_dataset():\n",
        "#  for i in range(100):\n",
        "#    yield [ np.array([(np.random.rand(1960)).astype(np.float32)]) ]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.compat.v1.lite.constants.INT8 # or tf.uint8\n",
        "converter.inference_output_type = tf.compat.v1.lite.constants.INT8  # or tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "print(\"Quantized model size: \", open(os.path.join('/content/models', model_name + '-int8.tflite'), \"wb\").write(tflite_model_quant))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5yfoy1_DDK7",
        "outputId": "bcf94dff-0dd0-4204-c2a5-6223737ace03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model size:  3576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3jWIB7NRF7hi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snF9dxLqHrBG"
      },
      "source": [
        "### Generate a TensorFlow Lite for Microcontrollers Model\n",
        "To convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers on Arduino we simply need to use the ```xxd``` tool to convert the ```.tflite``` file into a ```.cc``` file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get -qq install xxd\n",
        "\n",
        "MODEL_TFLITE = '/content/models/'+ model_name +'-int8.tflite'\n",
        "MODEL_TFLITE_MICRO = 'TinyConvModel-int8.cc'\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "#REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wal1izt0F8oq",
        "outputId": "3542e752-6637-45e5-d101-4c1e71ffabda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,050 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,202 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,726 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,270 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,345 kB]\n",
            "Fetched 11.0 MB in 9s (1,257 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBVUjnPWc_tK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}