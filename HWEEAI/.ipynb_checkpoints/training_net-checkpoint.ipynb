{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 450\n"
     ]
    }
   ],
   "source": [
    "# create tensorflow dataset from the training data\n",
    "\n",
    "# iterate on every csv file in the folder\n",
    "# create a dataset from the csv file\n",
    "# append the dataset to the main dataset\n",
    "# save the main dataset to a file\n",
    "\n",
    "import os\n",
    "\n",
    "# get parent directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# get the list of csv files in the folder\n",
    "directory = parent_dir + \"\\\\datasets\\\\\"\n",
    "\n",
    "csv_files_ita = [directory + \"\\\\ita\\\\\" + f for f in os.listdir(directory + \"ita\\\\\") if f.endswith('.csv')]\n",
    "csv_files_eng = [directory + \"\\\\eng\\\\\" + f for f in os.listdir(directory + \"eng\\\\\") if f.endswith('.csv')]\n",
    "\n",
    "print(len(csv_files_ita), len(csv_files_eng))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    " \n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data array shape: (1247, 12)\n",
      "(<tf.Tensor: shape=(1247, 12), dtype=int8, numpy=\n",
      "array([[-89,  32,  76, ...,  35,  63,  49],\n",
      "       [-84,  18,  57, ..., -11,  61,  22],\n",
      "       [-83,  14,  66, ..., -32,  56,  20],\n",
      "       ...,\n",
      "       [ -6,  87,  22, ..., -14,  14,   5],\n",
      "       [ 11,  71,  -4, ...,  -7,   1, -16],\n",
      "       [ 32,  69, -33, ..., -17,   0,   2]], dtype=int8)>, <tf.Tensor: shape=(), dtype=string, numpy=b'ita'>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# read csv file and store the values into a numpy matrix\n",
    "data_array = np.genfromtxt(csv_files_ita[0], delimiter=',', dtype=np.int8)\n",
    "print(\"Loaded data array shape:\", data_array.shape)\n",
    "\n",
    "label = \"ita\"\n",
    "test = [[1, 2], [3, 4]]\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "tf_dataset_matrix = tf.data.Dataset.from_tensor_slices([data_array])\n",
    "tf_dataset_label = tf.data.Dataset.from_tensor_slices([label])\n",
    "\n",
    "tf_dataset = tf.data.Dataset.zip((tf_dataset_matrix, tf_dataset_label))\n",
    "\n",
    "for element in tf_dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  875\n",
      "labels size:  875\n"
     ]
    }
   ],
   "source": [
    "# create empty pandas dataframe\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "# read csv files into dataframe\n",
    "for file in csv_files_ita:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset.append(data_array)\n",
    "    labels.append(\"ita\")\n",
    "\n",
    "for file in csv_files_eng:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset.append(data_array)\n",
    "    labels.append(\"eng\")\n",
    "\n",
    "print(\"dataset size: \", len(dataset))\n",
    "print(\"labels size: \", len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels = np.array([class_to_index[label] for label in labels], dtype=np.int8)\n",
    "\n",
    "labels_one_hot = tf.keras.utils.to_categorical(integer_labels, num_classes=2) # one hot encoding\n",
    "\n",
    "print(labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n"
     ]
    }
   ],
   "source": [
    "# train - validation split of tensorflow dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(dataset, labels_one_hot, test_size=0.2, random_state=42) \n",
    "print(val_features[0].dtype)\n",
    "\n",
    "val_features = tf.reshape(val_features, (-1, 1247, 12))\n",
    "train_features = tf.reshape(train_features, (-1, 1247, 12))\n",
    "\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_labels))\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(train_features))\n",
    "\n",
    "val_dataset = val_dataset.batch(32)\n",
    "train_dataset = train_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1247, 12)\n",
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(image_batch.shape)\n",
    "\tprint(labels_batch.shape)\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 1243, 12, 64)      384       \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 621, 12, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 617, 12, 64)       20544     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 308, 12, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 306, 12, 32)       6176      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 153, 12, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 151, 10, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 75, 5, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 32)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,530\n",
      "Trainable params: 38,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.5471INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 143ms/step - loss: 0.7317 - accuracy: 0.5471 - val_loss: 0.6769 - val_accuracy: 0.5486\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.6647 - accuracy: 0.5986 - val_loss: 0.6966 - val_accuracy: 0.5143\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.6029INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 136ms/step - loss: 0.6496 - accuracy: 0.6029 - val_loss: 0.6107 - val_accuracy: 0.6800\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.6388 - accuracy: 0.6186 - val_loss: 0.6441 - val_accuracy: 0.6057\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.6786INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 134ms/step - loss: 0.6147 - accuracy: 0.6786 - val_loss: 0.5841 - val_accuracy: 0.6857\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.6409 - accuracy: 0.6443 - val_loss: 0.6243 - val_accuracy: 0.6457\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.6253 - accuracy: 0.6671 - val_loss: 0.6096 - val_accuracy: 0.6343\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.6729INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 133ms/step - loss: 0.5929 - accuracy: 0.6729 - val_loss: 0.5646 - val_accuracy: 0.7086\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5642 - accuracy: 0.7171 - val_loss: 0.6086 - val_accuracy: 0.6800\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5850 - accuracy: 0.6957 - val_loss: 0.5579 - val_accuracy: 0.6971\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7271INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 139ms/step - loss: 0.5602 - accuracy: 0.7271 - val_loss: 0.5460 - val_accuracy: 0.7314\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5530 - accuracy: 0.7357 - val_loss: 0.5423 - val_accuracy: 0.6971\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5931 - accuracy: 0.6843 - val_loss: 0.5641 - val_accuracy: 0.7143\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5778 - accuracy: 0.6929 - val_loss: 0.5721 - val_accuracy: 0.7143\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5485 - accuracy: 0.7343 - val_loss: 0.5536 - val_accuracy: 0.7086\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.5280 - accuracy: 0.7414 - val_loss: 0.5646 - val_accuracy: 0.7257\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.7386INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 136ms/step - loss: 0.5197 - accuracy: 0.7386 - val_loss: 0.5274 - val_accuracy: 0.7486\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5638 - accuracy: 0.7000 - val_loss: 0.5460 - val_accuracy: 0.7200\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5443 - accuracy: 0.7271 - val_loss: 0.5759 - val_accuracy: 0.7143\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5378 - accuracy: 0.7443 - val_loss: 0.5168 - val_accuracy: 0.7314\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5364 - accuracy: 0.7443 - val_loss: 0.5092 - val_accuracy: 0.7486\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 0.5323 - accuracy: 0.7543 - val_loss: 0.5106 - val_accuracy: 0.7486\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7329INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 134ms/step - loss: 0.5386 - accuracy: 0.7329 - val_loss: 0.4984 - val_accuracy: 0.7657\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.4918 - accuracy: 0.7657 - val_loss: 0.5103 - val_accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5168 - accuracy: 0.7486 - val_loss: 0.6688 - val_accuracy: 0.6343\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.6269 - accuracy: 0.6586 - val_loss: 0.5748 - val_accuracy: 0.6571\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5475 - accuracy: 0.7014 - val_loss: 0.6431 - val_accuracy: 0.6343\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.5180 - accuracy: 0.7414 - val_loss: 0.5210 - val_accuracy: 0.7086\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5240 - accuracy: 0.7371 - val_loss: 0.5376 - val_accuracy: 0.7371\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.4733 - accuracy: 0.7814 - val_loss: 0.4928 - val_accuracy: 0.7371\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.5630 - accuracy: 0.7029 - val_loss: 0.5192 - val_accuracy: 0.7371\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.7643INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 134ms/step - loss: 0.4958 - accuracy: 0.7643 - val_loss: 0.5094 - val_accuracy: 0.7829\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7871INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 133ms/step - loss: 0.4659 - accuracy: 0.7871 - val_loss: 0.4604 - val_accuracy: 0.7886\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.4860 - accuracy: 0.7686 - val_loss: 0.4603 - val_accuracy: 0.7771\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.7814INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 141ms/step - loss: 0.4492 - accuracy: 0.7814 - val_loss: 0.4499 - val_accuracy: 0.8000\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.4392 - accuracy: 0.7843 - val_loss: 0.5033 - val_accuracy: 0.7371\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.7400INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5234 - accuracy: 0.7400 - val_loss: 0.4481 - val_accuracy: 0.8057\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.4385 - accuracy: 0.8014 - val_loss: 0.4729 - val_accuracy: 0.7714\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8257INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3839 - accuracy: 0.8257 - val_loss: 0.4030 - val_accuracy: 0.8171\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8329INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 132ms/step - loss: 0.3777 - accuracy: 0.8329 - val_loss: 0.3707 - val_accuracy: 0.8286\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.3885 - accuracy: 0.8200 - val_loss: 0.4089 - val_accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.8643INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3150 - accuracy: 0.8643 - val_loss: 0.3262 - val_accuracy: 0.8514\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.3221 - accuracy: 0.8500 - val_loss: 0.3473 - val_accuracy: 0.8400\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.4472 - accuracy: 0.7843 - val_loss: 0.4429 - val_accuracy: 0.7943\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.3330 - accuracy: 0.8571 - val_loss: 0.3551 - val_accuracy: 0.8229\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.2897 - accuracy: 0.8786 - val_loss: 0.3936 - val_accuracy: 0.8057\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9114INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 131ms/step - loss: 0.2161 - accuracy: 0.9114 - val_loss: 0.3056 - val_accuracy: 0.8800\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.2056 - accuracy: 0.9071 - val_loss: 0.3939 - val_accuracy: 0.8171\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9014INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 132ms/step - loss: 0.2147 - accuracy: 0.9014 - val_loss: 0.2668 - val_accuracy: 0.9029\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.2350 - accuracy: 0.9100 - val_loss: 0.2999 - val_accuracy: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1475565b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import absl.logging\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "    #layers.Reshape(( 1247, 12), input_shape=(1247, 12)),\n",
    "\tlayers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu', input_shape=(1247, 12, 1)),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.GlobalAveragePooling2D(), \n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"\\\\models\\\\\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
    "\n",
    "callbacks_list = [checkpoint, es]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=50, callbacks=callbacks_list, batch_size=32, \n",
    "          validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\model_lite\\CNN_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\model_lite\\CNN_model_h5\\assets\n"
     ]
    }
   ],
   "source": [
    "filepath = parent_dir + \"\\\\model_lite\\\\\"\n",
    "model.save(filepath +  \"CNN_model_h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_49_input:0', 'index': 0, 'shape': array([   1, 1247,   12,    1]), 'shape_signature': array([  -1, 1247,   12,    1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 28, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1 1247   12    1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-89  32  76 ...  35  63  49]\n",
      " [-84  18  57 ... -11  61  22]\n",
      " [-83  14  66 ... -32  56  20]\n",
      " ...\n",
      " [ -6  87  22 ... -14  14   5]\n",
      " [ 11  71  -4 ...  -7   1 -16]\n",
      " [ 32  69 -33 ... -17   0   2]]\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(dataset))\n",
    "\n",
    "print(dataset[0])\n",
    "# Select the random data point using the random index\n",
    "random_data_point = dataset[random_index]\n",
    "random_label = labels[random_index]\n",
    "# Convert the random data point from int8 to float32\n",
    "input_data_matrix = random_data_point.astype(np.float32)\n",
    "batch_size = 1\n",
    "\n",
    "input_data_matrix = tf.reshape(input_data_matrix, (-1, 1247, 12, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 1 but expected 1247 for dimension 1 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3956\\3612392701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set input data to the interpreter.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Run inference.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    695\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \"\"\"\n\u001b[1;32m--> 697\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 1 but expected 1247 for dimension 1 of input 0."
     ]
    }
   ],
   "source": [
    "# Set input data to the interpreter.\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data_matrix)\n",
    "\n",
    "# Run inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output data from the interpreter.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process output data.\n",
    "# For example, if your output is classification probabilities:\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
