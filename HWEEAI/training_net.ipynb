{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  3300\n",
      "validation files:  900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 12:53:24.554521: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 12:53:33.007488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 12:53:42.412193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:53:45.074111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:53:45.074779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# imports of necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  3300\n",
      "dataset validation size:  900\n",
      "labels train size:  3300\n",
      "labels validation size:  900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ita': 0, 'eng': 1, 'fra': 2}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\", \"fra\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "print(class_to_index)\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 12:54:03.431654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:03.432195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:03.432534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:04.042647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:04.043089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:04.043507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-23 12:54:04.043842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3494 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (3300, 349, 12, 1)\n",
      "Validation features shape: (900, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 150\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "#val_dataset = val_dataset.shuffle(len(x_validation))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (64, 349, 12, 1)\n",
      "MFCC labels shape:  (64, 3)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 345, 12, 16)       96        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 172, 12, 16)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 172, 8, 16)        1296      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 86, 8, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 82, 6, 16)         3856      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 41, 3, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 1, 1, 16)          0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5299 (20.70 KB)\n",
      "Trainable params: 5299 (20.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# first model version\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=16, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(1, 5), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(5, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "\tlayers.AveragePooling2D(pool_size=(41, 3)),\n",
    "\tlayers.Flatten(),\n",
    "\t#layers.Dense(32, activation='relu'),\n",
    "    #layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(len(classes), activation='softmax')  # as many classes as languages\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 19ms/step - loss: 2.1630 - accuracy: 0.3882 - val_loss: 1.1148 - val_accuracy: 0.4167\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.0857 - accuracy: 0.4436 - val_loss: 1.2440 - val_accuracy: 0.3744\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 1.0092 - accuracy: 0.4933 - val_loss: 0.9657 - val_accuracy: 0.5589\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.9306 - accuracy: 0.5542 - val_loss: 0.9089 - val_accuracy: 0.5589\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.9058 - accuracy: 0.5706 - val_loss: 0.8987 - val_accuracy: 0.5844\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8555 - accuracy: 0.6061 - val_loss: 0.8482 - val_accuracy: 0.6322\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8544 - accuracy: 0.6091 - val_loss: 0.8193 - val_accuracy: 0.6356\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8346 - accuracy: 0.6173 - val_loss: 0.8200 - val_accuracy: 0.6433\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7927 - accuracy: 0.6467 - val_loss: 0.8748 - val_accuracy: 0.6111\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7684 - accuracy: 0.6570 - val_loss: 0.9280 - val_accuracy: 0.5478\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7611 - accuracy: 0.6585 - val_loss: 0.7863 - val_accuracy: 0.6644\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7095 - accuracy: 0.6918 - val_loss: 0.7569 - val_accuracy: 0.6556\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7362 - accuracy: 0.6861 - val_loss: 0.8010 - val_accuracy: 0.6589\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.7018 - accuracy: 0.6988 - val_loss: 0.7254 - val_accuracy: 0.6667\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.6610 - accuracy: 0.7203 - val_loss: 0.7144 - val_accuracy: 0.6867\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.6596 - accuracy: 0.7094 - val_loss: 0.7226 - val_accuracy: 0.6656\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6812 - accuracy: 0.7033 - val_loss: 0.7493 - val_accuracy: 0.6844\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.6244 - accuracy: 0.7385 - val_loss: 0.6904 - val_accuracy: 0.6978\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6609 - accuracy: 0.7185 - val_loss: 0.6879 - val_accuracy: 0.7022\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6104 - accuracy: 0.7515 - val_loss: 0.7825 - val_accuracy: 0.6733\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6443 - accuracy: 0.7309 - val_loss: 0.7117 - val_accuracy: 0.6767\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5718 - accuracy: 0.7700 - val_loss: 0.7765 - val_accuracy: 0.6756\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.5579 - accuracy: 0.7733 - val_loss: 0.8516 - val_accuracy: 0.6411\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.5664 - accuracy: 0.7739 - val_loss: 0.6923 - val_accuracy: 0.7122\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5597 - accuracy: 0.7694 - val_loss: 0.6467 - val_accuracy: 0.7078\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5650 - accuracy: 0.7645 - val_loss: 0.8161 - val_accuracy: 0.6256\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.5560 - accuracy: 0.7770 - val_loss: 0.6407 - val_accuracy: 0.7044\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4978 - accuracy: 0.8033 - val_loss: 0.5959 - val_accuracy: 0.7289\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4924 - accuracy: 0.7985 - val_loss: 0.6756 - val_accuracy: 0.7122\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5023 - accuracy: 0.7979 - val_loss: 0.7405 - val_accuracy: 0.6744\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4816 - accuracy: 0.8082 - val_loss: 0.6033 - val_accuracy: 0.7333\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4588 - accuracy: 0.8224 - val_loss: 0.6721 - val_accuracy: 0.7033\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4643 - accuracy: 0.8173 - val_loss: 0.5961 - val_accuracy: 0.7389\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4431 - accuracy: 0.8276 - val_loss: 0.5776 - val_accuracy: 0.7544\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4308 - accuracy: 0.8306 - val_loss: 0.5879 - val_accuracy: 0.7456\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4374 - accuracy: 0.8255 - val_loss: 0.5563 - val_accuracy: 0.7511\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4065 - accuracy: 0.8439 - val_loss: 0.6892 - val_accuracy: 0.7100\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4424 - accuracy: 0.8264 - val_loss: 0.5564 - val_accuracy: 0.7556\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4489 - accuracy: 0.8158 - val_loss: 0.5605 - val_accuracy: 0.7578\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4046 - accuracy: 0.8473 - val_loss: 0.6026 - val_accuracy: 0.7500\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4062 - accuracy: 0.8421 - val_loss: 1.0663 - val_accuracy: 0.6133\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.4131 - accuracy: 0.8382 - val_loss: 0.7174 - val_accuracy: 0.7189\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4223 - accuracy: 0.8309 - val_loss: 0.6914 - val_accuracy: 0.7244\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3676 - accuracy: 0.8588 - val_loss: 0.5194 - val_accuracy: 0.7744\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3379 - accuracy: 0.8806 - val_loss: 0.7289 - val_accuracy: 0.7089\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3604 - accuracy: 0.8670 - val_loss: 0.5572 - val_accuracy: 0.7678\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3239 - accuracy: 0.8827 - val_loss: 0.5292 - val_accuracy: 0.7700\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3281 - accuracy: 0.8785 - val_loss: 0.5390 - val_accuracy: 0.7722\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3483 - accuracy: 0.8673 - val_loss: 0.6073 - val_accuracy: 0.7456\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3207 - accuracy: 0.8806 - val_loss: 0.6972 - val_accuracy: 0.7411\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3677 - accuracy: 0.8600 - val_loss: 0.5642 - val_accuracy: 0.7533\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.3073 - accuracy: 0.8879 - val_loss: 0.5613 - val_accuracy: 0.7600\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3189 - accuracy: 0.8821 - val_loss: 0.5106 - val_accuracy: 0.7822\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3181 - accuracy: 0.8785 - val_loss: 0.5030 - val_accuracy: 0.7944\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2739 - accuracy: 0.9106 - val_loss: 0.5189 - val_accuracy: 0.7778\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.3037 - accuracy: 0.8885 - val_loss: 0.5222 - val_accuracy: 0.7911\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.8855 - val_loss: 0.5032 - val_accuracy: 0.8000\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3085 - accuracy: 0.8788 - val_loss: 0.5013 - val_accuracy: 0.7911\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2927 - accuracy: 0.8861 - val_loss: 0.6022 - val_accuracy: 0.7600\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2761 - accuracy: 0.8970 - val_loss: 0.5279 - val_accuracy: 0.7867\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2504 - accuracy: 0.9142 - val_loss: 0.5426 - val_accuracy: 0.7822\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2689 - accuracy: 0.9064 - val_loss: 0.4911 - val_accuracy: 0.7900\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2827 - accuracy: 0.8921 - val_loss: 0.5433 - val_accuracy: 0.7767\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2812 - accuracy: 0.8985 - val_loss: 0.4777 - val_accuracy: 0.8022\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2526 - accuracy: 0.9112 - val_loss: 0.5098 - val_accuracy: 0.7900\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2725 - accuracy: 0.8955 - val_loss: 0.5825 - val_accuracy: 0.7633\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2382 - accuracy: 0.9182 - val_loss: 0.5578 - val_accuracy: 0.7778\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2559 - accuracy: 0.9073 - val_loss: 0.5020 - val_accuracy: 0.7933\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2174 - accuracy: 0.9261 - val_loss: 0.4878 - val_accuracy: 0.7922\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2181 - accuracy: 0.9285 - val_loss: 0.4695 - val_accuracy: 0.8078\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2415 - accuracy: 0.9121 - val_loss: 0.4923 - val_accuracy: 0.8044\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2153 - accuracy: 0.9236 - val_loss: 0.5012 - val_accuracy: 0.8022\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2187 - accuracy: 0.9215 - val_loss: 0.4952 - val_accuracy: 0.8067\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2187 - accuracy: 0.9203 - val_loss: 0.5622 - val_accuracy: 0.7867\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2290 - accuracy: 0.9142 - val_loss: 0.5373 - val_accuracy: 0.7922\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2778 - accuracy: 0.8909 - val_loss: 0.4996 - val_accuracy: 0.8033\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2045 - accuracy: 0.9303 - val_loss: 0.6239 - val_accuracy: 0.7722\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2116 - accuracy: 0.9270 - val_loss: 0.5346 - val_accuracy: 0.7878\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2106 - accuracy: 0.9248 - val_loss: 0.7918 - val_accuracy: 0.7344\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1952 - accuracy: 0.9315 - val_loss: 0.4791 - val_accuracy: 0.8089\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1833 - accuracy: 0.9327 - val_loss: 0.4942 - val_accuracy: 0.8067\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1839 - accuracy: 0.9379 - val_loss: 0.4641 - val_accuracy: 0.8233\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9385 - val_loss: 0.4887 - val_accuracy: 0.8111\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1754 - accuracy: 0.9430 - val_loss: 0.4694 - val_accuracy: 0.8156\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1686 - accuracy: 0.9467 - val_loss: 0.6124 - val_accuracy: 0.7778\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1833 - accuracy: 0.9327 - val_loss: 0.5015 - val_accuracy: 0.8078\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1703 - accuracy: 0.9442 - val_loss: 0.5878 - val_accuracy: 0.7867\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2373 - accuracy: 0.9097 - val_loss: 0.5411 - val_accuracy: 0.8067\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2245 - accuracy: 0.9145 - val_loss: 0.6820 - val_accuracy: 0.7356\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2400 - accuracy: 0.9030 - val_loss: 0.5837 - val_accuracy: 0.7933\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1546 - accuracy: 0.9497 - val_loss: 0.5413 - val_accuracy: 0.8100\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1757 - accuracy: 0.9367 - val_loss: 0.5391 - val_accuracy: 0.7944\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1781 - accuracy: 0.9358 - val_loss: 0.4784 - val_accuracy: 0.8222\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1592 - accuracy: 0.9470 - val_loss: 0.5604 - val_accuracy: 0.7878\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1536 - accuracy: 0.9479 - val_loss: 0.5367 - val_accuracy: 0.8033\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2436 - accuracy: 0.9021 - val_loss: 0.4958 - val_accuracy: 0.8056\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1578 - accuracy: 0.9467 - val_loss: 0.4795 - val_accuracy: 0.8200\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1494 - accuracy: 0.9497 - val_loss: 0.4674 - val_accuracy: 0.8233\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1383 - accuracy: 0.9536 - val_loss: 0.4871 - val_accuracy: 0.8222\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1543 - accuracy: 0.9442 - val_loss: 0.5345 - val_accuracy: 0.8011\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1165 - accuracy: 0.9652 - val_loss: 0.4759 - val_accuracy: 0.8156\n",
      "Epoch 102/150\n",
      "49/52 [===========================>..] - ETA: 0s - loss: 0.1211 - accuracy: 0.9630Restoring model weights from the end of the best epoch: 82.\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1237 - accuracy: 0.9615 - val_loss: 0.4830 - val_accuracy: 0.8233\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f906c210e50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3329 - accuracy: 0.8281"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.8233\n",
      "{'loss': 0.46408218145370483, 'accuracy': 0.8233333230018616}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: more parameters and different types of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 349, 12, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 345, 12, 16)       96        \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 172, 12, 16)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 172, 8, 16)        1296      \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 86, 8, 16)         0         \n",
      "                                                                 \n",
      " avg_pool (AveragePooling2D  (None, 2, 8, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                8224      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                1056      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10771 (42.07 KB)\n",
      "Trainable params: 10771 (42.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# create new CNN model\n",
    "input_layer = tf.keras.layers.Input(shape=mfcc_shape, name='input_layer')\n",
    "conv1 = tf.keras.layers.Conv2D(16, (5, 1), activation='relu', padding='same', name='conv1')(input_layer)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2, 1), name='pool1')(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(16, (1, 5), activation='relu', padding='same', name='conv2')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2, 1), name='pool2')(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv3')(pool2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(conv3)\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(21, 2), name='avg_pool')(pool3)\n",
    "flatten = tf.keras.layers.Flatten(name='flatten')(avg_pool)\n",
    "dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1', kernel_regularizer='l2')(flatten)\n",
    "dropout = tf.keras.layers.Dropout(0.3, name='dropout')(dense1)\n",
    "dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2', kernel_regularizer='l2')(dropout)\n",
    "output_layer = tf.keras.layers.Dense(len(classes), activation='softmax', name='output_layer')(dense2)\n",
    "'''\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=mfcc_shape, name='input_layer')\n",
    "conv1 = tf.keras.layers.Conv2D(16, (5, 1), activation='relu', padding='valid', name='conv1')(input_layer)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2, 1), name='pool1')(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(16, (1, 5), activation='relu', padding='valid', name='conv2')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2, 1), name='pool2')(conv2)\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(40, 1), name='avg_pool')(pool2)\n",
    "flatten = tf.keras.layers.Flatten(name='flatten')(avg_pool)\n",
    "\n",
    "dropout = tf.keras.layers.Dropout(0.3, name='dropout')(flatten)\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(32, activation='relu', name='dense1', kernel_regularizer='l2')(dropout)\n",
    "dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2', kernel_regularizer='l2')(dense1)\n",
    "output_layer = tf.keras.layers.Dense(len(classes), activation='softmax', name='output_layer')(dense2)\n",
    "\n",
    "model_2 = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.0004,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=2.5e-4,\n",
    "    power=0.3\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 15ms/step - loss: 3.5460 - accuracy: 0.3427 - lr: 3.9989e-04 - val_loss: 2.1296 - val_accuracy: 0.3133 - val_lr: 3.9977e-04\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 2.1760 - accuracy: 0.3530 - lr: 3.9965e-04 - val_loss: 1.9517 - val_accuracy: 0.3744 - val_lr: 3.9953e-04\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 2.0147 - accuracy: 0.3588 - lr: 3.9941e-04 - val_loss: 1.9232 - val_accuracy: 0.3722 - val_lr: 3.9930e-04\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.9582 - accuracy: 0.3455 - lr: 3.9918e-04 - val_loss: 1.8921 - val_accuracy: 0.4056 - val_lr: 3.9906e-04\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.9075 - accuracy: 0.3867 - lr: 3.9894e-04 - val_loss: 1.8698 - val_accuracy: 0.3811 - val_lr: 3.9882e-04\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8722 - accuracy: 0.3836 - lr: 3.9870e-04 - val_loss: 1.8350 - val_accuracy: 0.4311 - val_lr: 3.9859e-04\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.8366 - accuracy: 0.4079 - lr: 3.9846e-04 - val_loss: 1.8023 - val_accuracy: 0.4478 - val_lr: 3.9835e-04\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.8080 - accuracy: 0.4142 - lr: 3.9822e-04 - val_loss: 1.7713 - val_accuracy: 0.4300 - val_lr: 3.9810e-04\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.7739 - accuracy: 0.4179 - lr: 3.9798e-04 - val_loss: 1.7294 - val_accuracy: 0.5000 - val_lr: 3.9786e-04\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.7344 - accuracy: 0.4473 - lr: 3.9774e-04 - val_loss: 1.6887 - val_accuracy: 0.5367 - val_lr: 3.9762e-04\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.6992 - accuracy: 0.4548 - lr: 3.9750e-04 - val_loss: 1.6483 - val_accuracy: 0.5567 - val_lr: 3.9738e-04\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.6592 - accuracy: 0.4709 - lr: 3.9725e-04 - val_loss: 1.6072 - val_accuracy: 0.5900 - val_lr: 3.9713e-04\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.6296 - accuracy: 0.4779 - lr: 3.9701e-04 - val_loss: 1.5604 - val_accuracy: 0.5933 - val_lr: 3.9689e-04\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.5834 - accuracy: 0.5036 - lr: 3.9676e-04 - val_loss: 1.5177 - val_accuracy: 0.6122 - val_lr: 3.9664e-04\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.5489 - accuracy: 0.5264 - lr: 3.9652e-04 - val_loss: 1.4746 - val_accuracy: 0.6244 - val_lr: 3.9639e-04\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.5163 - accuracy: 0.5303 - lr: 3.9627e-04 - val_loss: 1.4377 - val_accuracy: 0.6322 - val_lr: 3.9615e-04\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.4797 - accuracy: 0.5503 - lr: 3.9602e-04 - val_loss: 1.4020 - val_accuracy: 0.6622 - val_lr: 3.9590e-04\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.4309 - accuracy: 0.5736 - lr: 3.9577e-04 - val_loss: 1.3586 - val_accuracy: 0.6444 - val_lr: 3.9565e-04\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.4062 - accuracy: 0.5776 - lr: 3.9552e-04 - val_loss: 1.3384 - val_accuracy: 0.6711 - val_lr: 3.9540e-04\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.3760 - accuracy: 0.5858 - lr: 3.9527e-04 - val_loss: 1.3029 - val_accuracy: 0.6756 - val_lr: 3.9514e-04\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.3340 - accuracy: 0.6073 - lr: 3.9501e-04 - val_loss: 1.2918 - val_accuracy: 0.6422 - val_lr: 3.9489e-04\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.3145 - accuracy: 0.6100 - lr: 3.9476e-04 - val_loss: 1.2446 - val_accuracy: 0.6833 - val_lr: 3.9464e-04\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.2809 - accuracy: 0.6291 - lr: 3.9451e-04 - val_loss: 1.2275 - val_accuracy: 0.6733 - val_lr: 3.9438e-04\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.2606 - accuracy: 0.6318 - lr: 3.9425e-04 - val_loss: 1.1997 - val_accuracy: 0.6767 - val_lr: 3.9412e-04\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.2352 - accuracy: 0.6315 - lr: 3.9399e-04 - val_loss: 1.1610 - val_accuracy: 0.6933 - val_lr: 3.9387e-04\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.1853 - accuracy: 0.6576 - lr: 3.9374e-04 - val_loss: 1.1256 - val_accuracy: 0.7011 - val_lr: 3.9361e-04\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.1695 - accuracy: 0.6597 - lr: 3.9348e-04 - val_loss: 1.1043 - val_accuracy: 0.6978 - val_lr: 3.9335e-04\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.1420 - accuracy: 0.6615 - lr: 3.9322e-04 - val_loss: 1.0961 - val_accuracy: 0.7000 - val_lr: 3.9309e-04\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.1198 - accuracy: 0.6667 - lr: 3.9296e-04 - val_loss: 1.0586 - val_accuracy: 0.7044 - val_lr: 3.9283e-04\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.1062 - accuracy: 0.6745 - lr: 3.9269e-04 - val_loss: 1.0639 - val_accuracy: 0.7067 - val_lr: 3.9256e-04\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0781 - accuracy: 0.6824 - lr: 3.9243e-04 - val_loss: 1.0199 - val_accuracy: 0.7211 - val_lr: 3.9230e-04\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.0522 - accuracy: 0.6930 - lr: 3.9216e-04 - val_loss: 0.9949 - val_accuracy: 0.7378 - val_lr: 3.9203e-04\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0300 - accuracy: 0.6870 - lr: 3.9190e-04 - val_loss: 0.9751 - val_accuracy: 0.7322 - val_lr: 3.9177e-04\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.0097 - accuracy: 0.6955 - lr: 3.9163e-04 - val_loss: 0.9750 - val_accuracy: 0.7211 - val_lr: 3.9150e-04\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.9931 - accuracy: 0.7067 - lr: 3.9136e-04 - val_loss: 0.9495 - val_accuracy: 0.7300 - val_lr: 3.9123e-04\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.9746 - accuracy: 0.6997 - lr: 3.9109e-04 - val_loss: 0.9373 - val_accuracy: 0.7233 - val_lr: 3.9096e-04\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9551 - accuracy: 0.7145 - lr: 3.9082e-04 - val_loss: 0.9055 - val_accuracy: 0.7456 - val_lr: 3.9069e-04\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.9321 - accuracy: 0.7252 - lr: 3.9055e-04 - val_loss: 0.8820 - val_accuracy: 0.7444 - val_lr: 3.9042e-04\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.9222 - accuracy: 0.7218 - lr: 3.9028e-04 - val_loss: 0.8852 - val_accuracy: 0.7400 - val_lr: 3.9015e-04\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.9042 - accuracy: 0.7345 - lr: 3.9001e-04 - val_loss: 0.8748 - val_accuracy: 0.7433 - val_lr: 3.8987e-04\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8946 - accuracy: 0.7245 - lr: 3.8973e-04 - val_loss: 0.8455 - val_accuracy: 0.7644 - val_lr: 3.8959e-04\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8761 - accuracy: 0.7324 - lr: 3.8945e-04 - val_loss: 0.8268 - val_accuracy: 0.7544 - val_lr: 3.8932e-04\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8631 - accuracy: 0.7373 - lr: 3.8917e-04 - val_loss: 0.8266 - val_accuracy: 0.7533 - val_lr: 3.8904e-04\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8507 - accuracy: 0.7524 - lr: 3.8890e-04 - val_loss: 0.8080 - val_accuracy: 0.7678 - val_lr: 3.8876e-04\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8321 - accuracy: 0.7530 - lr: 3.8861e-04 - val_loss: 0.7876 - val_accuracy: 0.7733 - val_lr: 3.8848e-04\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8192 - accuracy: 0.7524 - lr: 3.8833e-04 - val_loss: 0.7769 - val_accuracy: 0.7678 - val_lr: 3.8819e-04\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.8057 - accuracy: 0.7470 - lr: 3.8805e-04 - val_loss: 0.7622 - val_accuracy: 0.7778 - val_lr: 3.8791e-04\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7986 - accuracy: 0.7561 - lr: 3.8776e-04 - val_loss: 0.7625 - val_accuracy: 0.7856 - val_lr: 3.8762e-04\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7736 - accuracy: 0.7627 - lr: 3.8748e-04 - val_loss: 0.7442 - val_accuracy: 0.7778 - val_lr: 3.8734e-04\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7650 - accuracy: 0.7730 - lr: 3.8719e-04 - val_loss: 0.7643 - val_accuracy: 0.7700 - val_lr: 3.8705e-04\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7596 - accuracy: 0.7603 - lr: 3.8690e-04 - val_loss: 0.7339 - val_accuracy: 0.7933 - val_lr: 3.8676e-04\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7598 - accuracy: 0.7655 - lr: 3.8661e-04 - val_loss: 0.7249 - val_accuracy: 0.7933 - val_lr: 3.8647e-04\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7411 - accuracy: 0.7712 - lr: 3.8632e-04 - val_loss: 0.7273 - val_accuracy: 0.7789 - val_lr: 3.8618e-04\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7303 - accuracy: 0.7712 - lr: 3.8603e-04 - val_loss: 0.6961 - val_accuracy: 0.7922 - val_lr: 3.8588e-04\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7073 - accuracy: 0.7897 - lr: 3.8573e-04 - val_loss: 0.6982 - val_accuracy: 0.7944 - val_lr: 3.8559e-04\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.7042 - accuracy: 0.7812 - lr: 3.8544e-04 - val_loss: 0.6879 - val_accuracy: 0.8056 - val_lr: 3.8529e-04\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6952 - accuracy: 0.7852 - lr: 3.8514e-04 - val_loss: 0.6737 - val_accuracy: 0.7967 - val_lr: 3.8499e-04\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6860 - accuracy: 0.7915 - lr: 3.8484e-04 - val_loss: 0.6601 - val_accuracy: 0.8122 - val_lr: 3.8469e-04\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6854 - accuracy: 0.7861 - lr: 3.8454e-04 - val_loss: 0.6557 - val_accuracy: 0.8133 - val_lr: 3.8439e-04\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6643 - accuracy: 0.7909 - lr: 3.8424e-04 - val_loss: 0.6491 - val_accuracy: 0.8100 - val_lr: 3.8409e-04\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6575 - accuracy: 0.8033 - lr: 3.8393e-04 - val_loss: 0.6598 - val_accuracy: 0.8089 - val_lr: 3.8378e-04\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6752 - accuracy: 0.7939 - lr: 3.8363e-04 - val_loss: 0.6405 - val_accuracy: 0.8144 - val_lr: 3.8348e-04\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6496 - accuracy: 0.8036 - lr: 3.8332e-04 - val_loss: 0.6584 - val_accuracy: 0.7933 - val_lr: 3.8317e-04\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6290 - accuracy: 0.8136 - lr: 3.8301e-04 - val_loss: 0.6208 - val_accuracy: 0.8211 - val_lr: 3.8286e-04\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6409 - accuracy: 0.8027 - lr: 3.8270e-04 - val_loss: 0.6290 - val_accuracy: 0.8189 - val_lr: 3.8255e-04\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6344 - accuracy: 0.8024 - lr: 3.8239e-04 - val_loss: 0.6246 - val_accuracy: 0.8178 - val_lr: 3.8223e-04\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6184 - accuracy: 0.8118 - lr: 3.8207e-04 - val_loss: 0.6193 - val_accuracy: 0.8133 - val_lr: 3.8192e-04\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.6009 - accuracy: 0.8142 - lr: 3.8176e-04 - val_loss: 0.6079 - val_accuracy: 0.8222 - val_lr: 3.8160e-04\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6093 - accuracy: 0.8118 - lr: 3.8144e-04 - val_loss: 0.5991 - val_accuracy: 0.8211 - val_lr: 3.8128e-04\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6065 - accuracy: 0.8070 - lr: 3.8112e-04 - val_loss: 0.6440 - val_accuracy: 0.7900 - val_lr: 3.8096e-04\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5927 - accuracy: 0.8255 - lr: 3.8080e-04 - val_loss: 0.5910 - val_accuracy: 0.8267 - val_lr: 3.8064e-04\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.6030 - accuracy: 0.8142 - lr: 3.8048e-04 - val_loss: 0.6008 - val_accuracy: 0.8256 - val_lr: 3.8032e-04\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5853 - accuracy: 0.8270 - lr: 3.8015e-04 - val_loss: 0.5851 - val_accuracy: 0.8211 - val_lr: 3.7999e-04\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5730 - accuracy: 0.8191 - lr: 3.7982e-04 - val_loss: 0.5708 - val_accuracy: 0.8400 - val_lr: 3.7966e-04\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5634 - accuracy: 0.8348 - lr: 3.7950e-04 - val_loss: 0.5716 - val_accuracy: 0.8300 - val_lr: 3.7933e-04\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5670 - accuracy: 0.8300 - lr: 3.7916e-04 - val_loss: 0.5614 - val_accuracy: 0.8344 - val_lr: 3.7900e-04\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5657 - accuracy: 0.8306 - lr: 3.7883e-04 - val_loss: 0.5718 - val_accuracy: 0.8267 - val_lr: 3.7867e-04\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5600 - accuracy: 0.8324 - lr: 3.7850e-04 - val_loss: 0.5678 - val_accuracy: 0.8244 - val_lr: 3.7833e-04\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5468 - accuracy: 0.8382 - lr: 3.7816e-04 - val_loss: 0.5681 - val_accuracy: 0.8200 - val_lr: 3.7799e-04\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5568 - accuracy: 0.8303 - lr: 3.7782e-04 - val_loss: 0.5629 - val_accuracy: 0.8267 - val_lr: 3.7765e-04\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5444 - accuracy: 0.8391 - lr: 3.7748e-04 - val_loss: 0.5690 - val_accuracy: 0.8189 - val_lr: 3.7731e-04\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5287 - accuracy: 0.8412 - lr: 3.7714e-04 - val_loss: 0.5525 - val_accuracy: 0.8344 - val_lr: 3.7697e-04\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5320 - accuracy: 0.8394 - lr: 3.7679e-04 - val_loss: 0.5657 - val_accuracy: 0.8156 - val_lr: 3.7662e-04\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5325 - accuracy: 0.8397 - lr: 3.7644e-04 - val_loss: 0.5423 - val_accuracy: 0.8400 - val_lr: 3.7627e-04\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5289 - accuracy: 0.8379 - lr: 3.7610e-04 - val_loss: 0.5413 - val_accuracy: 0.8322 - val_lr: 3.7592e-04\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5082 - accuracy: 0.8509 - lr: 3.7574e-04 - val_loss: 0.5517 - val_accuracy: 0.8356 - val_lr: 3.7557e-04\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5170 - accuracy: 0.8427 - lr: 3.7539e-04 - val_loss: 0.5376 - val_accuracy: 0.8344 - val_lr: 3.7521e-04\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5041 - accuracy: 0.8433 - lr: 3.7503e-04 - val_loss: 0.5593 - val_accuracy: 0.8256 - val_lr: 3.7486e-04\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4918 - accuracy: 0.8576 - lr: 3.7467e-04 - val_loss: 0.5364 - val_accuracy: 0.8444 - val_lr: 3.7450e-04\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4989 - accuracy: 0.8503 - lr: 3.7431e-04 - val_loss: 0.5257 - val_accuracy: 0.8478 - val_lr: 3.7413e-04\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4889 - accuracy: 0.8576 - lr: 3.7395e-04 - val_loss: 0.6044 - val_accuracy: 0.7867 - val_lr: 3.7377e-04\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.5057 - accuracy: 0.8491 - lr: 3.7358e-04 - val_loss: 0.5150 - val_accuracy: 0.8467 - val_lr: 3.7340e-04\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4968 - accuracy: 0.8582 - lr: 3.7321e-04 - val_loss: 0.5203 - val_accuracy: 0.8333 - val_lr: 3.7303e-04\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4744 - accuracy: 0.8606 - lr: 3.7284e-04 - val_loss: 0.5650 - val_accuracy: 0.8244 - val_lr: 3.7266e-04\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4940 - accuracy: 0.8497 - lr: 3.7247e-04 - val_loss: 0.5222 - val_accuracy: 0.8456 - val_lr: 3.7228e-04\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4729 - accuracy: 0.8676 - lr: 3.7209e-04 - val_loss: 0.5176 - val_accuracy: 0.8456 - val_lr: 3.7190e-04\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4688 - accuracy: 0.8618 - lr: 3.7171e-04 - val_loss: 0.5350 - val_accuracy: 0.8244 - val_lr: 3.7152e-04\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4758 - accuracy: 0.8579 - lr: 3.7133e-04 - val_loss: 0.5211 - val_accuracy: 0.8467 - val_lr: 3.7114e-04\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4698 - accuracy: 0.8594 - lr: 3.7094e-04 - val_loss: 0.5180 - val_accuracy: 0.8500 - val_lr: 3.7075e-04\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4644 - accuracy: 0.8661 - lr: 3.7055e-04 - val_loss: 0.5148 - val_accuracy: 0.8489 - val_lr: 3.7036e-04\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4662 - accuracy: 0.8600 - lr: 3.7016e-04 - val_loss: 0.5329 - val_accuracy: 0.8322 - val_lr: 3.6997e-04\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4439 - accuracy: 0.8770 - lr: 3.6977e-04 - val_loss: 0.5081 - val_accuracy: 0.8467 - val_lr: 3.6957e-04\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4527 - accuracy: 0.8670 - lr: 3.6937e-04 - val_loss: 0.5072 - val_accuracy: 0.8456 - val_lr: 3.6918e-04\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4559 - accuracy: 0.8688 - lr: 3.6897e-04 - val_loss: 0.5138 - val_accuracy: 0.8411 - val_lr: 3.6877e-04\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4552 - accuracy: 0.8661 - lr: 3.6857e-04 - val_loss: 0.5300 - val_accuracy: 0.8367 - val_lr: 3.6837e-04\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4539 - accuracy: 0.8670 - lr: 3.6816e-04 - val_loss: 0.5108 - val_accuracy: 0.8444 - val_lr: 3.6796e-04\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4402 - accuracy: 0.8815 - lr: 3.6775e-04 - val_loss: 0.5020 - val_accuracy: 0.8389 - val_lr: 3.6755e-04\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4417 - accuracy: 0.8682 - lr: 3.6734e-04 - val_loss: 0.5096 - val_accuracy: 0.8456 - val_lr: 3.6713e-04\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4356 - accuracy: 0.8779 - lr: 3.6692e-04 - val_loss: 0.4954 - val_accuracy: 0.8478 - val_lr: 3.6672e-04\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4253 - accuracy: 0.8830 - lr: 3.6650e-04 - val_loss: 0.4798 - val_accuracy: 0.8556 - val_lr: 3.6629e-04\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4310 - accuracy: 0.8718 - lr: 3.6608e-04 - val_loss: 0.5130 - val_accuracy: 0.8322 - val_lr: 3.6587e-04\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4342 - accuracy: 0.8748 - lr: 3.6565e-04 - val_loss: 0.5197 - val_accuracy: 0.8433 - val_lr: 3.6544e-04\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4347 - accuracy: 0.8779 - lr: 3.6522e-04 - val_loss: 0.5159 - val_accuracy: 0.8378 - val_lr: 3.6501e-04\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4370 - accuracy: 0.8745 - lr: 3.6478e-04 - val_loss: 0.4928 - val_accuracy: 0.8489 - val_lr: 3.6457e-04\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4261 - accuracy: 0.8721 - lr: 3.6434e-04 - val_loss: 0.4830 - val_accuracy: 0.8489 - val_lr: 3.6413e-04\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4314 - accuracy: 0.8776 - lr: 3.6390e-04 - val_loss: 0.4703 - val_accuracy: 0.8656 - val_lr: 3.6368e-04\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4147 - accuracy: 0.8806 - lr: 3.6345e-04 - val_loss: 0.5138 - val_accuracy: 0.8444 - val_lr: 3.6323e-04\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4058 - accuracy: 0.8818 - lr: 3.6300e-04 - val_loss: 0.4690 - val_accuracy: 0.8522 - val_lr: 3.6278e-04\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4060 - accuracy: 0.8855 - lr: 3.6255e-04 - val_loss: 0.4800 - val_accuracy: 0.8478 - val_lr: 3.6232e-04\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4095 - accuracy: 0.8876 - lr: 3.6209e-04 - val_loss: 0.4914 - val_accuracy: 0.8411 - val_lr: 3.6186e-04\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4098 - accuracy: 0.8833 - lr: 3.6162e-04 - val_loss: 0.5013 - val_accuracy: 0.8344 - val_lr: 3.6140e-04\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4140 - accuracy: 0.8806 - lr: 3.6116e-04 - val_loss: 0.4699 - val_accuracy: 0.8511 - val_lr: 3.6092e-04\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3974 - accuracy: 0.8888 - lr: 3.6068e-04 - val_loss: 0.4900 - val_accuracy: 0.8544 - val_lr: 3.6045e-04\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3987 - accuracy: 0.8894 - lr: 3.6020e-04 - val_loss: 0.4680 - val_accuracy: 0.8622 - val_lr: 3.5997e-04\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4173 - accuracy: 0.8797 - lr: 3.5972e-04 - val_loss: 0.4897 - val_accuracy: 0.8444 - val_lr: 3.5948e-04\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4006 - accuracy: 0.8861 - lr: 3.5923e-04 - val_loss: 0.4986 - val_accuracy: 0.8567 - val_lr: 3.5899e-04\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3965 - accuracy: 0.8891 - lr: 3.5874e-04 - val_loss: 0.4977 - val_accuracy: 0.8456 - val_lr: 3.5850e-04\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.4015 - accuracy: 0.8879 - lr: 3.5824e-04 - val_loss: 0.4707 - val_accuracy: 0.8556 - val_lr: 3.5800e-04\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3924 - accuracy: 0.8933 - lr: 3.5774e-04 - val_loss: 0.4821 - val_accuracy: 0.8500 - val_lr: 3.5749e-04\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3907 - accuracy: 0.8927 - lr: 3.5723e-04 - val_loss: 0.5076 - val_accuracy: 0.8311 - val_lr: 3.5698e-04\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3860 - accuracy: 0.8939 - lr: 3.5671e-04 - val_loss: 0.4716 - val_accuracy: 0.8633 - val_lr: 3.5646e-04\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3668 - accuracy: 0.8967 - lr: 3.5619e-04 - val_loss: 0.4632 - val_accuracy: 0.8633 - val_lr: 3.5594e-04\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3845 - accuracy: 0.8933 - lr: 3.5567e-04 - val_loss: 0.4666 - val_accuracy: 0.8511 - val_lr: 3.5541e-04\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3720 - accuracy: 0.9000 - lr: 3.5513e-04 - val_loss: 0.4990 - val_accuracy: 0.8333 - val_lr: 3.5487e-04\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3764 - accuracy: 0.8948 - lr: 3.5459e-04 - val_loss: 0.4960 - val_accuracy: 0.8433 - val_lr: 3.5433e-04\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3751 - accuracy: 0.8973 - lr: 3.5405e-04 - val_loss: 0.4929 - val_accuracy: 0.8533 - val_lr: 3.5378e-04\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3709 - accuracy: 0.8973 - lr: 3.5350e-04 - val_loss: 0.4747 - val_accuracy: 0.8500 - val_lr: 3.5322e-04\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3794 - accuracy: 0.8942 - lr: 3.5294e-04 - val_loss: 0.4772 - val_accuracy: 0.8478 - val_lr: 3.5266e-04\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3641 - accuracy: 0.9036 - lr: 3.5237e-04 - val_loss: 0.4579 - val_accuracy: 0.8600 - val_lr: 3.5209e-04\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3575 - accuracy: 0.9042 - lr: 3.5179e-04 - val_loss: 0.4859 - val_accuracy: 0.8511 - val_lr: 3.5151e-04\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3791 - accuracy: 0.8945 - lr: 3.5121e-04 - val_loss: 0.4906 - val_accuracy: 0.8533 - val_lr: 3.5092e-04\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3638 - accuracy: 0.9006 - lr: 3.5062e-04 - val_loss: 0.4962 - val_accuracy: 0.8400 - val_lr: 3.5033e-04\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3711 - accuracy: 0.8933 - lr: 3.5002e-04 - val_loss: 0.4630 - val_accuracy: 0.8678 - val_lr: 3.4973e-04\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3564 - accuracy: 0.9067 - lr: 3.4942e-04 - val_loss: 0.4670 - val_accuracy: 0.8578 - val_lr: 3.4912e-04\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3597 - accuracy: 0.9033 - lr: 3.4880e-04 - val_loss: 0.4662 - val_accuracy: 0.8589 - val_lr: 3.4850e-04\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3571 - accuracy: 0.9033 - lr: 3.4818e-04 - val_loss: 0.4771 - val_accuracy: 0.8533 - val_lr: 3.4787e-04\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3485 - accuracy: 0.9094 - lr: 3.4754e-04 - val_loss: 0.4642 - val_accuracy: 0.8567 - val_lr: 3.4723e-04\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.3685 - accuracy: 0.8976 - lr: 3.4690e-04 - val_loss: 0.4521 - val_accuracy: 0.8611 - val_lr: 3.4658e-04\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3704 - accuracy: 0.9009 - lr: 3.4625e-04 - val_loss: 0.5084 - val_accuracy: 0.8411 - val_lr: 3.4592e-04\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3636 - accuracy: 0.9030 - lr: 3.4558e-04 - val_loss: 0.4801 - val_accuracy: 0.8533 - val_lr: 3.4525e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f907471b890>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model 2\n",
    "model_2.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4512 - accuracy: 0.8438 - lr: 3.4525e-04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.8533 - lr: 3.4525e-04\n",
      "{'loss': 0.4800722897052765, 'accuracy': 0.8533333539962769, 'lr': 0.000345252628903836}\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "[[0.79333333 0.09666667 0.11      ]\n",
      " [0.13       0.79333333 0.07666667]\n",
      " [0.01666667 0.01       0.97333333]]\n"
     ]
    }
   ],
   "source": [
    "evaluation_2 = model_2.evaluate(val_dataset, batch_size=32)\n",
    "evaluation_2 = dict(zip(model_2.metrics_names, evaluation_2))\n",
    "print(evaluation_2)\n",
    "\n",
    "\n",
    "# print model_3's confusion matrix\n",
    "model_2_pred = model_2.predict(val_dataset)\n",
    "model_2_pred = np.argmax(model_2_pred, axis=1)\n",
    "\n",
    "model_2_true = np.concatenate([y for x, y in val_dataset], axis=0)\n",
    "model_2_true = np.argmax(model_2_true, axis=1)\n",
    "model_2_cm = confusion_matrix(model_2_true, model_2_pred, labels=[0, 1, 2])\n",
    "# normalize the cm to have sum 1 on each row\n",
    "model_2_cm = model_2_cm.astype('float') / model_2_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(model_2_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: with residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)    [(None, 349, 12, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 349, 12, 16)          96        ['input_layer[0][0]']         \n",
      "                                                                                                  \n",
      " add1 (Add)                  (None, 349, 12, 16)          0         ['input_layer[0][0]',         \n",
      "                                                                     'conv1[0][0]']               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)        (None, 174, 12, 16)          0         ['add1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)              (None, 174, 12, 16)          1296      ['pool1[0][0]']               \n",
      "                                                                                                  \n",
      " add2 (Add)                  (None, 174, 12, 16)          0         ['pool1[0][0]',               \n",
      "                                                                     'conv2[0][0]']               \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)        (None, 87, 12, 16)           0         ['add2[0][0]']                \n",
      "                                                                                                  \n",
      " conv33 (Conv2D)             (None, 87, 12, 16)           272       ['pool2[0][0]']               \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)              (None, 87, 12, 16)           2320      ['pool2[0][0]']               \n",
      "                                                                                                  \n",
      " add3 (Add)                  (None, 87, 12, 16)           0         ['conv33[0][0]',              \n",
      "                                                                     'conv3[0][0]']               \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D  (None, 4, 6, 16)             0         ['add3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 384)                  0         ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 64)                   24640     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 32)                   2080      ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " output_layer (Dense)        (None, 3)                    99        ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30803 (120.32 KB)\n",
      "Trainable params: 30803 (120.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create CNN with residual connections\n",
    "input_layer = tf.keras.layers.Input(shape=mfcc_shape, name='input_layer')\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(16, (5, 1), activation='relu', padding='same', name='conv1')(input_layer)\n",
    "conv11 = tf.keras.layers.Conv2D(16, (1, 1), activation='relu', padding='same', name='conv11')(input_layer)\n",
    "add1 = tf.keras.layers.Add(name='add1')([input_layer, conv1])\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2, 1), name='pool1')(add1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(16, (1, 5), activation='relu', padding='same', name='conv2')(pool1)\n",
    "conv22 = tf.keras.layers.Conv2D(16, (1, 1), activation='relu', padding='same', name='conv22')(pool1)\n",
    "add2 = tf.keras.layers.Add(name='add2')([pool1, conv2])\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2, 1), name='pool2')(add2)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv3')(pool2)\n",
    "conv33 = tf.keras.layers.Conv2D(16, (1, 1), activation='relu', padding='same', name='conv33')(pool2)\n",
    "add3 = tf.keras.layers.Add(name='add3')([conv33, conv3])\n",
    "pool3 = tf.keras.layers.MaxPooling2D((2, 1), name='pool3')(add3)\n",
    "\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(21, 2), name='avg_pool')(add3)\n",
    "flatten = tf.keras.layers.Flatten(name='flatten')(avg_pool)\n",
    "\n",
    "# dropout = tf.keras.layers.Dropout(0.3, name='dropout')(flatten)\n",
    "dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1', kernel_regularizer='l2')(flatten)\n",
    "dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2', kernel_regularizer='l2')(dense1)\n",
    "output_layer = tf.keras.layers.Dense(len(classes), activation='softmax', name='output_layer')(dense2)\n",
    "\n",
    "\n",
    "model_3 = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.0008,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=5e-4,\n",
    "    power=0.3\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 3s 20ms/step - loss: 12.1498 - accuracy: 0.3552 - lr: 7.9977e-04 - val_loss: 4.1026 - val_accuracy: 0.3633 - val_lr: 7.9954e-04\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 3.3232 - accuracy: 0.3973 - lr: 7.9930e-04 - val_loss: 3.2925 - val_accuracy: 0.3733 - val_lr: 7.9907e-04\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.8681 - accuracy: 0.4064 - lr: 7.9883e-04 - val_loss: 2.8614 - val_accuracy: 0.3944 - val_lr: 7.9860e-04\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.5523 - accuracy: 0.4227 - lr: 7.9836e-04 - val_loss: 2.5529 - val_accuracy: 0.4489 - val_lr: 7.9812e-04\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.4767 - accuracy: 0.4552 - lr: 7.9788e-04 - val_loss: 2.4830 - val_accuracy: 0.4600 - val_lr: 7.9765e-04\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.3291 - accuracy: 0.4742 - lr: 7.9740e-04 - val_loss: 2.2905 - val_accuracy: 0.4878 - val_lr: 7.9717e-04\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.2738 - accuracy: 0.4806 - lr: 7.9693e-04 - val_loss: 2.5038 - val_accuracy: 0.3922 - val_lr: 7.9669e-04\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.1874 - accuracy: 0.4991 - lr: 7.9645e-04 - val_loss: 2.1779 - val_accuracy: 0.5033 - val_lr: 7.9621e-04\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.1586 - accuracy: 0.5045 - lr: 7.9596e-04 - val_loss: 2.1268 - val_accuracy: 0.5044 - val_lr: 7.9573e-04\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 2.1090 - accuracy: 0.5073 - lr: 7.9548e-04 - val_loss: 2.0883 - val_accuracy: 0.5011 - val_lr: 7.9524e-04\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 2.0332 - accuracy: 0.5385 - lr: 7.9499e-04 - val_loss: 2.1115 - val_accuracy: 0.5133 - val_lr: 7.9475e-04\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.0560 - accuracy: 0.5288 - lr: 7.9451e-04 - val_loss: 2.1635 - val_accuracy: 0.4589 - val_lr: 7.9427e-04\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 2.0992 - accuracy: 0.5003 - lr: 7.9402e-04 - val_loss: 1.9563 - val_accuracy: 0.5522 - val_lr: 7.9378e-04\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.9592 - accuracy: 0.5452 - lr: 7.9352e-04 - val_loss: 1.9571 - val_accuracy: 0.5456 - val_lr: 7.9328e-04\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8982 - accuracy: 0.5721 - lr: 7.9303e-04 - val_loss: 2.0946 - val_accuracy: 0.4611 - val_lr: 7.9279e-04\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8861 - accuracy: 0.5579 - lr: 7.9254e-04 - val_loss: 1.8781 - val_accuracy: 0.5744 - val_lr: 7.9229e-04\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8580 - accuracy: 0.5688 - lr: 7.9204e-04 - val_loss: 1.8566 - val_accuracy: 0.5700 - val_lr: 7.9179e-04\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.8245 - accuracy: 0.5770 - lr: 7.9154e-04 - val_loss: 1.9372 - val_accuracy: 0.5211 - val_lr: 7.9129e-04\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.7831 - accuracy: 0.5970 - lr: 7.9104e-04 - val_loss: 1.8114 - val_accuracy: 0.5800 - val_lr: 7.9079e-04\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.7524 - accuracy: 0.6045 - lr: 7.9053e-04 - val_loss: 1.7994 - val_accuracy: 0.5711 - val_lr: 7.9029e-04\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.7636 - accuracy: 0.5955 - lr: 7.9003e-04 - val_loss: 1.7987 - val_accuracy: 0.5733 - val_lr: 7.8978e-04\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.7453 - accuracy: 0.5915 - lr: 7.8952e-04 - val_loss: 1.9639 - val_accuracy: 0.5278 - val_lr: 7.8927e-04\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.7561 - accuracy: 0.5833 - lr: 7.8901e-04 - val_loss: 1.7732 - val_accuracy: 0.5511 - val_lr: 7.8876e-04\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.6656 - accuracy: 0.6239 - lr: 7.8850e-04 - val_loss: 1.7798 - val_accuracy: 0.5789 - val_lr: 7.8825e-04\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.6445 - accuracy: 0.6248 - lr: 7.8799e-04 - val_loss: 1.6969 - val_accuracy: 0.5944 - val_lr: 7.8773e-04\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.6435 - accuracy: 0.6215 - lr: 7.8747e-04 - val_loss: 1.6595 - val_accuracy: 0.6089 - val_lr: 7.8722e-04\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.6355 - accuracy: 0.6115 - lr: 7.8695e-04 - val_loss: 1.6744 - val_accuracy: 0.5967 - val_lr: 7.8670e-04\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.6550 - accuracy: 0.6079 - lr: 7.8643e-04 - val_loss: 1.6257 - val_accuracy: 0.6189 - val_lr: 7.8618e-04\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5568 - accuracy: 0.6397 - lr: 7.8591e-04 - val_loss: 1.6140 - val_accuracy: 0.6144 - val_lr: 7.8565e-04\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5294 - accuracy: 0.6512 - lr: 7.8539e-04 - val_loss: 1.5941 - val_accuracy: 0.6189 - val_lr: 7.8513e-04\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5361 - accuracy: 0.6415 - lr: 7.8486e-04 - val_loss: 1.6591 - val_accuracy: 0.5878 - val_lr: 7.8460e-04\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5229 - accuracy: 0.6400 - lr: 7.8433e-04 - val_loss: 1.5872 - val_accuracy: 0.6022 - val_lr: 7.8407e-04\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5141 - accuracy: 0.6403 - lr: 7.8380e-04 - val_loss: 1.6527 - val_accuracy: 0.5711 - val_lr: 7.8354e-04\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.4980 - accuracy: 0.6336 - lr: 7.8326e-04 - val_loss: 1.6502 - val_accuracy: 0.5300 - val_lr: 7.8300e-04\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5164 - accuracy: 0.6239 - lr: 7.8273e-04 - val_loss: 1.5148 - val_accuracy: 0.6411 - val_lr: 7.8246e-04\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.5336 - accuracy: 0.6109 - lr: 7.8219e-04 - val_loss: 1.5176 - val_accuracy: 0.6233 - val_lr: 7.8192e-04\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.4846 - accuracy: 0.6315 - lr: 7.8165e-04 - val_loss: 1.5116 - val_accuracy: 0.6111 - val_lr: 7.8138e-04\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.4200 - accuracy: 0.6585 - lr: 7.8110e-04 - val_loss: 1.5120 - val_accuracy: 0.6211 - val_lr: 7.8084e-04\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.4161 - accuracy: 0.6427 - lr: 7.8056e-04 - val_loss: 1.4659 - val_accuracy: 0.6222 - val_lr: 7.8029e-04\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3932 - accuracy: 0.6621 - lr: 7.8001e-04 - val_loss: 1.4336 - val_accuracy: 0.6478 - val_lr: 7.7974e-04\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3803 - accuracy: 0.6600 - lr: 7.7946e-04 - val_loss: 1.6016 - val_accuracy: 0.5800 - val_lr: 7.7919e-04\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3593 - accuracy: 0.6633 - lr: 7.7891e-04 - val_loss: 1.3998 - val_accuracy: 0.6556 - val_lr: 7.7863e-04\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3353 - accuracy: 0.6682 - lr: 7.7835e-04 - val_loss: 1.4443 - val_accuracy: 0.6211 - val_lr: 7.7808e-04\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3085 - accuracy: 0.6842 - lr: 7.7779e-04 - val_loss: 1.3848 - val_accuracy: 0.6400 - val_lr: 7.7752e-04\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3043 - accuracy: 0.6745 - lr: 7.7723e-04 - val_loss: 1.6853 - val_accuracy: 0.5456 - val_lr: 7.7695e-04\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3451 - accuracy: 0.6588 - lr: 7.7667e-04 - val_loss: 1.3582 - val_accuracy: 0.6600 - val_lr: 7.7639e-04\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2924 - accuracy: 0.6724 - lr: 7.7610e-04 - val_loss: 1.3371 - val_accuracy: 0.6611 - val_lr: 7.7582e-04\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.3091 - accuracy: 0.6627 - lr: 7.7553e-04 - val_loss: 1.5368 - val_accuracy: 0.5344 - val_lr: 7.7525e-04\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2899 - accuracy: 0.6661 - lr: 7.7496e-04 - val_loss: 1.4266 - val_accuracy: 0.5833 - val_lr: 7.7468e-04\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2479 - accuracy: 0.6712 - lr: 7.7438e-04 - val_loss: 1.4084 - val_accuracy: 0.6022 - val_lr: 7.7410e-04\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2291 - accuracy: 0.6748 - lr: 7.7380e-04 - val_loss: 1.3060 - val_accuracy: 0.6478 - val_lr: 7.7352e-04\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2167 - accuracy: 0.6915 - lr: 7.7322e-04 - val_loss: 1.2873 - val_accuracy: 0.6533 - val_lr: 7.7294e-04\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2515 - accuracy: 0.6615 - lr: 7.7264e-04 - val_loss: 1.2964 - val_accuracy: 0.6433 - val_lr: 7.7235e-04\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1919 - accuracy: 0.6912 - lr: 7.7205e-04 - val_loss: 1.3065 - val_accuracy: 0.6544 - val_lr: 7.7177e-04\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1724 - accuracy: 0.7015 - lr: 7.7146e-04 - val_loss: 1.2969 - val_accuracy: 0.6322 - val_lr: 7.7117e-04\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1752 - accuracy: 0.6945 - lr: 7.7087e-04 - val_loss: 1.3519 - val_accuracy: 0.6000 - val_lr: 7.7058e-04\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1673 - accuracy: 0.6867 - lr: 7.7028e-04 - val_loss: 1.6532 - val_accuracy: 0.5589 - val_lr: 7.6998e-04\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1701 - accuracy: 0.6764 - lr: 7.6968e-04 - val_loss: 1.2592 - val_accuracy: 0.6422 - val_lr: 7.6938e-04\n",
      "Epoch 59/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1232 - accuracy: 0.6961 - lr: 7.6908e-04 - val_loss: 1.1923 - val_accuracy: 0.6678 - val_lr: 7.6878e-04\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0867 - accuracy: 0.7158 - lr: 7.6847e-04 - val_loss: 1.1997 - val_accuracy: 0.6756 - val_lr: 7.6817e-04\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1274 - accuracy: 0.6915 - lr: 7.6786e-04 - val_loss: 1.1888 - val_accuracy: 0.6744 - val_lr: 7.6756e-04\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1010 - accuracy: 0.7015 - lr: 7.6725e-04 - val_loss: 1.2237 - val_accuracy: 0.6667 - val_lr: 7.6695e-04\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0900 - accuracy: 0.7052 - lr: 7.6664e-04 - val_loss: 1.4143 - val_accuracy: 0.5900 - val_lr: 7.6634e-04\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.1022 - accuracy: 0.6958 - lr: 7.6602e-04 - val_loss: 1.2108 - val_accuracy: 0.6556 - val_lr: 7.6572e-04\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0777 - accuracy: 0.7085 - lr: 7.6540e-04 - val_loss: 1.2178 - val_accuracy: 0.6567 - val_lr: 7.6509e-04\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0459 - accuracy: 0.7088 - lr: 7.6477e-04 - val_loss: 1.1180 - val_accuracy: 0.6956 - val_lr: 7.6447e-04\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0193 - accuracy: 0.7221 - lr: 7.6415e-04 - val_loss: 1.1010 - val_accuracy: 0.6933 - val_lr: 7.6384e-04\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0268 - accuracy: 0.7148 - lr: 7.6351e-04 - val_loss: 1.1962 - val_accuracy: 0.6378 - val_lr: 7.6320e-04\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0360 - accuracy: 0.7127 - lr: 7.6288e-04 - val_loss: 1.1218 - val_accuracy: 0.6644 - val_lr: 7.6257e-04\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0427 - accuracy: 0.7012 - lr: 7.6224e-04 - val_loss: 1.0909 - val_accuracy: 0.6956 - val_lr: 7.6193e-04\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0142 - accuracy: 0.7194 - lr: 7.6160e-04 - val_loss: 1.2668 - val_accuracy: 0.6200 - val_lr: 7.6128e-04\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0429 - accuracy: 0.7021 - lr: 7.6095e-04 - val_loss: 1.0833 - val_accuracy: 0.7044 - val_lr: 7.6063e-04\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9905 - accuracy: 0.7170 - lr: 7.6030e-04 - val_loss: 1.0786 - val_accuracy: 0.6733 - val_lr: 7.5998e-04\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.9752 - accuracy: 0.7345 - lr: 7.5965e-04 - val_loss: 1.0818 - val_accuracy: 0.6744 - val_lr: 7.5933e-04\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9631 - accuracy: 0.7285 - lr: 7.5899e-04 - val_loss: 1.1884 - val_accuracy: 0.6422 - val_lr: 7.5867e-04\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.0044 - accuracy: 0.7048 - lr: 7.5833e-04 - val_loss: 1.1607 - val_accuracy: 0.6333 - val_lr: 7.5800e-04\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9972 - accuracy: 0.7079 - lr: 7.5766e-04 - val_loss: 1.0832 - val_accuracy: 0.6644 - val_lr: 7.5734e-04\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9635 - accuracy: 0.7079 - lr: 7.5699e-04 - val_loss: 1.1193 - val_accuracy: 0.6511 - val_lr: 7.5667e-04\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9846 - accuracy: 0.6997 - lr: 7.5632e-04 - val_loss: 1.0251 - val_accuracy: 0.6767 - val_lr: 7.5599e-04\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9147 - accuracy: 0.7500 - lr: 7.5564e-04 - val_loss: 1.1116 - val_accuracy: 0.6489 - val_lr: 7.5531e-04\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9555 - accuracy: 0.7152 - lr: 7.5496e-04 - val_loss: 1.0241 - val_accuracy: 0.6867 - val_lr: 7.5463e-04\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9351 - accuracy: 0.7197 - lr: 7.5428e-04 - val_loss: 1.0173 - val_accuracy: 0.6911 - val_lr: 7.5394e-04\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9000 - accuracy: 0.7333 - lr: 7.5358e-04 - val_loss: 1.0297 - val_accuracy: 0.6889 - val_lr: 7.5324e-04\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8796 - accuracy: 0.7421 - lr: 7.5289e-04 - val_loss: 1.0773 - val_accuracy: 0.6600 - val_lr: 7.5255e-04\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.9140 - accuracy: 0.7312 - lr: 7.5219e-04 - val_loss: 1.0414 - val_accuracy: 0.6744 - val_lr: 7.5185e-04\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8484 - accuracy: 0.7567 - lr: 7.5149e-04 - val_loss: 1.0540 - val_accuracy: 0.6689 - val_lr: 7.5114e-04\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8667 - accuracy: 0.7382 - lr: 7.5078e-04 - val_loss: 1.0448 - val_accuracy: 0.6744 - val_lr: 7.5043e-04\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8823 - accuracy: 0.7309 - lr: 7.5006e-04 - val_loss: 1.0011 - val_accuracy: 0.6733 - val_lr: 7.4971e-04\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8778 - accuracy: 0.7361 - lr: 7.4935e-04 - val_loss: 0.9592 - val_accuracy: 0.7100 - val_lr: 7.4899e-04\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8280 - accuracy: 0.7527 - lr: 7.4862e-04 - val_loss: 1.0216 - val_accuracy: 0.6778 - val_lr: 7.4827e-04\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8470 - accuracy: 0.7458 - lr: 7.4790e-04 - val_loss: 1.0472 - val_accuracy: 0.6611 - val_lr: 7.4754e-04\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8586 - accuracy: 0.7352 - lr: 7.4716e-04 - val_loss: 0.9864 - val_accuracy: 0.6833 - val_lr: 7.4680e-04\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8299 - accuracy: 0.7594 - lr: 7.4642e-04 - val_loss: 0.9818 - val_accuracy: 0.6956 - val_lr: 7.4606e-04\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8684 - accuracy: 0.7315 - lr: 7.4568e-04 - val_loss: 0.9593 - val_accuracy: 0.7011 - val_lr: 7.4531e-04\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8267 - accuracy: 0.7533 - lr: 7.4493e-04 - val_loss: 0.9611 - val_accuracy: 0.6978 - val_lr: 7.4456e-04\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8295 - accuracy: 0.7509 - lr: 7.4418e-04 - val_loss: 1.0259 - val_accuracy: 0.6922 - val_lr: 7.4381e-04\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7979 - accuracy: 0.7561 - lr: 7.4342e-04 - val_loss: 0.9185 - val_accuracy: 0.7256 - val_lr: 7.4305e-04\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7955 - accuracy: 0.7570 - lr: 7.4265e-04 - val_loss: 0.9740 - val_accuracy: 0.6878 - val_lr: 7.4228e-04\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7893 - accuracy: 0.7591 - lr: 7.4188e-04 - val_loss: 0.9923 - val_accuracy: 0.6700 - val_lr: 7.4150e-04\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7824 - accuracy: 0.7573 - lr: 7.4111e-04 - val_loss: 1.1412 - val_accuracy: 0.6133 - val_lr: 7.4072e-04\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.7807 - accuracy: 0.7621 - lr: 7.4032e-04 - val_loss: 0.9176 - val_accuracy: 0.7078 - val_lr: 7.3994e-04\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7799 - accuracy: 0.7606 - lr: 7.3954e-04 - val_loss: 0.9231 - val_accuracy: 0.6978 - val_lr: 7.3915e-04\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7764 - accuracy: 0.7645 - lr: 7.3874e-04 - val_loss: 0.9505 - val_accuracy: 0.6911 - val_lr: 7.3835e-04\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.8021 - accuracy: 0.7491 - lr: 7.3794e-04 - val_loss: 0.9453 - val_accuracy: 0.6878 - val_lr: 7.3755e-04\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7418 - accuracy: 0.7733 - lr: 7.3714e-04 - val_loss: 0.9417 - val_accuracy: 0.7056 - val_lr: 7.3674e-04\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7749 - accuracy: 0.7503 - lr: 7.3632e-04 - val_loss: 0.8949 - val_accuracy: 0.6922 - val_lr: 7.3592e-04\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7308 - accuracy: 0.7797 - lr: 7.3550e-04 - val_loss: 1.1442 - val_accuracy: 0.6311 - val_lr: 7.3510e-04\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7708 - accuracy: 0.7503 - lr: 7.3468e-04 - val_loss: 0.8895 - val_accuracy: 0.7189 - val_lr: 7.3427e-04\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7384 - accuracy: 0.7697 - lr: 7.3384e-04 - val_loss: 0.9166 - val_accuracy: 0.7133 - val_lr: 7.3343e-04\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7446 - accuracy: 0.7664 - lr: 7.3300e-04 - val_loss: 0.9486 - val_accuracy: 0.6744 - val_lr: 7.3259e-04\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7828 - accuracy: 0.7500 - lr: 7.3215e-04 - val_loss: 0.9660 - val_accuracy: 0.6911 - val_lr: 7.3174e-04\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7666 - accuracy: 0.7497 - lr: 7.3130e-04 - val_loss: 0.9694 - val_accuracy: 0.6967 - val_lr: 7.3088e-04\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7067 - accuracy: 0.7806 - lr: 7.3044e-04 - val_loss: 0.8709 - val_accuracy: 0.7233 - val_lr: 7.3001e-04\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7081 - accuracy: 0.7761 - lr: 7.2957e-04 - val_loss: 0.9591 - val_accuracy: 0.6967 - val_lr: 7.2914e-04\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6934 - accuracy: 0.7906 - lr: 7.2869e-04 - val_loss: 0.9611 - val_accuracy: 0.6844 - val_lr: 7.2826e-04\n",
      "Epoch 116/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6927 - accuracy: 0.7806 - lr: 7.2780e-04 - val_loss: 0.8638 - val_accuracy: 0.7133 - val_lr: 7.2737e-04\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.7375 - accuracy: 0.7615 - lr: 7.2691e-04 - val_loss: 0.9746 - val_accuracy: 0.6922 - val_lr: 7.2647e-04\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7304 - accuracy: 0.7639 - lr: 7.2601e-04 - val_loss: 0.9108 - val_accuracy: 0.6800 - val_lr: 7.2556e-04\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6999 - accuracy: 0.7815 - lr: 7.2510e-04 - val_loss: 0.9612 - val_accuracy: 0.6911 - val_lr: 7.2465e-04\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7104 - accuracy: 0.7736 - lr: 7.2418e-04 - val_loss: 1.0373 - val_accuracy: 0.6322 - val_lr: 7.2372e-04\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7599 - accuracy: 0.7533 - lr: 7.2325e-04 - val_loss: 0.9554 - val_accuracy: 0.7056 - val_lr: 7.2279e-04\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6883 - accuracy: 0.7776 - lr: 7.2231e-04 - val_loss: 0.9243 - val_accuracy: 0.7022 - val_lr: 7.2185e-04\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6841 - accuracy: 0.7800 - lr: 7.2137e-04 - val_loss: 0.8391 - val_accuracy: 0.7267 - val_lr: 7.2090e-04\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6718 - accuracy: 0.7833 - lr: 7.2041e-04 - val_loss: 0.9096 - val_accuracy: 0.7089 - val_lr: 7.1994e-04\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.6630 - accuracy: 0.7933 - lr: 7.1944e-04 - val_loss: 0.8999 - val_accuracy: 0.7033 - val_lr: 7.1897e-04\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.7117 - accuracy: 0.7721 - lr: 7.1847e-04 - val_loss: 0.9593 - val_accuracy: 0.6989 - val_lr: 7.1799e-04\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6829 - accuracy: 0.7770 - lr: 7.1748e-04 - val_loss: 0.9305 - val_accuracy: 0.6889 - val_lr: 7.1700e-04\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.6602 - accuracy: 0.7918 - lr: 7.1649e-04 - val_loss: 0.9132 - val_accuracy: 0.7011 - val_lr: 7.1599e-04\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.6674 - accuracy: 0.7806 - lr: 7.1548e-04 - val_loss: 0.9460 - val_accuracy: 0.6689 - val_lr: 7.1498e-04\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.6744 - accuracy: 0.7788 - lr: 7.1446e-04 - val_loss: 0.9671 - val_accuracy: 0.6656 - val_lr: 7.1396e-04\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6418 - accuracy: 0.8061 - lr: 7.1343e-04 - val_loss: 0.8376 - val_accuracy: 0.7189 - val_lr: 7.1292e-04\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6425 - accuracy: 0.8015 - lr: 7.1239e-04 - val_loss: 0.8614 - val_accuracy: 0.7178 - val_lr: 7.1187e-04\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6513 - accuracy: 0.7921 - lr: 7.1133e-04 - val_loss: 0.9145 - val_accuracy: 0.6967 - val_lr: 7.1081e-04\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6443 - accuracy: 0.7955 - lr: 7.1027e-04 - val_loss: 0.9173 - val_accuracy: 0.6767 - val_lr: 7.0974e-04\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6030 - accuracy: 0.8145 - lr: 7.0919e-04 - val_loss: 0.8773 - val_accuracy: 0.7100 - val_lr: 7.0866e-04\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6329 - accuracy: 0.8012 - lr: 7.0810e-04 - val_loss: 0.8848 - val_accuracy: 0.7044 - val_lr: 7.0756e-04\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6496 - accuracy: 0.7921 - lr: 7.0699e-04 - val_loss: 1.0230 - val_accuracy: 0.6556 - val_lr: 7.0644e-04\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6754 - accuracy: 0.7806 - lr: 7.0587e-04 - val_loss: 0.8482 - val_accuracy: 0.7200 - val_lr: 7.0532e-04\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6300 - accuracy: 0.7924 - lr: 7.0474e-04 - val_loss: 0.8476 - val_accuracy: 0.6967 - val_lr: 7.0418e-04\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6358 - accuracy: 0.7921 - lr: 7.0359e-04 - val_loss: 0.9472 - val_accuracy: 0.6956 - val_lr: 7.0302e-04\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6496 - accuracy: 0.7912 - lr: 7.0242e-04 - val_loss: 0.9053 - val_accuracy: 0.7056 - val_lr: 7.0185e-04\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6213 - accuracy: 0.8045 - lr: 7.0124e-04 - val_loss: 0.8180 - val_accuracy: 0.7233 - val_lr: 7.0066e-04\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 1s 17ms/step - loss: 0.6293 - accuracy: 0.7967 - lr: 7.0005e-04 - val_loss: 0.8537 - val_accuracy: 0.7244 - val_lr: 6.9946e-04\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6320 - accuracy: 0.7952 - lr: 6.9884e-04 - val_loss: 1.0231 - val_accuracy: 0.6778 - val_lr: 6.9823e-04\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6180 - accuracy: 0.8024 - lr: 6.9760e-04 - val_loss: 0.9669 - val_accuracy: 0.6600 - val_lr: 6.9699e-04\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6530 - accuracy: 0.7818 - lr: 6.9636e-04 - val_loss: 0.8490 - val_accuracy: 0.7222 - val_lr: 6.9574e-04\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5968 - accuracy: 0.8109 - lr: 6.9509e-04 - val_loss: 0.8320 - val_accuracy: 0.7244 - val_lr: 6.9446e-04\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.6122 - accuracy: 0.8000 - lr: 6.9380e-04 - val_loss: 1.0633 - val_accuracy: 0.6611 - val_lr: 6.9316e-04\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5960 - accuracy: 0.8067 - lr: 6.9249e-04 - val_loss: 0.8443 - val_accuracy: 0.7122 - val_lr: 6.9184e-04\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.5510 - accuracy: 0.8352 - lr: 6.9116e-04 - val_loss: 0.8340 - val_accuracy: 0.7144 - val_lr: 6.9051e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc497cca4d0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model 3\n",
    "model_3.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model_3.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7499 - accuracy: 0.7969 - lr: 6.3469e-04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 9ms/step - loss: 0.7339 - accuracy: 0.7844 - lr: 6.3469e-04\n",
      "{'loss': 0.7338971495628357, 'accuracy': 0.7844444513320923, 'lr': 0.0006346917361952364}\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "[[0.79333333 0.15666667 0.05      ]\n",
      " [0.22569444 0.69444444 0.07986111]\n",
      " [0.06410256 0.07692308 0.85897436]]\n"
     ]
    }
   ],
   "source": [
    "evaluation_3 = model_3.evaluate(val_dataset, batch_size=64)\n",
    "evaluation_3 = dict(zip(model_3.metrics_names, evaluation_3))\n",
    "print(evaluation_3)\n",
    "\n",
    "\n",
    "# print model_3's confusion matrix\n",
    "model_3_pred = model_3.predict(val_dataset)\n",
    "model_3_pred = np.argmax(model_3_pred, axis=1)\n",
    "\n",
    "model_3_true = np.concatenate([y for x, y in val_dataset], axis=0)\n",
    "model_3_true = np.argmax(model_3_true, axis=1)\n",
    "model_3_cm = confusion_matrix(model_3_true, model_3_pred, labels=[0, 1, 2])\n",
    "# normalize the cm to have sum 1 on each row\n",
    "model_3_cm = model_3_cm.astype('float') / model_3_cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(model_3_cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for evaluation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model_2.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 13:06:54.313180: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-23 13:06:54.313224: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-23 13:06:54.313415: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-23 13:06:54.315303: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-23 13:06:54.315410: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-23 13:06:54.324242: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-23 13:06:54.400769: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-23 13:06:54.418285: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 104870 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_dataset(num_samples = x_train.shape[0]):\n",
    "    for x, y in train_dataset.take(num_samples):\n",
    "    \tyield [tf.cast(x, dtype=tf.float32)]\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 21, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 3]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the TFLite model into a TFMicro model using the bash script below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simon/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate quantized model on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tflite_model_evaluation(x_test, y_onehot_test):\n",
    "\n",
    "\t# convert test set into int8\n",
    "\tx_test_int8 = tf.convert_to_tensor(tf.cast(x_test, tf.int8))\n",
    "\ty_test_int8 = tf.convert_to_tensor(tf.cast(y_onehot_test, tf.int8))\n",
    "\t# Convert the random data point from int8 to float32\n",
    "\tbatch_size = len(x_test_int8)\n",
    "\n",
    "\teval_shape = (1, mfcc_size[0], mfcc_size[1], 1)\n",
    "\tprint(\"x shape = \", x_test_int8.shape)\n",
    "\tprint(\"y shape =\", y_test_int8.shape)\n",
    "\n",
    "\tpredictions = np.empty( (y_test_int8.shape) )\n",
    "\n",
    "\tfor i in range(batch_size):\n",
    "\t\t# Set input data to the interpreter.\n",
    "\t\tinterpreter.set_tensor(input_details[0]['index'], tf.reshape(x_test_int8[i], eval_shape) )\n",
    "\n",
    "\t\t# Run inference.\n",
    "\t\tinterpreter.invoke()\n",
    "\n",
    "\t\t# Get output data from the interpreter.\n",
    "\t\toutput_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "\t\t# get quantization parameters from output_details\n",
    "\t\toutput_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "\t\t# scale and zero point dequantization to get probabilities\n",
    "\t\toutput_probability = tf.math.softmax(output_data / output_scale + output_zero_point)\n",
    "\t\tpredictions[i] = output_probability.numpy()\n",
    "\n",
    "\tmse_loss = np.sqrt( np.sum( (y_test_int8 - predictions)**2 ) ) / batch_size\n",
    "\taccuracy = np.sum( np.argmax(predictions, axis=1) == np.argmax(y_test_int8, axis=1) ) / batch_size\n",
    "\tprint(\"Accuracy in test set of quantized TFLite model: {:.4f}\".format(accuracy))\n",
    "\tprint(\"MSE loss in test set of quantized TFLite model: {:.4f}\".format(mse_loss))\n",
    "\n",
    "\t# print model's confusion matrix\n",
    "\tpredictions_class = np.argmax(predictions, axis=1)\n",
    "\ttrue_labels = np.argmax(y_test_int8, axis=1)\n",
    "\tcm = confusion_matrix(true_labels, predictions_class, labels=[0, 1, 2])\n",
    "\t# normalize the cm to have sum 1 on each row\n",
    "\tcm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\tprint(cm)\n",
    "\n",
    "\t# Plot the confusion matrix\n",
    "\tplt.imshow(cm, interpolation='nearest', cmap='viridis')\n",
    "\tplt.title('Confusion matrix')\n",
    "\tplt.colorbar()\n",
    "\ttick_marks = np.arange(len(classes))\n",
    "\tplt.xticks(tick_marks, classes)\n",
    "\tplt.yticks(tick_marks, classes)\n",
    "\tplt.xlabel('Predicted label')\n",
    "\tplt.ylabel('True label')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape =  (900, 349, 12, 1)\n",
      "y shape = (900, 3)\n",
      "Accuracy in test set of quantized TFLite model: 0.8533\n",
      "MSE loss in test set of quantized TFLite model: 0.0181\n",
      "[[0.79333333 0.09666667 0.11      ]\n",
      " [0.12666667 0.79333333 0.08      ]\n",
      " [0.01666667 0.01       0.97333333]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAHHCAYAAADaqqCfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6zElEQVR4nO3deXQUZdr38V8nkE6AJIBhDTEBIhEeligceNkMzIDxURD1qMCwBGRREWQRBVR2ISrDflQU2QcVBh0fNQxKgIgsjorighAlrKOsImGJSaC73j+Y9NhUgtV0Z+n093NOnZO+u+6qqxMxV657KZthGIYAAAB+J6i0AwAAAGUPCQIAADAhQQAAACYkCAAAwIQEAQAAmJAgAAAAExIEAABgQoIAAABMSBAAAIAJCQLgYz/++KNuv/12RUZGymaz6d133/Xp9Q8dOiSbzably5f79LrlQVxcnAYMGFDaYQDlAgkCyqWsrCw9/PDDatCggUJDQxUREaH27dtr/vz5+u2334r13ikpKfr22281Y8YMrVq1Sq1atSrW+5VH33//vaZMmaJDhw6VdihAwLLxLAaUN2lpaXrggQdkt9vVv39/NW3aVPn5+dq2bZvefvttDRgwQK+99lqx3Pu3335TpUqV9Mwzz+i5554rlnsYhqG8vDxVrFhRwcHBxXKP0rZu3To98MAD2rJlizp16mS5X15enoKCglSxYsXiCw4IEBVKOwDAlw4ePKhevXopNjZWmzdvVp06dVzvPfbYY9q/f7/S0tKK7f6nTp2SJFWtWrXY7mGz2RQaGlps1/c3hmEoNzdXYWFhstvtpR0OUG4wxIBy5cUXX9SFCxe0ZMkSt+SgQHx8vEaOHOl6ffnyZU2fPl0NGzaU3W5XXFycnn76aeXl5bn1i4uLU7du3bRt2za1bt1aoaGhatCggVauXOk6Z8qUKYqNjZUkPfnkk7LZbIqLi5MkDRgwwPX1702ZMkU2m82tbePGjerQoYOqVq2qKlWqKCEhQU8//bTr/aLmIGzevFkdO3ZU5cqVVbVqVfXo0UN79+4t9H779+/XgAEDVLVqVUVGRmrgwIHKyckp+hv7H506dVLTpk31zTffKCkpSZUqVVJ8fLzWrVsnSfr444/Vpk0bhYWFKSEhQenp6W79Dx8+rGHDhikhIUFhYWG64YYb9MADD7gNJSxfvlwPPPCAJKlz586y2Wyy2WzKyMiQ9N+fxYcffqhWrVopLCxMr776quu9gjkIhmGoc+fOqlGjhk6ePOm6fn5+vpo1a6aGDRvq4sWLf/iZgUBFgoBy5f3331eDBg3Url07S+cPHjxYkyZN0q233qq5c+cqKSlJqamp6tWrl+nc/fv36/7771fXrl01e/ZsVatWTQMGDNCePXskSffdd5/mzp0rSerdu7dWrVqlefPmeRT/nj171K1bN+Xl5WnatGmaPXu27r77bm3fvv2a/dLT05WcnKyTJ09qypQpGjNmjHbs2KH27dsXOo7/4IMP6vz580pNTdWDDz6o5cuXa+rUqZZi/PXXX9WtWze1adNGL774oux2u3r16qU1a9aoV69euvPOO/X888/r4sWLuv/++3X+/HlX388//1w7duxQr169tGDBAj3yyCPatGmTOnXq5EpQbrvtNj3++OOSpKefflqrVq3SqlWr1LhxY9d1MjMz1bt3b3Xt2lXz589XYmKiKU6bzaalS5cqNzdXjzzyiKt98uTJ2rNnj5YtW6bKlStb+sxAQDKAciI7O9uQZPTo0cPS+bt37zYkGYMHD3ZrHzt2rCHJ2Lx5s6stNjbWkGRs3brV1Xby5EnDbrcbTzzxhKvt4MGDhiRj1qxZbtdMSUkxYmNjTTFMnjzZ+P0/w7lz5xqSjFOnThUZd8E9li1b5mpLTEw0atasafzyyy+utq+//toICgoy+vfvb7rfQw895HbNe++917jhhhuKvGeBpKQkQ5LxxhtvuNr27dtnSDKCgoKMTz/91NX+4YcfmuLMyckxXXPnzp2GJGPlypWutr///e+GJGPLli2m8wt+Fhs2bCj0vZSUFLe2V1991ZBk/O1vfzM+/fRTIzg42Bg1atQfflYg0FFBQLlx7tw5SVJ4eLil89evXy9JGjNmjFv7E088IUmmuQpNmjRRx44dXa9r1KihhIQEHThw4LpjvlrB3IX/+7//k9PptNTn2LFj2r17twYMGKDq1au72ps3b66uXbu6Pufv/f4vaknq2LGjfvnlF9f38FqqVKniVmFJSEhQ1apV1bhxY7Vp08bVXvD1778/YWFhrq8vXbqkX375RfHx8apataq+/PJLC5/2ivr16ys5OdnSuUOHDlVycrJGjBihfv36qWHDhpo5c6blewGBigQB5UZERIQkuZW0r+Xw4cMKCgpSfHy8W3vt2rVVtWpVHT582K39xhtvNF2jWrVq+vXXX68zYrOePXuqffv2Gjx4sGrVqqVevXpp7dq110wWCuJMSEgwvde4cWOdPn3aNNZ+9WepVq2aJFn6LPXq1TPNm4iMjFRMTIyp7epr/vbbb5o0aZJiYmJkt9sVFRWlGjVq6OzZs8rOzv7DexeoX7++5XMlacmSJcrJydGPP/6o5cuXuyUqAApHgoByIyIiQnXr1tV3333nUb+rf9kVpaglhYaFlcJF3cPhcLi9DgsL09atW5Wenq5+/frpm2++Uc+ePdW1a1fTud7w5rMU1dfKNUeMGKEZM2bowQcf1Nq1a/XRRx9p48aNuuGGGyxXTCR5/As+IyPDNfH022+/9agvEKhIEFCudOvWTVlZWdq5c+cfnhsbGyun06kff/zRrf3EiRM6e/asa0WCL1SrVk1nz541tV9dpZCkoKAg/fnPf9acOXP0/fffa8aMGdq8ebO2bNlS6LUL4szMzDS9t2/fPkVFRZWZyXjr1q1TSkqKZs+e7Zrw2aFDB9P3xmrSZsWxY8c0YsQI3X777erWrZvGjh1b6PcdgDsSBJQrTz31lCpXrqzBgwfrxIkTpvezsrI0f/58SdKdd94pSaaVBnPmzJEk3XXXXT6Lq2HDhsrOztY333zjajt27Jj+8Y9/uJ135swZU9+CGfpXL70sUKdOHSUmJmrFihVuv2i/++47ffTRR67PWRYEBwebqhQLFy40VUcKEprCkipPDRkyRE6nU0uWLNFrr72mChUqaNCgQZaqJUAgY6MklCsNGzbUG2+8oZ49e6px48ZuOynu2LFDf//7313r5Fu0aKGUlBS99tprOnv2rJKSkvTZZ59pxYoVuueee9S5c2efxdWrVy+NGzdO9957rx5//HHl5OTolVdeUaNGjdwm502bNk1bt27VXXfdpdjYWJ08eVIvv/yy6tWrpw4dOhR5/VmzZul///d/1bZtWw0aNEi//fabFi5cqMjISE2ZMsVnn8Nb3bp106pVqxQZGakmTZpo586dSk9P1w033OB2XmJiooKDg/XCCy8oOztbdrtdf/rTn1SzZk2P7rds2TKlpaVp+fLlqlevnqQrCUnfvn31yiuvaNiwYT77bEC5U6prKIBi8sMPPxhDhgwx4uLijJCQECM8PNxo3769sXDhQiM3N9d13qVLl4ypU6ca9evXNypWrGjExMQYEyZMcDvHMK4sn7vrrrtM90lKSjKSkpJcr4ta5mgYhvHRRx8ZTZs2NUJCQoyEhATjb3/7m2mZ46ZNm4wePXoYdevWNUJCQoy6desavXv3Nn744QfTPX6/fNAwDCM9Pd1o3769ERYWZkRERBjdu3c3vv/+e7dzCu539TLKZcuWGZKMgwcPFvk9Lfi8//M//2NqL+r7I8l47LHHXK9//fVXY+DAgUZUVJRRpUoVIzk52di3b1+hyxMXL15sNGjQwAgODnZb8ljUvQreK7jO0aNHjcjISKN79+6m8+69916jcuXKxoEDB675eYFAxrMYAACACXMQAACACQkCAAAwIUEAAAAmJAgAAMCEBAEAAJiQIAAAAJOA3yjJ6XTq559/Vnh4uE+3dwUAlAzDMHT+/HnVrVtXQUHF93dvbm6u8vPzvb5OSEiIQkNDfRBR8Qr4BOHnn382PYUOAOB/jh496tox09dyc3NVP7aKjp/0/qFptWvX1sGDB8t8khDwCUJ4eLgkaWz6n2SvHPDfjnLvX71uKu0QUIKMIp4wifLlsjNPHx961fX/8+KQn5+v4ycdOrwrThHh11+lOHfeqdiWh5Sfn0+CUNYVDCvYK1dQaJWKpRwNiluFIHtph4ASRIIQWEpimLhKuE1Vwq//Pk75z1B2wCcIAABY5TCccnjxgAKH4fRdMMWMBAEAAIucMuTU9WcI3vQtaSxzBAAAJlQQAACwyCmnvBkk8K53ySJBAADAIodhyGFc/zCBN31LGkMMAADAhAoCAAAWBdIkRRIEAAAscsqQI0ASBIYYAACACRUEAAAsYogBAACYsIoBAAAENCoIAABY5PzP4U1/f0GCAACARQ4vVzF407ekkSAAAGCRw5CXT3P0XSzFjTkIAADAhAoCAAAWMQcBAACYOGWTQzav+vsLhhgAAIAJFQQAACxyGlcOb/r7CxIEAAAscng5xOBN35LGEAMAADChggAAgEWBVEEgQQAAwCKnYZPT8GIVgxd9SxpDDAAAwIQKAgAAFjHEAAAATBwKksOL4rvDh7EUNxIEAAAsMrycg2AwBwEAAPgzKggAAFjEHAQAAGDiMILkMLyYg+BHWy0zxAAAAEyoIAAAYJFTNjm9+NvaKf8pIZAgAABgUSDNQWCIAQAAmFBBAADAIu8nKTLEAABAuXNlDoIXD2tiiAEAAPgzKggAAFjk9PJZDKxiAACgHGIOAgAAMHEqKGD2QWAOAgAAMKGCAACARQ7DJocXj2z2pm9JI0EAAMAih5eTFB0MMQAAAH9GBQEAAIucRpCcXqxicLKKAQCA8ochBgAAENCoIAAAYJFT3q1EcPoulGJHggAAgEXeb5TkP4V7/4kUAACUGCoIAABY5P2zGPzn73ISBAAALHLKJqe8mYPgPzsplulUplOnTho1alRphwEAgKT/VhC8OfxFma4gvPPOO6pYsaIkKS4uTqNGjSJhAACgBJTpBKF69eqlHQIAAC7eb5TkPxWEMh1pwRBDp06ddPjwYY0ePVo2m00225UxnF9++UW9e/dWdHS0KlWqpGbNmunNN98s5agBAOWV07B5ffiLMp0gFHjnnXdUr149TZs2TceOHdOxY8ckSbm5uWrZsqXS0tL03XffaejQoerXr58+++yzUo4YAAD/VqaHGApUr15dwcHBCg8PV+3atV3t0dHRGjt2rOv1iBEj9OGHH2rt2rVq3bp1odfKy8tTXl6e6/W5c+eKL3AAQLni9HKIgY2SSojD4dD06dPVrFkzVa9eXVWqVNGHH36oI0eOFNknNTVVkZGRriMmJqYEIwYA+LOCpzl6c1yPl156SXFxcQoNDVWbNm3+sFI+b948JSQkKCwsTDExMRo9erRyc3M9uqdfJwizZs3S/PnzNW7cOG3ZskW7d+9WcnKy8vPzi+wzYcIEZWdnu46jR4+WYMQAAHhmzZo1GjNmjCZPnqwvv/xSLVq0UHJysk6ePFno+W+88YbGjx+vyZMna+/evVqyZInWrFmjp59+2qP7+sUQgySFhITI4XC4tW3fvl09evRQ3759JUlOp1M//PCDmjRpUuR17Ha77HZ7scYKACifHLLJ4cVmR9fTd86cORoyZIgGDhwoSVq0aJHS0tK0dOlSjR8/3nT+jh071L59e/3lL3+RdGWbgN69e+tf//qXR/f1mwpCXFyctm7dqp9++kmnT5+WJN10003auHGjduzYob179+rhhx/WiRMnSjlSAEB5VdJDDPn5+dq1a5e6dOniagsKClKXLl20c+fOQvu0a9dOu3btcg1DHDhwQOvXr9edd97p0b39poIwbdo0Pfzww2rYsKHy8vJkGIaeffZZHThwQMnJyapUqZKGDh2qe+65R9nZ2aUdLgAARbp6gnxR1e3Tp0/L4XCoVq1abu21atXSvn37Cr32X/7yF50+fVodOnSQYRi6fPmyHnnkkfI1xJCRkeH6+v/9v/+nr7/+2u396tWr69133y3ZoAAAAcuh6xsm+H1/SaYJ8pMnT9aUKVOu+7q/l5GRoZkzZ+rll19WmzZttH//fo0cOVLTp0/XxIkTLV+nTCcIAACUJd6sRCjoL0lHjx5VRESEq72ouXFRUVEKDg42DZ+fOHHCbdn/702cOFH9+vXT4MGDJUnNmjXTxYsXNXToUD3zzDMKCrIWv9/MQQAAoLT56mFNERERbkdRCUJISIhatmypTZs2udqcTqc2bdqktm3bFtonJyfHlAQEBwdLkgzDsPxZqSAAAFCGjRkzRikpKWrVqpVat26tefPm6eLFi65VDf3791d0dLRSU1MlSd27d9ecOXN0yy23uIYYJk6cqO7du7sSBStIEAAAsMiQTU4v5iAY19G3Z8+eOnXqlCZNmqTjx48rMTFRGzZscE1cPHLkiFvF4Nlnn5XNZtOzzz6rn376STVq1FD37t01Y8YMj+5rMzypN5RD586dU2RkpJ7ZebtCq1Qs7XBQzLbfnVDaIaAEGRWs/7UE/3XZkadNBxYoOzvbbVzflwp+Vzy54y7ZvfhdkXfhkma1SyvWWH2FOQgAAMCEIQYAACzy9pHN/vS4ZxIEAAAscnj5NEdv+pY0/4kUAACUGCoIAABYxBADAAAwcSpITi+K7970LWn+EykAACgxVBAAALDIYdjk8GKYwJu+JY0EAQAAi5iDAAAATAwvn+ZoeNG3pPlPpAAAoMRQQQAAwCKHbHJ48bAmb/qWNBIEAAAschrezSNw+tHjERliAAAAJlQQAACwyOnlJEVv+pY0EgQAACxyyianF/MIvOlb0vwnlQEAACWGCgIAABaxkyIAADAJpDkI/hMpAAAoMVQQAACwyCkvn8XgR5MUSRAAALDI8HIVg0GCAABA+RNIT3NkDgIAADChggAAgEWBtIqBBAEAAIsYYgAAAAGNCgIAABYF0rMYSBAAALCIIQYAABDQqCAAAGBRIFUQSBAAALAokBIEhhgAAIAJFQQAACwKpAoCCQIAABYZ8m6pouG7UIodCQIAABYFUgWBOQgAAMCECgIAABYFUgWBBAEAAIsCKUFgiAEAAJhQQQAAwKJAqiCQIAAAYJFh2GR48Uvem74ljSEGAABgQgUBAACLnLJ5tVGSN31LGgkCAAAWBdIcBIYYAACACRUEAAAsCqRJiiQIAABYFEhDDCQIAABYFEgVBOYgAAAAEyoI//HpwGaqEGwv7TBQzDq893Vph4AStD25fmmHgBJgc+aX2L0ML4cY/KmCQIIAAIBFhiTD8K6/v2CIAQAAmFBBAADAIqdssrGTIgAA+D1WMQAAgIBGBQEAAIuchk02NkoCAAC/ZxhermLwo2UMDDEAAAATKggAAFgUSJMUSRAAALCIBAEAAJgE0iRF5iAAAAATKggAAFgUSKsYSBAAALDoSoLgzRwEHwZTzBhiAAAAJiQIAABYVLCKwZvjerz00kuKi4tTaGio2rRpo88+++ya5589e1aPPfaY6tSpI7vdrkaNGmn9+vUe3ZMhBgAALDL+c3jT31Nr1qzRmDFjtGjRIrVp00bz5s1TcnKyMjMzVbNmTdP5+fn56tq1q2rWrKl169YpOjpahw8fVtWqVT26LwkCAABl2Jw5czRkyBANHDhQkrRo0SKlpaVp6dKlGj9+vOn8pUuX6syZM9qxY4cqVqwoSYqLi/P4vgwxAABgka+GGM6dO+d25OXlFXq//Px87dq1S126dHG1BQUFqUuXLtq5c2ehfd577z21bdtWjz32mGrVqqWmTZtq5syZcjgcHn1WEgQAAKwyfHBIiomJUWRkpOtITU0t9HanT5+Ww+FQrVq13Npr1aql48ePF9rnwIEDWrdunRwOh9avX6+JEydq9uzZeu655zz6qAwxAABglZdbLes/fY8ePaqIiAhXs91u9zYyF6fTqZo1a+q1115TcHCwWrZsqZ9++kmzZs3S5MmTLV+HBAEAgBIWERHhliAUJSoqSsHBwTpx4oRb+4kTJ1S7du1C+9SpU0cVK1ZUcHCwq61x48Y6fvy48vPzFRISYilGhhgAALCoYCdFbw5PhISEqGXLltq0aZOrzel0atOmTWrbtm2hfdq3b6/9+/fL6XS62n744QfVqVPHcnIgkSAAAGBZaeyDMGbMGC1evFgrVqzQ3r179eijj+rixYuuVQ39+/fXhAkTXOc/+uijOnPmjEaOHKkffvhBaWlpmjlzph577DGP7ssQAwAAZVjPnj116tQpTZo0ScePH1diYqI2bNjgmrh45MgRBQX99+/9mJgYffjhhxo9erSaN2+u6OhojRw5UuPGjfPoviQIAABYZdhcEw2vu/91GD58uIYPH17oexkZGaa2tm3b6tNPP72uexUgQQAAwKJAepojcxAAAIAJFQQAAKwqjYcxlBJLCcJ7771n+YJ33333dQcDAEBZ5s0TGQv6+wtLCcI999xj6WI2m83jvZ4BAEDZYylB+P1mCwAABDQ/GibwhldzEHJzcxUaGuqrWAAAKNMCaYjB41UMDodD06dPV3R0tKpUqaIDBw5IkiZOnKglS5b4PEAAAMoMHz3N0R94nCDMmDFDy5cv14svvui2p3PTpk31+uuv+zQ4AABQOjxOEFauXKnXXntNffr0cXtSVIsWLbRv3z6fBgcAQNli88HhHzyeg/DTTz8pPj7e1O50OnXp0iWfBAUAQJkUQPsgeFxBaNKkiT755BNT+7p163TLLbf4JCgAAFC6PK4gTJo0SSkpKfrpp5/kdDr1zjvvKDMzUytXrtQHH3xQHDECAFA2UEEoWo8ePfT+++8rPT1dlStX1qRJk7R37169//776tq1a3HECABA2VDwNEdvDj9xXfsgdOzYURs3bvR1LAAAoIy47o2SvvjiC+3du1fSlXkJLVu29FlQAACURYH0uGePE4R///vf6t27t7Zv366qVatKks6ePat27drprbfeUr169XwdIwAAZQNzEIo2ePBgXbp0SXv37tWZM2d05swZ7d27V06nU4MHDy6OGAEAQAnzuILw8ccfa8eOHUpISHC1JSQkaOHCherYsaNPgwMAoEzxdqJheZ6kGBMTU+iGSA6HQ3Xr1vVJUAAAlEU248rhTX9/4fEQw6xZszRixAh98cUXrrYvvvhCI0eO1F//+lefBgcAQJkSQA9rslRBqFatmmy2/5ZFLl68qDZt2qhChSvdL1++rAoVKuihhx7SPffcUyyBAgCAkmMpQZg3b14xhwEAgB9gDoK7lJSU4o4DAICyL4CWOV73RkmSlJubq/z8fLe2iIgIrwICAAClz+NJihcvXtTw4cNVs2ZNVa5cWdWqVXM7AAAotwJokqLHCcJTTz2lzZs365VXXpHdbtfrr7+uqVOnqm7dulq5cmVxxAgAQNkQQAmCx0MM77//vlauXKlOnTpp4MCB6tixo+Lj4xUbG6vVq1erT58+xREnAAAoQR5XEM6cOaMGDRpIujLf4MyZM5KkDh06aOvWrb6NDgCAsiSAHvfscYLQoEEDHTx4UJJ08803a+3atZKuVBYKHt4EAEB5VLCTojeHv/A4QRg4cKC+/vprSdL48eP10ksvKTQ0VKNHj9aTTz7p8wABAEDJ83gOwujRo11fd+nSRfv27dOuXbsUHx+v5s2b+zQ4AADKFPZBsC42NlaxsbG+iAUAAJQRlhKEBQsWWL7g448/bvlcp9OpF154Qa+99pqOHz+uRo0aaeLEibr//vuVkZGhzp07Kz09XePGjdP333+vxMRELVu2zO1R088995wWLFig3377TT179lRUVJQ2bNig3bt3W44DAAArbPLyaY4+i6T4WUoQ5s6da+liNpvNowQhNTVVf/vb37Ro0SLddNNN2rp1q/r27asaNWq4znnmmWc0e/Zs1ahRQ4888ogeeughbd++XZK0evVqzZgxQy+//LLat2+vt956S7Nnz1b9+vWLvGdeXp7y8vJcr8+dO2c5XgAAAoWlBKFg1YIv5eXlaebMmUpPT1fbtm0lXVkhsW3bNr366qsaOnSoJGnGjBlKSkqSdGVS5F133aXc3FyFhoZq4cKFGjRokAYOHChJmjRpkj766CNduHChyPumpqZq6tSpPv88AIAAEEAPa/J4FYOv7N+/Xzk5OeratauqVKniOlauXKmsrCzXeb+f+FinTh1J0smTJyVJmZmZat26tdt1r359tQkTJig7O9t1HD161FcfCQBQ3rGTYvEr+Cs/LS1N0dHRbu/Z7XZXklCxYkVXu812JfNyOp3XfV+73S673X7d/QEACASlVkFo0qSJ7Ha7jhw5ovj4eLcjJibG0jUSEhL0+eefu7Vd/RoAAJ+hglD8wsPDNXbsWI0ePVpOp1MdOnRQdna2tm/froiICEtLJ0eMGKEhQ4aoVatWateundasWaNvvvnGtRU0AAC+5O1uiP60k2KpJQiSNH36dNWoUUOpqak6cOCAqlatqltvvVVPP/20pWGEPn366MCBAxo7dqxyc3P14IMPasCAAfrss89KIHoAAMqv60oQPvnkE7366qvKysrSunXrFB0drVWrVql+/frq0KGD5evYbDaNHDlSI0eOLPR9w3BPtRITE01tEydO1MSJE12vu3btqvj4eA8+DQAAFgXQTooez0F4++23lZycrLCwMH311VeuPQWys7M1c+ZMnwd4LTk5OZozZ4727Nmjffv2afLkyUpPT1dKSkqJxgEACBABNAfB4wThueee06JFi7R48WK3FQbt27fXl19+6dPg/ojNZtP69et12223qWXLlnr//ff19ttvq0uXLiUaBwAA5Y3HQwyZmZm67bbbTO2RkZE6e/asL2KyLCwsTOnp6SV6TwBA4AqkSYoeVxBq166t/fv3m9q3bdvG6gEAQPlWsJOiN4ef8DhBGDJkiEaOHKl//etfstls+vnnn7V69WqNHTtWjz76aHHECABA2RBAcxA8HmIYP368nE6n/vznPysnJ0e33Xab7Ha7xo4dqxEjRhRHjAAAoIR5nCDYbDY988wzevLJJ7V//35duHBBTZo0UZUqVYojPgAAyoxAmoNw3RslhYSEqEmTJr6MBQCAsi2A9kHwOEHo3Lmz66FJhdm8ebNXAQEAgNLncYKQmJjo9vrSpUvavXu3vvvuOzYoAgCUb14OMZTrCsLcuXMLbZ8yZYrrEc4AAJRLATTE4LPHPfft21dLly711eUAAEAp8tnTHHfu3KnQ0FBfXQ4AgLIngCoIHicI9913n9trwzB07NgxffHFF25PVQQAoLxhmeM1REZGur0OCgpSQkKCpk2bpttvv91ngQEAgNLjUYLgcDg0cOBANWvWTNWqVSuumAAAQCnzaJJicHCwbr/99hJ/aiMAAGVCAD2LweNVDE2bNtWBAweKIxYAAMq0gjkI3hz+wuME4bnnntPYsWP1wQcf6NixYzp37pzbAQAA/J/lOQjTpk3TE088oTvvvFOSdPfdd7ttuWwYhmw2mxwOh++jBACgrPCjKoA3LCcIU6dO1SOPPKItW7YUZzwAAJRd7INgZhhXPlVSUlKxBQMAAMoGj5Y5XuspjgAAlHdslFSERo0a/WGScObMGa8CAgCgzGKIoXBTp0417aQIAACK10svvaRZs2bp+PHjatGihRYuXKjWrVv/Yb+33npLvXv3Vo8ePfTuu+96dE+PEoRevXqpZs2aHt0AAIDyojSGGNasWaMxY8Zo0aJFatOmjebNm6fk5GRlZmZe83fyoUOHNHbsWHXs2PG6YrW8DwLzDwAAAa8UdlKcM2eOhgwZooEDB6pJkyZatGiRKlWqpKVLlxbZx+FwqE+fPpo6daoaNGjg+U3lQYJQsIoBAAB45+pNBvPy8go9Lz8/X7t27VKXLl1cbUFBQerSpYt27txZ5PWnTZummjVratCgQdcdo+UEwel0MrwAAAhsPqogxMTEKDIy0nWkpqYWervTp0/L4XCoVq1abu21atXS8ePHC+2zbds2LVmyRIsXL/bqo3r8uGcAAAKVr+YgHD16VBEREa52u93uZWRXnD9/Xv369dPixYsVFRXl1bVIEAAAsMpHyxwjIiLcEoSiREVFKTg4WCdOnHBrP3HihGrXrm06PysrS4cOHVL37t1dbU6nU5JUoUIFZWZmqmHDhpZC9fhhTQAAoGSEhISoZcuW2rRpk6vN6XRq06ZNatu2ren8m2++Wd9++612797tOu6++2517txZu3fvVkxMjOV7U0EAAMCqUtgoacyYMUpJSVGrVq3UunVrzZs3TxcvXtTAgQMlSf3791d0dLRSU1MVGhqqpk2buvWvWrWqJJna/wgJAgAAFpXGPgg9e/bUqVOnNGnSJB0/flyJiYnasGGDa+LikSNHFBTk+wEBEgQAAMq44cOHa/jw4YW+l5GRcc2+y5cvv657kiAAAGAVz2IAAABXC6SnObKKAQAAmFBBAADAKoYYAACASQAlCAwxAAAAEyoIAABYZPvP4U1/f0GCAACAVQE0xECCAACARSxzBAAAAY0KAgAAVjHEAAAACuVHv+S9wRADAAAwoYIAAIBFgTRJkQQBAACrAmgOAkMMAADAhAoCAAAWMcQAAADMGGIAAACBjArCfzgys2SzVSztMFDMPm4eVtohoAR9+POG0g4BJeDceaeqNSqZezHEAAAAzAJoiIEEAQAAqwIoQWAOAgAAMKGCAACARcxBAAAAZgwxAACAQEYFAQAAi2yGIZtx/WUAb/qWNBIEAACsYogBAAAEMioIAABYxCoGAABgxhADAAAIZFQQAACwiCEGAABgFkBDDCQIAABYFEgVBOYgAAAAEyoIAABYxRADAAAojD8NE3iDIQYAAGBCBQEAAKsM48rhTX8/QYIAAIBFrGIAAAABjQoCAABWsYoBAABczea8cnjT318wxAAAAEyoIAAAYBVDDAAA4GqBtIqBBAEAAKsCaB8E5iAAAAATKggAAFjEEAMAADALoEmKDDEAAAATKggAAFjEEAMAADBjFQMAAAhkVBAAALCIIQYAAGDGKgYAABDIqCAAAGARQwwAAMDMaVw5vOnvJ0gQAACwijkIAAAgkFFBAADAIpu8nIPgs0iKHwkCAABWsZMiAAAIZFQQAACwKJCWOVJBAADAKsMHx3V46aWXFBcXp9DQULVp00afffZZkecuXrxYHTt2VLVq1VStWjV16dLlmucXhQQBAIAybM2aNRozZowmT56sL7/8Ui1atFBycrJOnjxZ6PkZGRnq3bu3tmzZop07dyomJka33367fvrpJ4/uS4IAAIBFNsPw+vDUnDlzNGTIEA0cOFBNmjTRokWLVKlSJS1durTQ81evXq1hw4YpMTFRN998s15//XU5nU5t2rTJo/uSIAAAYJXTB4ekc+fOuR15eXmF3i4/P1+7du1Sly5dXG1BQUHq0qWLdu7caSnknJwcXbp0SdWrV/foo5IgAABQwmJiYhQZGek6UlNTCz3v9OnTcjgcqlWrllt7rVq1dPz4cUv3GjdunOrWreuWZFjBKgYAACy63mGC3/eXpKNHjyoiIsLVbrfbvY6tMM8//7zeeustZWRkKDQ01KO+JAgAAFjlo2cxREREuCUIRYmKilJwcLBOnDjh1n7ixAnVrl37mn3/+te/6vnnn1d6erqaN2/ucagMMQAAYFXBToreHB4ICQlRy5Yt3SYYFkw4bNu2bZH9XnzxRU2fPl0bNmxQq1atruujUkEAAKAMGzNmjFJSUtSqVSu1bt1a8+bN08WLFzVw4EBJUv/+/RUdHe2ax/DCCy9o0qRJeuONNxQXF+eaq1ClShVVqVLF8n1JEAAAsKg0dlLs2bOnTp06pUmTJun48eNKTEzUhg0bXBMXjxw5oqCg/w4IvPLKK8rPz9f999/vdp3JkydrypQplu9bZhMEwzD08MMPa926dfr111/11VdfKTExsbTDAgAEslJ6WNPw4cM1fPjwQt/LyMhwe33o0KHrusfVymyCsGHDBi1fvlwZGRlq0KCBoqKiSjskAAACRplNELKyslSnTh21a9eu0Pfz8/MVEhJSwlEBAAKZzXnl8Ka/vyiTqxgGDBigESNG6MiRI7LZbIqLi1OnTp00fPhwjRo1SlFRUUpOTpZ0ZQvKZs2aqXLlyoqJidGwYcN04cKFUv4EAIByqYRXMZSmMpkgzJ8/X9OmTVO9evV07Ngxff7555KkFStWKCQkRNu3b9eiRYskXdlycsGCBdqzZ49WrFihzZs366mnniry2nl5eaYtLgEAgLsyOcQQGRmp8PBwBQcHu20EcdNNN+nFF190O3fUqFGur+Pi4vTcc8/pkUce0csvv1zotVNTUzV16tRiiRsAUM75aKMkf1AmKwhFadmypaktPT1df/7znxUdHa3w8HD169dPv/zyi3Jycgq9xoQJE5Sdne06jh49WtxhAwDKidJ4mmNp8asEoXLlym6vDx06pG7duql58+Z6++23tWvXLr300kuSrkxiLIzdbndtcWl1q0sAAAJNmRxisGrXrl1yOp2aPXu2a5OItWvXlnJUAIByq5T2QSgNfp0gxMfH69KlS1q4cKG6d+/uNnkRAACfMyR5s1TRf/ID/xpiuFqLFi00Z84cvfDCC2ratKlWr15d5DO1AQDwViDNQbAZhh9FWwzOnTunyMhIdbLdowq2iqUdDopbYP/nHnA+/Hl3aYeAEnDuvFPVGh1QdnZ2sc0rK/hd8adbxqtCcOh1X+eyI1ebv3q+WGP1Fb8eYgAAoEQZ8nIOgs8iKXYkCAAAWBVAkxT9eg4CAAAoHlQQAACwyinJ5mV/P0GCAACARd6uRPCnVQwMMQAAABMqCAAAWBVAkxRJEAAAsCqAEgSGGAAAgAkVBAAArAqgCgIJAgAAVrHMEQAAXI1ljgAAIKBRQQAAwCrmIAAAABOnIdm8+CXv9J8EgSEGAABgQgUBAACrGGIAAABmXiYI8p8EgSEGAABgQgUBAACrGGIAAAAmTkNeDROwigEAAPgzKggAAFhlOK8c3vT3EyQIAABYxRwEAABgwhwEAAAQyKggAABgFUMMAADAxJCXCYLPIil2DDEAAAATKggAAFjFEAMAADBxOiV5sZeB03/2QWCIAQAAmFBBAADAKoYYAACASQAlCAwxAAAAEyoIAABYFUBbLZMgAABgkWE4ZXjxREZv+pY0EgQAAKwyDO+qAMxBAAAA/owKAgAAVhlezkHwowoCCQIAAFY5nZLNi3kEfjQHgSEGAABgQgUBAACrGGIAAABXM5xOGV4MMfjTMkeGGAAAgAkVBAAArGKIAQAAmDgNyRYYCQJDDAAAwIQKAgAAVhmGJG/2QfCfCgIJAgAAFhlOQ4YXQwwGCQIAAOWQ4ZR3FQSWOQIAAD9GBQEAAIsYYgAAAGYBNMQQ8AlCQTZ32bhUypGgRPhR9g7vnTvvP/8zxvU7d+HKz7kk/jq/rEte7ZN0Wf7zuybgE4Tz589LkrYpzasfOoCyp1qj0o4AJen8+fOKjIwslmuHhISodu3a2nZ8vdfXql27tkJCQnwQVfGyGf40IFIMnE6nfv75Z4WHh8tms5V2OCXm3LlziomJ0dGjRxUREVHa4aAY8bMOHIH6szYMQ+fPn1fdunUVFFR8c+9zc3OVn5/v9XVCQkIUGhrqg4iKV8BXEIKCglSvXr3SDqPUREREBNT/SAIZP+vAEYg/6+KqHPxeaGioX/xi9xWWOQIAABMSBAAAYEKCEKDsdrsmT54su91e2qGgmPGzDhz8rOFLAT9JEQAAmFFBAAAAJiQIAADAhAQBAACYkCCUY506ddKoUaNKOwwAPmQYhoYOHarq1avLZrNp9+7dpR0SyikmKZZjZ86cUcWKFRUeHq64uDiNGjWKhAHwc//85z/Vo0cPZWRkqEGDBoqKilKFCgG/5x2KAf9VlWPVq1cv7RAA+FhWVpbq1Kmjdu3aFfp+fn6+X+zzj7KPIYZyrGCIoVOnTjp8+LBGjx4tm83meubEL7/8ot69eys6OlqVKlVSs2bN9Oabb5Zy1LDK6XQqNTVV9evXV1hYmFq0aKF169ZJkjIyMmSz2bRp0ya1atVKlSpVUrt27ZSZmel2jeeee041a9ZUeHi4Bg8erPHjxysxMbEUPg2sGDBggEaMGKEjR47IZrMpLi5OnTp10vDhwzVq1ChFRUUpOTlZkjRnzhw1a9ZMlStXVkxMjIYNG6YLFy6U8ieAPyFBCADvvPOO6tWrp2nTpunYsWM6duyYpCsPHmnZsqXS0tL03XffaejQoerXr58+++yzUo4YVqSmpmrlypVatGiR9uzZo9GjR6tv3776+OOPXec888wzmj17tr744gtVqFBBDz30kOu91atXa8aMGXrhhRe0a9cu3XjjjXrllVdK46PAovnz52vatGmqV6+ejh07ps8//1yStGLFCoWEhGj79u1atGiRpCvPmVmwYIH27NmjFStWaPPmzXrqqadKM3z4GwPlVlJSkjFy5EjDMAwjNjbWmDt37h/2ueuuu4wnnniieAOD13Jzc41KlSoZO3bscGsfNGiQ0bt3b2PLli2GJCM9Pd31XlpamiHJ+O233wzDMIw2bdoYjz32mFv/9u3bGy1atCj2+HH95s6da8TGxrpeJyUlGbfccssf9vv73/9u3HDDDcUYGcob5iAEMIfDoZkzZ2rt2rX66aeflJ+fr7y8PFWqVKm0Q8Mf2L9/v3JyctS1a1e39vz8fN1yyy2u182bN3d9XadOHUnSyZMndeONNyozM1PDhg1z69+6dWtt3ry5GCNHcWjZsqWpLT09Xampqdq3b5/OnTuny5cvKzc3Vzk5OfwbhyUkCAFs1qxZmj9/vubNm+caqxw1apRPnneO4lUwlpyWlqbo6Gi39+x2u7KysiRJFStWdLUXzD1xOp0lFCVKSuXKld1eHzp0SN26ddOjjz6qGTNmqHr16tq2bZsGDRqk/Px8EgRYQoIQIEJCQuRwONzatm/frh49eqhv376Srvzi+OGHH9SkSZPSCBEeaNKkiex2u44cOaKkpCTT+wUJwrUkJCTo888/V//+/V1tBWPa8G+7du2S0+nU7NmzFRR0ZarZ2rVrSzkq+BsShAARFxenrVu3qlevXrLb7YqKitJNN92kdevWaceOHapWrZrmzJmjEydOkCD4gfDwcI0dO1ajR4+W0+lUhw4dlJ2dre3btysiIkKxsbF/eI0RI0ZoyJAhatWqldq1a6c1a9bom2++UYMGDUrgE6A4xcfH69KlS1q4cKG6d+/uNnkRsIpVDAFi2rRpOnTokBo2bKgaNWpIkp599lndeuutSk5OVqdOnVS7dm3dc889pRsoLJs+fbomTpyo1NRUNW7cWHfccYfS0tJUv359S/379OmjCRMmaOzYsbr11lt18OBBDRgwQKGhocUcOYpbixYtNGfOHL3wwgtq2rSpVq9erdTU1NIOC36GnRQBuHTt2lW1a9fWqlWrSjsUAKWMIQYgQOXk5GjRokVKTk5WcHCw3nzzTaWnp2vjxo2lHRqAMoAKAhCgfvvtN3Xv3l1fffWVcnNzlZCQoGeffVb33XdfaYcGoAwgQQAAACZMUgQAACYkCAAAwIQEAQAAmJAgAAAAExIEoAwYMGCA2yZVnTp10qhRo0o8joyMDNlsNp09e7bIc2w2m959913L15wyZYoSExO9iuvQoUOy2WzavXu3V9cBYB0JAlCEAQMGyGazyWazKSQkRPHx8Zo2bZouX75c7Pd+5513NH36dEvnWvmlDgCeYqMk4BruuOMOLVu2THl5eVq/fr0ee+wxVaxYURMmTDCdm5+fr5CQEJ/ct3r16j65DgBcLyoIwDXY7XbVrl1bsbGxevTRR9WlSxe99957kv47LDBjxgzVrVtXCQkJkqSjR4/qwQcfVNWqVVW9enX16NFDhw4dcl3T4XBozJgxqlq1qm644QY99dRTuno7kquHGPLy8jRu3DjFxMTIbrcrPj5eS5Ys0aFDh9S5c2dJUrVq1WSz2TRgwABJV57OmZqaqvr16yssLEwtWrTQunXr3O6zfv16NWrUSGFhYercubNbnFaNGzdOjRo1UqVKldSgQQNNnDhRly5dMp336quvKiYmRpUqVdKDDz6o7Oxst/dff/11NW7cWKGhobr55pv18ssvexwLAN8hQQA8EBYWpvz8fNfrTZs2KTMzUxs3btQHH3ygS5cuKTk5WeHh4frkk0+0fft2ValSRXfccYer3+zZs7V8+XItXbpU27Zt05kzZ/SPf/zjmvft37+/3nzzTS1YsEB79+7Vq6++qipVqigmJkZvv/22JCkzM1PHjh3T/PnzJUmpqalauXKlFi1apD179mj06NHq27evPv74Y0lXEpn77rtP3bt31+7duzV48GCNHz/e4+9JeHi4li9fru+//17z58/X4sWLNXfuXLdz9u/fr7Vr1+r999/Xhg0b9NVXX2nYsGGu91evXq1JkyZpxowZ2rt3r2bOnKmJEydqxYoVHscDwEcMAIVKSUkxevToYRiGYTidTmPjxo2G3W43xo4d63q/Vq1aRl5enqvPqlWrjISEBMPpdLra8vLyjLCwMOPDDz80DMMw6tSpY7z44ouu9y9dumTUq1fPdS/DMIykpCRj5MiRhmEYRmZmpiHJ2LhxY6FxbtmyxZBk/Prrr6623Nxco1KlSsaOHTvczh00aJDRu3dvwzAMY8KECUaTJk3c3h83bpzpWleTZPzjH/8o8v1Zs2YZLVu2dL2ePHmyERwcbPz73/92tf3zn/80goKCjGPHjhmGYRgNGzY03njjDbfrTJ8+3Wjbtq1hGIZx8OBBQ5Lx1VdfFXlfAL7FHATgGj744ANVqVJFly5dktPp1F/+8hdNmTLF9X6zZs3c5h18/fXX2r9/v8LDw92uk5ubq6ysLGVnZ+vYsWNq06aN670KFSqoVatWpmGGArt371ZwcLCSkpIsx71//37l5OSoa9eubu35+fm65ZZbJEl79+51i0OS2rZta/keBdasWaMFCxYoKytLFy5c0OXLlxUREeF2zo033qjo6Gi3+zidTmVmZio8PFxZWVkaNGiQhgwZ4jrn8uXLioyM9DgeAL5BggBcQ+fOnfXKK68oJCREdevWVYUK7v9kKleu7Pb6woULatmypVavXm26Vo0aNa4rhrCwMI/7XLhwQZKUlpbm9otZujKvwld27typPn36aOrUqUpOTlZkZKTeeustzZ492+NYFy9ebEpYgoODfRYrAM+QIADXULlyZcXHx1s+/9Zbb9WaNWtUs2ZN01/RBerUqaN//etfuu222yRd+Ut5165duvXWWws9v1mzZnI6nfr444/VpUsX0/sFFQyHw+Fqa9Kkiex2u44cOVJk5aFx48auCZcFPv300z/+kL+zY8cOxcbG6plnnnG1HT582HTekSNH9PPPP6tu3bqu+wQFBSkhIUG1atVS3bp1deDAAfXp08ej+wMoPkxSBHyoT58+ioqKUo8ePfTJJ5/o4MGDysjI0OOPP65///vfkqSRI0fq+eef17vvvqt9+/Zp2LBh19zDIC4uTikpKXrooYf07rvvuq65du1aSVJsbKxsNps++OADnTp1ShcuXFB4eLjGjh2r0aNHa8WKFcrKytKXX36phQsXuib+PfLII/rxxx/15JNPKjMzU2+88YaWL1/u0ee96aabdOTIEb311lvKysrSggULCp1wGRoaqpSUFH399df65JNP9Pjjj+vBBx9U7dq1JUlTp05VamqqFixYoB9++EHffvutli1bpjlz5ngUDwDfIUEAfKhSpUraunWrbrzxRt13331q3LixBg0apNzcXFdF4YknnlC/fv2UkpKitm3bKjw8XPfee+81r/vKK6/o/vvv17Bhw3TzzTdryJAhunjxoiQpOjpaU6dO1fjx41WrVi0NHz5ckjR9+nRNnDhRqampaty4se644w6lpaWpfv36kq7MC3j77bf17rvvqkWLFlq0aJFmzpzp0ee9++67NXr0aA0fPlyJiYnasWOHJk6caDovPj5e9913n+68807dfvvtat68udsyxsGDB+v111/XsmXL1KxZMyUlJWn58uWuWAGUPJtR1MwoAAAQsKggAAAAExIEAABgQoIAAABMSBAAAIAJCQIAADAhQQAAACYkCAAAwIQEAQAAmJAgAAAAExIEAABgQoIAAABMSBAAAIDJ/wcyg8i1PsFufgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_validation, y_onehot_test = y_onehot_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_unheard_speakers files:  1260\n",
      "test_known_speakers files:  1170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_unheard = [directory + \"/test_unheard_speakers/\" + f for f in os.listdir(directory + \"test_unheard_speakers/\") if f.endswith('.csv')]\n",
    "csv_files_known = [directory + \"/test_known_speakers/\" + f for f in os.listdir(directory + \"test_known_speakers/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"test_unheard_speakers files: \", len(csv_files_unheard))\n",
    "print(\"test_known_speakers files: \", len(csv_files_known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_test_known size:  1170\n",
      "dataset_test_unheard size:  1260\n",
      "labels_test_known size:  1170\n",
      "labels_test_unheard size:  1260\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_test_known = []\n",
    "dataset_test_unheard = []\n",
    "labels_test_known = []\n",
    "labels_test_unheard = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_known:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_test_known.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_test_known.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_unheard:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_test_unheard.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_test_unheard.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset_test_known size: \", len(dataset_test_known))\n",
    "print(\"dataset_test_unheard size: \", len(dataset_test_unheard))\n",
    "print(\"labels_test_known size: \", len(labels_test_known))\n",
    "print(\"labels_test_unheard size: \", len(labels_test_unheard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_test_known[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ita': 0, 'eng': 1, 'fra': 2}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\", \"fra\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "print(class_to_index)\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_test_unheard = np.array([class_to_index[label] for label in labels_test_unheard], dtype=np.int8)\n",
    "integer_labels_test_known = np.array([class_to_index[label] for label in labels_test_known], dtype=np.int8)\n",
    "\n",
    "y_onehot_test_unheard = tf.keras.utils.to_categorical(integer_labels_test_unheard, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_test_known = tf.keras.utils.to_categorical(integer_labels_test_known, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unheard speakers features shape: (1260, 349, 12, 1)\n",
      "known speakers with noisy audio features shape: (1170, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test_unheard = tf.reshape(dataset_test_unheard, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_test_known = tf.reshape(dataset_test_known, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"unheard speakers features shape:\", x_test_unheard.shape)\n",
    "print(\"known speakers with noisy audio features shape:\", x_test_known.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "test_unheard_dataset = tf.data.Dataset.from_tensor_slices((x_test_unheard, y_onehot_test_unheard))\n",
    "test_known_dataset = tf.data.Dataset.from_tensor_slices((x_test_known, y_onehot_test_known))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 21, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "\n",
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating accuracy of quantized model on test set: unheard speakers\n",
      "x shape =  (1260, 349, 12, 1)\n",
      "y shape = (1260, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in test set of quantized TFLite model: 0.6429\n",
      "MSE loss in test set of quantized TFLite model: 0.0237\n",
      "[[0.62619048 0.30714286 0.06666667]\n",
      " [0.23571429 0.58809524 0.17619048]\n",
      " [0.18571429 0.1        0.71428571]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating accuracy of quantized model on test set: known speakers with noisy audio recordings\n",
      "x shape =  (1170, 349, 12, 1)\n",
      "y shape = (1170, 3)\n",
      "Accuracy in test set of quantized TFLite model: 0.7752\n",
      "MSE loss in test set of quantized TFLite model: 0.0198\n",
      "[[0.7025641  0.10769231 0.18974359]\n",
      " [0.14615385 0.71538462 0.13846154]\n",
      " [0.06923077 0.02307692 0.90769231]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"evaluating accuracy of quantized model on test set: unheard speakers\")\n",
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_test_unheard, y_onehot_test = y_onehot_test_unheard)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"evaluating accuracy of quantized model on test set: known speakers with noisy audio recordings\")\n",
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_test_known, y_onehot_test = y_onehot_test_known)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
