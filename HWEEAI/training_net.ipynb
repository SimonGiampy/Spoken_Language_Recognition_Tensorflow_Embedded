{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  770\n",
      "validation files:  210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:28:40.297100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 19:28:41.273176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:28:42.263897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:42.291977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:42.292224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  770\n",
      "dataset validation size:  210\n",
      "labels train size:  770\n",
      "labels validation size:  210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (770, 349, 12)\n",
      "Validation features shape: (210, 349, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:28:57.947492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:57.947950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:57.948250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:58.028141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:58.028331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:58.028480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-14 19:28:58.028587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3494 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1]))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1]))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 345, 12, 64)       384       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 172, 12, 64)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 168, 12, 64)       20544     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 84, 12, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 82, 12, 32)        6176      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 41, 12, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 39, 10, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 19, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 32)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38530 (150.51 KB)\n",
      "Trainable params: 38530 (150.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 19:29:09.491613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-14 19:29:10.015609: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0eb4052a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-14 19:29:10.015638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
      "2023-08-14 19:29:10.020263: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-14 19:29:11.482122: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 58ms/step - loss: 0.7709 - accuracy: 0.5104 - val_loss: 0.6781 - val_accuracy: 0.5810\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6797 - accuracy: 0.5766 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6802 - accuracy: 0.5455 - val_loss: 0.6683 - val_accuracy: 0.5381\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6757 - accuracy: 0.5844 - val_loss: 0.6523 - val_accuracy: 0.6048\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6539 - accuracy: 0.6052 - val_loss: 0.6540 - val_accuracy: 0.6048\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6698 - accuracy: 0.5792 - val_loss: 0.6398 - val_accuracy: 0.6286\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.6364 - accuracy: 0.6364 - val_loss: 0.6133 - val_accuracy: 0.6905\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6317 - accuracy: 0.6649 - val_loss: 0.6447 - val_accuracy: 0.6143\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6101 - accuracy: 0.6714 - val_loss: 0.5769 - val_accuracy: 0.6810\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6231 - accuracy: 0.6532 - val_loss: 0.6150 - val_accuracy: 0.6857\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5969 - accuracy: 0.6675 - val_loss: 0.6815 - val_accuracy: 0.5476\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6227 - accuracy: 0.6481 - val_loss: 0.6111 - val_accuracy: 0.6857\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5886 - accuracy: 0.6844 - val_loss: 0.7757 - val_accuracy: 0.5571\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.6320 - accuracy: 0.6455 - val_loss: 0.5881 - val_accuracy: 0.6905\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5785 - accuracy: 0.6870 - val_loss: 0.5602 - val_accuracy: 0.7238\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5974 - accuracy: 0.6792 - val_loss: 0.7555 - val_accuracy: 0.5571\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6257 - accuracy: 0.6416 - val_loss: 0.6062 - val_accuracy: 0.6905\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5689 - accuracy: 0.7260 - val_loss: 0.5516 - val_accuracy: 0.7190\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5134 - accuracy: 0.7662 - val_loss: 0.4999 - val_accuracy: 0.7429\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5204 - accuracy: 0.7325 - val_loss: 0.6668 - val_accuracy: 0.5952\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6620 - accuracy: 0.5948 - val_loss: 0.6123 - val_accuracy: 0.6714\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5560 - accuracy: 0.7117 - val_loss: 0.5594 - val_accuracy: 0.7143\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5265 - accuracy: 0.7494 - val_loss: 0.4865 - val_accuracy: 0.7810\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.4816 - accuracy: 0.7792 - val_loss: 0.4678 - val_accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4464 - accuracy: 0.7948 - val_loss: 0.4321 - val_accuracy: 0.7714\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4082 - accuracy: 0.8169 - val_loss: 1.0020 - val_accuracy: 0.5571\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5751 - accuracy: 0.7481 - val_loss: 0.5576 - val_accuracy: 0.7095\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4315 - accuracy: 0.8065 - val_loss: 0.4112 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4266 - accuracy: 0.8130 - val_loss: 0.6904 - val_accuracy: 0.6429\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4572 - accuracy: 0.7727 - val_loss: 0.4072 - val_accuracy: 0.8095\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.3479 - accuracy: 0.8468 - val_loss: 0.4560 - val_accuracy: 0.7762\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.4223 - accuracy: 0.8039 - val_loss: 0.4959 - val_accuracy: 0.7667\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.3401 - accuracy: 0.8584 - val_loss: 0.3545 - val_accuracy: 0.8238\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2992 - accuracy: 0.8831 - val_loss: 0.3448 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2873 - accuracy: 0.8844 - val_loss: 0.3561 - val_accuracy: 0.8238\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2888 - accuracy: 0.8857 - val_loss: 0.3484 - val_accuracy: 0.8238\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.4000 - accuracy: 0.7896 - val_loss: 0.3609 - val_accuracy: 0.8190\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2740 - accuracy: 0.8883 - val_loss: 0.4015 - val_accuracy: 0.8190\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2383 - accuracy: 0.8974 - val_loss: 0.3427 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.3550 - accuracy: 0.8390 - val_loss: 0.3243 - val_accuracy: 0.8524\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2411 - accuracy: 0.8961 - val_loss: 0.2981 - val_accuracy: 0.8381\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2029 - accuracy: 0.9195 - val_loss: 0.4844 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2070 - accuracy: 0.9143 - val_loss: 0.5367 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2176 - accuracy: 0.9078 - val_loss: 0.3702 - val_accuracy: 0.8238\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1997 - accuracy: 0.9195 - val_loss: 0.8439 - val_accuracy: 0.7476\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.3138 - accuracy: 0.8558 - val_loss: 1.0456 - val_accuracy: 0.6524\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.3294 - accuracy: 0.8584 - val_loss: 0.3479 - val_accuracy: 0.8286\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1790 - accuracy: 0.9338 - val_loss: 0.3054 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1652 - accuracy: 0.9377 - val_loss: 0.3535 - val_accuracy: 0.8381\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.1419 - accuracy: 0.9481 - val_loss: 0.2721 - val_accuracy: 0.8857\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.1602 - accuracy: 0.9351 - val_loss: 0.4698 - val_accuracy: 0.8095\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1694 - accuracy: 0.9338 - val_loss: 0.4801 - val_accuracy: 0.8238\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1314 - accuracy: 0.9532 - val_loss: 0.7348 - val_accuracy: 0.7429\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2791 - accuracy: 0.8831 - val_loss: 0.3025 - val_accuracy: 0.8762\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1257 - accuracy: 0.9636 - val_loss: 0.3900 - val_accuracy: 0.8381\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1840 - accuracy: 0.9143 - val_loss: 0.3894 - val_accuracy: 0.8429\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0870 - accuracy: 0.9727 - val_loss: 0.2921 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0558 - accuracy: 0.9909 - val_loss: 0.3079 - val_accuracy: 0.8905\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0449 - accuracy: 0.9935 - val_loss: 0.3065 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0347 - accuracy: 0.9974 - val_loss: 2.3383 - val_accuracy: 0.5810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f0f90fd0ad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "    #layers.Reshape(( 1247, 12), input_shape=(1247, 12)),\n",
    "\tlayers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.GlobalAveragePooling2D(), \n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, batch_size=batch_size, \n",
    "          validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step - loss: 2.3383 - accuracy: 0.5810\n",
      "{'loss': 2.3383290767669678, 'accuracy': 0.5809524059295654}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\model_lite\\CNN_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\Documents\\GitHub\\Spoken_Language_Recognition_Tensorflow_Embedded\\model_lite\\CNN_model_h5\\assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"\\\\model_lite\\\\\"\n",
    "model.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"\\\\model_lite\\\\\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_49_input:0', 'index': 0, 'shape': array([   1, 1247,   12,    1]), 'shape_signature': array([  -1, 1247,   12,    1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 28, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1 1247   12    1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-89  32  76 ...  35  63  49]\n",
      " [-84  18  57 ... -11  61  22]\n",
      " [-83  14  66 ... -32  56  20]\n",
      " ...\n",
      " [ -6  87  22 ... -14  14   5]\n",
      " [ 11  71  -4 ...  -7   1 -16]\n",
      " [ 32  69 -33 ... -17   0   2]]\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(val_features))\n",
    "\n",
    "# Select the random data point using the random index\n",
    "random_data_point = tf.convert_to_tensor(tf.cast(val_features[random_index], dtype=tf.float32))\n",
    "random_label = tf.convert_to_tensor(val_labels[random_index])\n",
    "# Convert the random data point from int8 to float32\n",
    "input_data_matrix = random_data_point\n",
    "batch_size = 1\n",
    "\n",
    "input_data_matrix = tf.reshape(input_data_matrix, (-1, 1247, 12, 1))\n",
    "print(input_data_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input data to the interpreter.\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data_matrix)\n",
    "\n",
    "# Run inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output data from the interpreter.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Process output data.\n",
    "# For example, if your output is classification probabilities:\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True label: \", random_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!xxd -i converted_model.tflite > model_data.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
