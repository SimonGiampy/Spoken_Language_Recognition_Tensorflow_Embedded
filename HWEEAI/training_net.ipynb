{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  770\n",
      "validation files:  210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 16:07:24.525515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 16:07:31.428674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 16:07:38.815474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-16 16:07:41.873864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-16 16:07:41.874118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  770\n",
      "dataset validation size:  210\n",
      "labels train size:  770\n",
      "labels validation size:  210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (770, 349, 12, 1)\n",
      "Validation features shape: (210, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12, 1)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.002,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=1e-4,\n",
    "    power=0.5\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 345, 12, 64)       384       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 172, 12, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 170, 12, 32)       6176      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 85, 12, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 83, 10, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 41, 5, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 32)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17986 (70.26 KB)\n",
      "Trainable params: 17986 (70.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 5s 33ms/step - loss: 1.1778 - accuracy: 0.5247 - lr: 0.0020 - val_loss: 0.7014 - val_accuracy: 0.5143 - val_lr: 0.0020\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.7177 - accuracy: 0.5182 - lr: 0.0020 - val_loss: 0.6562 - val_accuracy: 0.6333 - val_lr: 0.0020\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.6777 - accuracy: 0.5623 - lr: 0.0020 - val_loss: 0.6708 - val_accuracy: 0.5476 - val_lr: 0.0020\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6796 - accuracy: 0.5753 - lr: 0.0020 - val_loss: 0.6785 - val_accuracy: 0.5000 - val_lr: 0.0020\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.6832 - accuracy: 0.5494 - lr: 0.0020 - val_loss: 0.6549 - val_accuracy: 0.5619 - val_lr: 0.0020\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.6610 - accuracy: 0.6052 - lr: 0.0020 - val_loss: 0.6151 - val_accuracy: 0.6857 - val_lr: 0.0020\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.6449 - accuracy: 0.6221 - lr: 0.0020 - val_loss: 0.6154 - val_accuracy: 0.6619 - val_lr: 0.0020\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.6353 - accuracy: 0.6506 - lr: 0.0020 - val_loss: 0.6200 - val_accuracy: 0.6762 - val_lr: 0.0020\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.6265 - accuracy: 0.6584 - lr: 0.0020 - val_loss: 0.6785 - val_accuracy: 0.5524 - val_lr: 0.0020\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.6214 - accuracy: 0.6597 - lr: 0.0020 - val_loss: 0.6026 - val_accuracy: 0.6762 - val_lr: 0.0020\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.6604 - accuracy: 0.5948 - lr: 0.0020 - val_loss: 0.6503 - val_accuracy: 0.5476 - val_lr: 0.0020\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.6500 - accuracy: 0.6091 - lr: 0.0020 - val_loss: 0.6410 - val_accuracy: 0.6476 - val_lr: 0.0020\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6328 - accuracy: 0.6416 - lr: 0.0020 - val_loss: 0.5889 - val_accuracy: 0.6905 - val_lr: 0.0020\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5890 - accuracy: 0.6961 - lr: 0.0020 - val_loss: 0.5885 - val_accuracy: 0.6857 - val_lr: 0.0020\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5995 - accuracy: 0.6818 - lr: 0.0020 - val_loss: 0.5846 - val_accuracy: 0.6952 - val_lr: 0.0020\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5940 - accuracy: 0.6870 - lr: 0.0020 - val_loss: 0.5688 - val_accuracy: 0.6952 - val_lr: 0.0020\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5638 - accuracy: 0.6961 - lr: 0.0020 - val_loss: 0.6642 - val_accuracy: 0.6429 - val_lr: 0.0020\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.5493 - accuracy: 0.7247 - lr: 0.0020 - val_loss: 0.5702 - val_accuracy: 0.7143 - val_lr: 0.0020\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.5007 - accuracy: 0.7494 - lr: 0.0020 - val_loss: 1.3161 - val_accuracy: 0.5143 - val_lr: 0.0020\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.6091 - accuracy: 0.6779 - lr: 0.0020 - val_loss: 0.5449 - val_accuracy: 0.7429 - val_lr: 0.0020\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5284 - accuracy: 0.7377 - lr: 0.0020 - val_loss: 0.7290 - val_accuracy: 0.5857 - val_lr: 0.0019\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.5642 - accuracy: 0.7182 - lr: 0.0019 - val_loss: 0.5591 - val_accuracy: 0.7143 - val_lr: 0.0019\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.4946 - accuracy: 0.7636 - lr: 0.0019 - val_loss: 0.5009 - val_accuracy: 0.7714 - val_lr: 0.0019\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.5453 - accuracy: 0.7104 - lr: 0.0019 - val_loss: 0.5511 - val_accuracy: 0.7190 - val_lr: 0.0019\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4793 - accuracy: 0.7844 - lr: 0.0019 - val_loss: 0.7614 - val_accuracy: 0.6333 - val_lr: 0.0019\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4660 - accuracy: 0.7779 - lr: 0.0019 - val_loss: 0.5501 - val_accuracy: 0.7333 - val_lr: 0.0019\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4102 - accuracy: 0.8104 - lr: 0.0019 - val_loss: 0.6864 - val_accuracy: 0.6810 - val_lr: 0.0019\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4350 - accuracy: 0.7896 - lr: 0.0019 - val_loss: 0.6341 - val_accuracy: 0.7000 - val_lr: 0.0019\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3807 - accuracy: 0.8260 - lr: 0.0019 - val_loss: 0.6254 - val_accuracy: 0.7000 - val_lr: 0.0019\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3441 - accuracy: 0.8377 - lr: 0.0019 - val_loss: 0.5299 - val_accuracy: 0.7857 - val_lr: 0.0019\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.4216 - accuracy: 0.7844 - lr: 0.0019 - val_loss: 0.4925 - val_accuracy: 0.7952 - val_lr: 0.0019\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3434 - accuracy: 0.8442 - lr: 0.0019 - val_loss: 0.5351 - val_accuracy: 0.7381 - val_lr: 0.0019\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.4143 - accuracy: 0.8078 - lr: 0.0019 - val_loss: 0.5000 - val_accuracy: 0.7857 - val_lr: 0.0019\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.3169 - accuracy: 0.8675 - lr: 0.0019 - val_loss: 1.2457 - val_accuracy: 0.5667 - val_lr: 0.0019\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.4560 - accuracy: 0.7831 - lr: 0.0019 - val_loss: 0.4705 - val_accuracy: 0.7952 - val_lr: 0.0019\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3089 - accuracy: 0.8688 - lr: 0.0019 - val_loss: 0.5036 - val_accuracy: 0.7952 - val_lr: 0.0019\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3194 - accuracy: 0.8494 - lr: 0.0019 - val_loss: 0.5897 - val_accuracy: 0.7238 - val_lr: 0.0019\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.2829 - accuracy: 0.8792 - lr: 0.0019 - val_loss: 0.4864 - val_accuracy: 0.7810 - val_lr: 0.0019\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.2742 - accuracy: 0.8805 - lr: 0.0019 - val_loss: 0.5151 - val_accuracy: 0.7905 - val_lr: 0.0019\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.2937 - accuracy: 0.8740 - lr: 0.0019 - val_loss: 0.5791 - val_accuracy: 0.7571 - val_lr: 0.0019\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.2619 - accuracy: 0.8909 - lr: 0.0019 - val_loss: 0.6735 - val_accuracy: 0.7286 - val_lr: 0.0019\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.2649 - accuracy: 0.8818 - lr: 0.0019 - val_loss: 0.5703 - val_accuracy: 0.7667 - val_lr: 0.0019\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.2123 - accuracy: 0.9182 - lr: 0.0019 - val_loss: 0.5017 - val_accuracy: 0.8048 - val_lr: 0.0019\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.2069 - accuracy: 0.9221 - lr: 0.0019 - val_loss: 0.5029 - val_accuracy: 0.8095 - val_lr: 0.0019\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.3372 - accuracy: 0.8468 - lr: 0.0019 - val_loss: 0.5230 - val_accuracy: 0.7905 - val_lr: 0.0019\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.2405 - accuracy: 0.9000 - lr: 0.0019 - val_loss: 0.4822 - val_accuracy: 0.8095 - val_lr: 0.0019\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.2002 - accuracy: 0.9195 - lr: 0.0019 - val_loss: 0.7654 - val_accuracy: 0.7238 - val_lr: 0.0019\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 0.2004 - accuracy: 0.9273 - lr: 0.0019 - val_loss: 0.5898 - val_accuracy: 0.7571 - val_lr: 0.0019\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.2202 - accuracy: 0.8974 - lr: 0.0019 - val_loss: 0.5597 - val_accuracy: 0.7762 - val_lr: 0.0019\n",
      "Epoch 50/100\n",
      "22/25 [=========================>....] - ETA: 0s - loss: 0.1410 - accuracy: 0.9474 - lr: 0.0019Restoring model weights from the end of the best epoch: 35.\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.1368 - accuracy: 0.9494 - lr: 0.0019 - val_loss: 0.5767 - val_accuracy: 0.7952 - val_lr: 0.0019\n",
      "Epoch 50: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f36902af0d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    #layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\t#layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "\tlayers.AveragePooling2D(pool_size=(41, 5)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#POOL_SIZE = model.layers[-5].output.shape.as_list()[1:3]\n",
    "#print(POOL_SIZE)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3673 - accuracy: 0.8750 - lr: 0.0019"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4705 - accuracy: 0.7952 - lr: 0.0019\n",
      "{'loss': 0.47045403718948364, 'accuracy': 0.7952380776405334, 'lr': 0.0018773889169096947}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 16:40:35.591000: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-16 16:40:35.591031: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-16 16:40:35.591313: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-16 16:40:35.594793: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-16 16:40:35.594831: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-16 16:40:35.601840: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-16 16:40:35.692869: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-16 16:40:35.718675: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 127360 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_dataset(num_samples = x_train.shape[0]):\n",
    "    for x, y in train_dataset.take(num_samples):\n",
    "    \tyield [tf.cast(x, dtype=tf.float32)]\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_15_input:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 25, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index:  87\n",
      "tf.Tensor(\n",
      "[[[[ 89]\n",
      "   [-20]\n",
      "   [-47]\n",
      "   ...\n",
      "   [  4]\n",
      "   [ 21]\n",
      "   [-41]]\n",
      "\n",
      "  [[  2]\n",
      "   [ 44]\n",
      "   [  0]\n",
      "   ...\n",
      "   [-76]\n",
      "   [ 19]\n",
      "   [ -6]]\n",
      "\n",
      "  [[-10]\n",
      "   [ 41]\n",
      "   [  6]\n",
      "   ...\n",
      "   [-54]\n",
      "   [ 33]\n",
      "   [-12]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 47]\n",
      "   [ 19]\n",
      "   [-45]\n",
      "   ...\n",
      "   [ 17]\n",
      "   [-23]\n",
      "   [  6]]\n",
      "\n",
      "  [[ 21]\n",
      "   [  5]\n",
      "   [-34]\n",
      "   ...\n",
      "   [  5]\n",
      "   [ -9]\n",
      "   [-16]]\n",
      "\n",
      "  [[-29]\n",
      "   [ 22]\n",
      "   [ 30]\n",
      "   ...\n",
      "   [ 75]\n",
      "   [ -1]\n",
      "   [-14]]]], shape=(1, 349, 12, 1), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(x_validation))\n",
    "print(\"Random index: \", random_index)\n",
    "\n",
    "# Select the random data point using the random index\n",
    "random_data_point = tf.convert_to_tensor(tf.cast(x_validation[random_index], tf.int8))\n",
    "random_label = tf.convert_to_tensor(tf.cast(y_onehot_validation[random_index], tf.int8))\n",
    "# Convert the random data point from int8 to float32\n",
    "batch_size = 1\n",
    "\n",
    "random_data_point = tf.reshape(random_data_point, (batch_size, mfcc_size[0], mfcc_size[1], 1))\n",
    "print(random_data_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70 -70]]\n"
     ]
    }
   ],
   "source": [
    "# Set input data to the interpreter.\n",
    "interpreter.set_tensor(input_details[0]['index'], random_data_point)\n",
    "\n",
    "# Run inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output data from the interpreter.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "True label:  tf.Tensor([1 0], shape=(2,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "# Process output data.\n",
    "# For example, if your output is classification probabilities:\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True label: \", random_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simon/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
