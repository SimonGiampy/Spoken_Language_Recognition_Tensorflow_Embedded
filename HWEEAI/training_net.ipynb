{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  770\n",
      "validation files:  210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 17:13:13.118114: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 17:13:23.728396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 17:13:37.247469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:40.156362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:40.157067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  770\n",
      "dataset validation size:  210\n",
      "labels train size:  770\n",
      "labels validation size:  210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 17:13:53.958019: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:53.958743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:53.958926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:54.622830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:54.623673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:54.624533: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-15 17:13:54.625288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3494 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (770, 349, 12)\n",
      "Validation features shape: (210, 349, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1]))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1]))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.002,\n",
    "    decay_steps=1000,\n",
    "    end_learning_rate=1e-4,\n",
    "    power=0.5\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 345, 12, 64)       384       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 172, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 170, 12, 32)       6176      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 85, 12, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 83, 10, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 41, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 32)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17986 (70.26 KB)\n",
      "Trainable params: 17986 (70.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 25ms/step - loss: 0.8148 - accuracy: 0.5519 - lr: 0.0020 - val_loss: 0.6588 - val_accuracy: 0.6190 - val_lr: 0.0020\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6822 - accuracy: 0.5792 - lr: 0.0020 - val_loss: 0.6522 - val_accuracy: 0.6190 - val_lr: 0.0020\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6733 - accuracy: 0.5857 - lr: 0.0019 - val_loss: 0.6369 - val_accuracy: 0.6571 - val_lr: 0.0019\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6522 - accuracy: 0.6065 - lr: 0.0019 - val_loss: 0.6476 - val_accuracy: 0.6333 - val_lr: 0.0019\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6600 - accuracy: 0.5805 - lr: 0.0019 - val_loss: 0.6285 - val_accuracy: 0.6905 - val_lr: 0.0019\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6433 - accuracy: 0.6247 - lr: 0.0019 - val_loss: 0.6546 - val_accuracy: 0.6143 - val_lr: 0.0019\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6252 - accuracy: 0.6442 - lr: 0.0018 - val_loss: 0.6463 - val_accuracy: 0.6429 - val_lr: 0.0018\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.6614 - accuracy: 0.5922 - lr: 0.0018 - val_loss: 0.6116 - val_accuracy: 0.6810 - val_lr: 0.0018\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6416 - accuracy: 0.6455 - lr: 0.0018 - val_loss: 0.6012 - val_accuracy: 0.7000 - val_lr: 0.0018\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6078 - accuracy: 0.6753 - lr: 0.0018 - val_loss: 0.5886 - val_accuracy: 0.6905 - val_lr: 0.0017\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5918 - accuracy: 0.6779 - lr: 0.0017 - val_loss: 0.5781 - val_accuracy: 0.7238 - val_lr: 0.0017\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6306 - accuracy: 0.6390 - lr: 0.0017 - val_loss: 0.7015 - val_accuracy: 0.5095 - val_lr: 0.0017\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6184 - accuracy: 0.6571 - lr: 0.0017 - val_loss: 0.5947 - val_accuracy: 0.6810 - val_lr: 0.0017\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.6066 - accuracy: 0.6468 - lr: 0.0016 - val_loss: 0.5679 - val_accuracy: 0.7048 - val_lr: 0.0016\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5838 - accuracy: 0.6935 - lr: 0.0016 - val_loss: 0.5908 - val_accuracy: 0.6714 - val_lr: 0.0016\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5697 - accuracy: 0.6870 - lr: 0.0016 - val_loss: 0.7615 - val_accuracy: 0.5571 - val_lr: 0.0016\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5989 - accuracy: 0.6636 - lr: 0.0016 - val_loss: 0.6229 - val_accuracy: 0.6762 - val_lr: 0.0015\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5666 - accuracy: 0.7078 - lr: 0.0015 - val_loss: 0.6027 - val_accuracy: 0.7000 - val_lr: 0.0015\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5428 - accuracy: 0.7221 - lr: 0.0015 - val_loss: 0.5361 - val_accuracy: 0.7190 - val_lr: 0.0015\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5735 - accuracy: 0.6883 - lr: 0.0015 - val_loss: 0.5330 - val_accuracy: 0.7476 - val_lr: 0.0014\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4980 - accuracy: 0.7649 - lr: 0.0014 - val_loss: 0.4991 - val_accuracy: 0.7619 - val_lr: 0.0014\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.5727 - accuracy: 0.6948 - lr: 0.0014 - val_loss: 0.5243 - val_accuracy: 0.7333 - val_lr: 0.0014\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5790 - accuracy: 0.6675 - lr: 0.0014 - val_loss: 0.5458 - val_accuracy: 0.7286 - val_lr: 0.0013\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5505 - accuracy: 0.7013 - lr: 0.0013 - val_loss: 0.5801 - val_accuracy: 0.7143 - val_lr: 0.0013\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6024 - accuracy: 0.6727 - lr: 0.0013 - val_loss: 0.5571 - val_accuracy: 0.7286 - val_lr: 0.0013\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.4888 - accuracy: 0.7831 - lr: 0.0012 - val_loss: 0.5736 - val_accuracy: 0.7143 - val_lr: 0.0012\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4675 - accuracy: 0.7766 - lr: 0.0012 - val_loss: 0.4621 - val_accuracy: 0.7952 - val_lr: 0.0012\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4733 - accuracy: 0.7584 - lr: 0.0012 - val_loss: 0.4641 - val_accuracy: 0.7857 - val_lr: 0.0011\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4465 - accuracy: 0.7883 - lr: 0.0011 - val_loss: 0.5168 - val_accuracy: 0.7429 - val_lr: 0.0011\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5073 - accuracy: 0.7325 - lr: 0.0011 - val_loss: 0.5152 - val_accuracy: 0.7238 - val_lr: 0.0011\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4192 - accuracy: 0.8130 - lr: 0.0010 - val_loss: 0.6021 - val_accuracy: 0.7190 - val_lr: 0.0010\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.4741 - accuracy: 0.7649 - lr: 9.7676e-04 - val_loss: 0.6396 - val_accuracy: 0.6762 - val_lr: 9.5183e-04\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.5036 - accuracy: 0.7312 - lr: 9.2367e-04 - val_loss: 0.4755 - val_accuracy: 0.8095 - val_lr: 8.9709e-04\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.3883 - accuracy: 0.8364 - lr: 8.6690e-04 - val_loss: 0.4910 - val_accuracy: 0.7905 - val_lr: 8.3832e-04\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.3825 - accuracy: 0.8273 - lr: 8.0558e-04 - val_loss: 0.4723 - val_accuracy: 0.7571 - val_lr: 7.7443e-04\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.3653 - accuracy: 0.8416 - lr: 7.3837e-04 - val_loss: 0.4754 - val_accuracy: 0.7857 - val_lr: 7.0383e-04\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.3343 - accuracy: 0.8623 - lr: 6.6316e-04 - val_loss: 0.4526 - val_accuracy: 0.7905 - val_lr: 6.2379e-04\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.3261 - accuracy: 0.8662 - lr: 5.7611e-04 - val_loss: 0.4465 - val_accuracy: 0.8190 - val_lr: 5.2908e-04\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.3181 - accuracy: 0.8662 - lr: 4.6868e-04 - val_loss: 0.4533 - val_accuracy: 0.8286 - val_lr: 4.0637e-04\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.3020 - accuracy: 0.8792 - lr: 3.0581e-04 - val_loss: 0.4434 - val_accuracy: 0.8190 - val_lr: 1.6008e-04\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2953 - accuracy: 0.8792 - lr: 1.0000e-04 - val_loss: 0.4627 - val_accuracy: 0.7905 - val_lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2875 - accuracy: 0.8844 - lr: 1.0000e-04 - val_loss: 0.4517 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2836 - accuracy: 0.8909 - lr: 1.0000e-04 - val_loss: 0.4497 - val_accuracy: 0.8238 - val_lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2822 - accuracy: 0.8883 - lr: 1.0000e-04 - val_loss: 0.4568 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2862 - accuracy: 0.8818 - lr: 1.0000e-04 - val_loss: 0.4525 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2821 - accuracy: 0.8870 - lr: 1.0000e-04 - val_loss: 0.4503 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2930 - accuracy: 0.8779 - lr: 1.0000e-04 - val_loss: 0.4501 - val_accuracy: 0.8048 - val_lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.2773 - accuracy: 0.8922 - lr: 1.0000e-04 - val_loss: 0.4481 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2724 - accuracy: 0.8948 - lr: 1.0000e-04 - val_loss: 0.4989 - val_accuracy: 0.7762 - val_lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2909 - accuracy: 0.8740 - lr: 1.0000e-04 - val_loss: 0.4747 - val_accuracy: 0.8095 - val_lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2683 - accuracy: 0.8987 - lr: 1.0000e-04 - val_loss: 0.4526 - val_accuracy: 0.8190 - val_lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.2738 - accuracy: 0.8974 - lr: 1.0000e-04 - val_loss: 0.4876 - val_accuracy: 0.7857 - val_lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2687 - accuracy: 0.8896 - lr: 1.0000e-04 - val_loss: 0.4583 - val_accuracy: 0.8143 - val_lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.2641 - accuracy: 0.9013 - lr: 1.0000e-04 - val_loss: 0.4481 - val_accuracy: 0.8143 - val_lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.2792 - accuracy: 0.8906 - lr: 1.0000e-04Restoring model weights from the end of the best epoch: 40.\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 0.2786 - accuracy: 0.8909 - lr: 1.0000e-04 - val_loss: 0.4657 - val_accuracy: 0.8048 - val_lr: 1.0000e-04\n",
      "Epoch 55: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fcd7b9dd750>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    #layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\t#layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.GlobalAveragePooling2D(), \n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3124 - accuracy: 0.9062 - lr: 1.0000e-04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4434 - accuracy: 0.8190 - lr: 1.0000e-04\n",
      "{'loss': 0.4433830678462982, 'accuracy': 0.8190476298332214, 'lr': 9.999999747378752e-05}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 17:16:31.487649: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-15 17:16:31.487704: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-15 17:16:31.500385: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-15 17:16:31.502008: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-15 17:16:31.502021: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-15 17:16:31.505815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2023-08-15 17:16:31.508596: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-15 17:16:31.598135: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-15 17:16:31.616936: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 116558 microseconds.\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_3_input:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 24, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 20.]\n",
      "   [  9.]\n",
      "   [ 16.]\n",
      "   ...\n",
      "   [ 43.]\n",
      "   [-77.]\n",
      "   [-26.]]\n",
      "\n",
      "  [[ -2.]\n",
      "   [ 26.]\n",
      "   [ 36.]\n",
      "   ...\n",
      "   [ 32.]\n",
      "   [-78.]\n",
      "   [-56.]]\n",
      "\n",
      "  [[ 32.]\n",
      "   [  7.]\n",
      "   [ 10.]\n",
      "   ...\n",
      "   [ 51.]\n",
      "   [-23.]\n",
      "   [-83.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-46.]\n",
      "   [ 17.]\n",
      "   [ 69.]\n",
      "   ...\n",
      "   [-37.]\n",
      "   [-95.]\n",
      "   [-38.]]\n",
      "\n",
      "  [[-52.]\n",
      "   [-29.]\n",
      "   [ 58.]\n",
      "   ...\n",
      "   [ 13.]\n",
      "   [-29.]\n",
      "   [-27.]]\n",
      "\n",
      "  [[-52.]\n",
      "   [-18.]\n",
      "   [ 37.]\n",
      "   ...\n",
      "   [  0.]\n",
      "   [-39.]\n",
      "   [-16.]]]], shape=(1, 349, 12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(x_validation))\n",
    "\n",
    "# Select the random data point using the random index\n",
    "random_data_point = tf.convert_to_tensor(tf.cast(x_validation[random_index], dtype=tf.float32))\n",
    "random_label = tf.convert_to_tensor(y_onehot_validation[random_index])\n",
    "# Convert the random data point from int8 to float32\n",
    "batch_size = 1\n",
    "\n",
    "random_data_point = tf.reshape(random_data_point, (batch_size, mfcc_size[0], mfcc_size[1], 1))\n",
    "print(random_data_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9495107  0.05048933]]\n"
     ]
    }
   ],
   "source": [
    "# Set input data to the interpreter.\n",
    "interpreter.set_tensor(input_details[0]['index'], random_data_point)\n",
    "\n",
    "# Run inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output data from the interpreter.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "True label:  tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Process output data.\n",
    "# For example, if your output is classification probabilities:\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True label: \", random_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simon/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
