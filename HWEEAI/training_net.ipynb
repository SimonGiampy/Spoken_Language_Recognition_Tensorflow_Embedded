{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  770\n",
      "validation files:  210\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 16:15:37.330490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  770\n",
      "dataset validation size:  210\n",
      "labels train size:  770\n",
      "labels validation size:  210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 16:16:10.849134: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (770, 349, 12, 1)\n",
      "Validation features shape: (210, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12, 1)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 16:16:17.321011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 and shape [770,349,12,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-08-18 16:16:17.321802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [770,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.002,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=1e-4,\n",
    "    power=0.5\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 85, 12, 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      5\u001b[0m \u001b[39m# Create a basic CNN model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m      7\u001b[0m \tlayers\u001b[39m.\u001b[39;49mConv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m5\u001b[39;49m, \u001b[39m1\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49mmfcc_shape),\n\u001b[1;32m      8\u001b[0m \tlayers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m      9\u001b[0m     \u001b[39m#layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \t\u001b[39m#layers.MaxPooling2D(pool_size=(2, 1)),\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m1\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     12\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m     13\u001b[0m     layers\u001b[39m.\u001b[39;49mLSTM(\u001b[39m16\u001b[39;49m, unroll\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m     14\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     15\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m)),\n\u001b[1;32m     16\u001b[0m     \u001b[39m#layers.GlobalAveragePooling2D(),\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \tlayers\u001b[39m.\u001b[39;49mAveragePooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m41\u001b[39;49m, \u001b[39m5\u001b[39;49m)),\n\u001b[1;32m     18\u001b[0m \tlayers\u001b[39m.\u001b[39;49mFlatten(),\n\u001b[1;32m     19\u001b[0m \tlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m32\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     20\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m32\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     21\u001b[0m \tlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m2\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m# Two classes\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m ])\n\u001b[1;32m     24\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/envs/environmentAI/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/environmentAI/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/environmentAI/lib/python3.9/site-packages/keras/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_4\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 85, 12, 16)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=16, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    #layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\t#layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "\tlayers.AveragePooling2D(pool_size=(41, 5)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.9466 - accuracy: 0.4961 - lr: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 16:19:18.426761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [210,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 7s 176ms/step - loss: 0.9466 - accuracy: 0.4961 - lr: 0.0020 - val_loss: 0.7115 - val_accuracy: 0.5143 - val_lr: 0.0020\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 6s 232ms/step - loss: 0.7037 - accuracy: 0.5143 - lr: 0.0020 - val_loss: 0.6538 - val_accuracy: 0.5905 - val_lr: 0.0020\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 5s 190ms/step - loss: 0.7062 - accuracy: 0.5610 - lr: 0.0020 - val_loss: 0.6221 - val_accuracy: 0.6905 - val_lr: 0.0020\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 0.6555 - accuracy: 0.5974 - lr: 0.0020 - val_loss: 0.6416 - val_accuracy: 0.6095 - val_lr: 0.0020\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 5s 183ms/step - loss: 0.6565 - accuracy: 0.6013 - lr: 0.0020 - val_loss: 0.6597 - val_accuracy: 0.5857 - val_lr: 0.0020\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 5s 193ms/step - loss: 0.6676 - accuracy: 0.6039 - lr: 0.0020 - val_loss: 0.6447 - val_accuracy: 0.6048 - val_lr: 0.0020\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 6s 256ms/step - loss: 0.6474 - accuracy: 0.6312 - lr: 0.0020 - val_loss: 0.5884 - val_accuracy: 0.7000 - val_lr: 0.0020\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 6s 232ms/step - loss: 0.6318 - accuracy: 0.6416 - lr: 0.0020 - val_loss: 0.5697 - val_accuracy: 0.7333 - val_lr: 0.0020\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 5s 173ms/step - loss: 0.6290 - accuracy: 0.6584 - lr: 0.0020 - val_loss: 0.5749 - val_accuracy: 0.7095 - val_lr: 0.0020\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.6132 - accuracy: 0.6519 - lr: 0.0020 - val_loss: 0.5888 - val_accuracy: 0.6905 - val_lr: 0.0020\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 5s 203ms/step - loss: 0.6418 - accuracy: 0.6416 - lr: 0.0020 - val_loss: 0.5954 - val_accuracy: 0.6857 - val_lr: 0.0020\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 4s 147ms/step - loss: 0.6134 - accuracy: 0.6312 - lr: 0.0020 - val_loss: 0.5835 - val_accuracy: 0.6952 - val_lr: 0.0020\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.5894 - accuracy: 0.7000 - lr: 0.0020 - val_loss: 0.6536 - val_accuracy: 0.6190 - val_lr: 0.0020\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 6s 248ms/step - loss: 0.6021 - accuracy: 0.6831 - lr: 0.0020 - val_loss: 0.7621 - val_accuracy: 0.5571 - val_lr: 0.0020\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 5s 203ms/step - loss: 0.6594 - accuracy: 0.6312 - lr: 0.0020 - val_loss: 0.6039 - val_accuracy: 0.6667 - val_lr: 0.0020\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 7s 268ms/step - loss: 0.5906 - accuracy: 0.6883 - lr: 0.0020 - val_loss: 0.5216 - val_accuracy: 0.7381 - val_lr: 0.0020\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.5604 - accuracy: 0.7169 - lr: 0.0020 - val_loss: 0.5291 - val_accuracy: 0.7619 - val_lr: 0.0020\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 0.5383 - accuracy: 0.7351 - lr: 0.0020 - val_loss: 0.5064 - val_accuracy: 0.7571 - val_lr: 0.0020\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 5s 198ms/step - loss: 0.5420 - accuracy: 0.7286 - lr: 0.0020 - val_loss: 0.4910 - val_accuracy: 0.7762 - val_lr: 0.0020\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 5s 211ms/step - loss: 0.5141 - accuracy: 0.7649 - lr: 0.0020 - val_loss: 0.4893 - val_accuracy: 0.7714 - val_lr: 0.0020\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 5s 178ms/step - loss: 0.5114 - accuracy: 0.7468 - lr: 0.0020 - val_loss: 0.5142 - val_accuracy: 0.7333 - val_lr: 0.0019\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 4s 147ms/step - loss: 0.5001 - accuracy: 0.7442 - lr: 0.0019 - val_loss: 0.7218 - val_accuracy: 0.6286 - val_lr: 0.0019\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.5316 - accuracy: 0.7299 - lr: 0.0019 - val_loss: 0.4696 - val_accuracy: 0.7667 - val_lr: 0.0019\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 0.4998 - accuracy: 0.7675 - lr: 0.0019 - val_loss: 0.4842 - val_accuracy: 0.7714 - val_lr: 0.0019\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.5211 - accuracy: 0.7169 - lr: 0.0019 - val_loss: 0.4662 - val_accuracy: 0.7952 - val_lr: 0.0019\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 5s 190ms/step - loss: 0.4891 - accuracy: 0.7597 - lr: 0.0019 - val_loss: 0.5452 - val_accuracy: 0.7238 - val_lr: 0.0019\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 6s 232ms/step - loss: 0.4427 - accuracy: 0.7857 - lr: 0.0019 - val_loss: 0.4938 - val_accuracy: 0.7667 - val_lr: 0.0019\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 5s 190ms/step - loss: 0.4529 - accuracy: 0.7948 - lr: 0.0019 - val_loss: 0.4401 - val_accuracy: 0.8000 - val_lr: 0.0019\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 0.4408 - accuracy: 0.7935 - lr: 0.0019 - val_loss: 0.4505 - val_accuracy: 0.7857 - val_lr: 0.0019\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.4776 - accuracy: 0.7688 - lr: 0.0019 - val_loss: 0.4902 - val_accuracy: 0.7762 - val_lr: 0.0019\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 4s 157ms/step - loss: 0.4756 - accuracy: 0.7597 - lr: 0.0019 - val_loss: 0.4252 - val_accuracy: 0.8048 - val_lr: 0.0019\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 0.3943 - accuracy: 0.8351 - lr: 0.0019 - val_loss: 0.4526 - val_accuracy: 0.7857 - val_lr: 0.0019\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 0.3818 - accuracy: 0.8273 - lr: 0.0019 - val_loss: 0.5092 - val_accuracy: 0.7571 - val_lr: 0.0019\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 4s 158ms/step - loss: 0.3784 - accuracy: 0.8325 - lr: 0.0019 - val_loss: 0.4323 - val_accuracy: 0.7857 - val_lr: 0.0019\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 0.3888 - accuracy: 0.8169 - lr: 0.0019 - val_loss: 0.4615 - val_accuracy: 0.7810 - val_lr: 0.0019\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 0.3663 - accuracy: 0.8312 - lr: 0.0019 - val_loss: 0.4089 - val_accuracy: 0.8238 - val_lr: 0.0019\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 5s 187ms/step - loss: 0.3603 - accuracy: 0.8403 - lr: 0.0019 - val_loss: 0.3979 - val_accuracy: 0.8190 - val_lr: 0.0019\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 5s 182ms/step - loss: 0.3019 - accuracy: 0.8779 - lr: 0.0019 - val_loss: 0.4962 - val_accuracy: 0.7667 - val_lr: 0.0019\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 0.2897 - accuracy: 0.8675 - lr: 0.0019 - val_loss: 0.4084 - val_accuracy: 0.8238 - val_lr: 0.0019\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 0.3220 - accuracy: 0.8532 - lr: 0.0019 - val_loss: 0.3861 - val_accuracy: 0.8286 - val_lr: 0.0019\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.3090 - accuracy: 0.8753 - lr: 0.0019 - val_loss: 0.3602 - val_accuracy: 0.8381 - val_lr: 0.0019\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 0.2684 - accuracy: 0.8883 - lr: 0.0019 - val_loss: 0.4059 - val_accuracy: 0.8095 - val_lr: 0.0019\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 5s 201ms/step - loss: 0.2407 - accuracy: 0.8974 - lr: 0.0019 - val_loss: 0.9151 - val_accuracy: 0.6429 - val_lr: 0.0019\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 6s 250ms/step - loss: 0.3799 - accuracy: 0.8117 - lr: 0.0019 - val_loss: 0.4504 - val_accuracy: 0.7810 - val_lr: 0.0019\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 0.2411 - accuracy: 0.9000 - lr: 0.0019 - val_loss: 0.3773 - val_accuracy: 0.8333 - val_lr: 0.0019\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 0.2617 - accuracy: 0.8935 - lr: 0.0019 - val_loss: 0.3973 - val_accuracy: 0.8238 - val_lr: 0.0019\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 5s 193ms/step - loss: 0.2555 - accuracy: 0.8883 - lr: 0.0019 - val_loss: 0.3765 - val_accuracy: 0.8619 - val_lr: 0.0019\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 5s 187ms/step - loss: 0.2010 - accuracy: 0.9273 - lr: 0.0019 - val_loss: 0.6789 - val_accuracy: 0.7143 - val_lr: 0.0019\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.3677 - accuracy: 0.8221 - lr: 0.0019 - val_loss: 0.4472 - val_accuracy: 0.7905 - val_lr: 0.0019\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 4s 156ms/step - loss: 0.4165 - accuracy: 0.8104 - lr: 0.0019 - val_loss: 0.3583 - val_accuracy: 0.8524 - val_lr: 0.0019\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 0.3227 - accuracy: 0.8584 - lr: 0.0019 - val_loss: 0.3881 - val_accuracy: 0.8476 - val_lr: 0.0019\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 0.2314 - accuracy: 0.9130 - lr: 0.0019 - val_loss: 0.6278 - val_accuracy: 0.7190 - val_lr: 0.0019\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 0.3221 - accuracy: 0.8649 - lr: 0.0019 - val_loss: 0.3846 - val_accuracy: 0.8571 - val_lr: 0.0019\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 5s 179ms/step - loss: 0.2256 - accuracy: 0.9143 - lr: 0.0019 - val_loss: 0.3820 - val_accuracy: 0.8333 - val_lr: 0.0019\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 4s 155ms/step - loss: 0.1950 - accuracy: 0.9234 - lr: 0.0019 - val_loss: 0.3765 - val_accuracy: 0.8667 - val_lr: 0.0019\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 0.1737 - accuracy: 0.9351 - lr: 0.0019 - val_loss: 0.3725 - val_accuracy: 0.8714 - val_lr: 0.0019\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 5s 216ms/step - loss: 0.1625 - accuracy: 0.9403 - lr: 0.0019 - val_loss: 0.4540 - val_accuracy: 0.8048 - val_lr: 0.0019\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 0.1442 - accuracy: 0.9481 - lr: 0.0019 - val_loss: 0.4536 - val_accuracy: 0.8095 - val_lr: 0.0019\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 6s 223ms/step - loss: 0.1302 - accuracy: 0.9506 - lr: 0.0019 - val_loss: 0.6325 - val_accuracy: 0.7238 - val_lr: 0.0019\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 4s 159ms/step - loss: 0.2412 - accuracy: 0.8883 - lr: 0.0019 - val_loss: 0.3879 - val_accuracy: 0.8571 - val_lr: 0.0019\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 0.1769 - accuracy: 0.9299 - lr: 0.0019 - val_loss: 0.4423 - val_accuracy: 0.8381 - val_lr: 0.0018\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 0.1095 - accuracy: 0.9610 - lr: 0.0018 - val_loss: 0.4258 - val_accuracy: 0.8667 - val_lr: 0.0018\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 4s 154ms/step - loss: 0.1314 - accuracy: 0.9390 - lr: 0.0018 - val_loss: 0.7523 - val_accuracy: 0.7238 - val_lr: 0.0018\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 0.2020 - accuracy: 0.9091 - lr: 0.0018 - val_loss: 0.8724 - val_accuracy: 0.6762 - val_lr: 0.0018\n",
      "Epoch 65/100\n",
      "24/25 [===========================>..] - ETA: 0s - loss: 0.1710 - accuracy: 0.9245 - lr: 0.0018Restoring model weights from the end of the best epoch: 50.\n",
      "25/25 [==============================] - 3s 127ms/step - loss: 0.1713 - accuracy: 0.9247 - lr: 0.0018 - val_loss: 0.7901 - val_accuracy: 0.6810 - val_lr: 0.0018\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5d060e160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#POOL_SIZE = model.layers[-5].output.shape.as_list()[1:3]\n",
    "#print(POOL_SIZE)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/7 [=======>......................] - ETA: 0s - loss: 0.3813 - accuracy: 0.8438 - lr: 0.0018"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 65ms/step - loss: 0.3583 - accuracy: 0.8524 - lr: 0.0018\n",
      "{'loss': 0.3583161532878876, 'accuracy': 0.8523809313774109, 'lr': 0.001838889205828309}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/claudio/EmbeddedAI/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/claudio/EmbeddedAI/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 16:25:23.184923: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-18 16:25:23.185000: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-18 16:25:23.186751: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/claudio/EmbeddedAI/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-18 16:25:23.200432: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-08-18 16:25:23.200620: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /home/claudio/EmbeddedAI/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-18 16:25:23.202057: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-08-18 16:25:23.229325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-08-18 16:25:23.234964: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-18 16:25:23.424606: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/claudio/EmbeddedAI/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-18 16:25:23.460292: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 273581 microseconds.\n",
      "2023-08-18 16:25:23.567457: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-18 16:25:23.885339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [770,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-08-18 16:25:23.885750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [770,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_dataset(num_samples = x_train.shape[0]):\n",
    "    for x, y in train_dataset.take(num_samples):\n",
    "    \tyield [tf.cast(x, dtype=tf.float32)]\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 25, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index:  207\n",
      "tf.Tensor(\n",
      "[[[[-102]\n",
      "   [   7]\n",
      "   [ -14]\n",
      "   ...\n",
      "   [   0]\n",
      "   [  12]\n",
      "   [  45]]\n",
      "\n",
      "  [[ -12]\n",
      "   [ -70]\n",
      "   [  -2]\n",
      "   ...\n",
      "   [  28]\n",
      "   [  -6]\n",
      "   [ 121]]\n",
      "\n",
      "  [[ -19]\n",
      "   [ -55]\n",
      "   [  60]\n",
      "   ...\n",
      "   [ -23]\n",
      "   [  17]\n",
      "   [  32]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -93]\n",
      "   [   5]\n",
      "   [  -9]\n",
      "   ...\n",
      "   [ -12]\n",
      "   [  25]\n",
      "   [  34]]\n",
      "\n",
      "  [[ -16]\n",
      "   [  12]\n",
      "   [  -5]\n",
      "   ...\n",
      "   [ -23]\n",
      "   [  40]\n",
      "   [  55]]\n",
      "\n",
      "  [[  52]\n",
      "   [  54]\n",
      "   [ -95]\n",
      "   ...\n",
      "   [  77]\n",
      "   [  28]\n",
      "   [   4]]]], shape=(1, 349, 12, 1), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, len(x_validation))\n",
    "print(\"Random index: \", random_index)\n",
    "\n",
    "# Select the random data point using the random index\n",
    "random_data_point = tf.convert_to_tensor(tf.cast(x_validation[random_index], tf.int8))\n",
    "random_label = tf.convert_to_tensor(tf.cast(y_onehot_validation[random_index], tf.int8))\n",
    "# Convert the random data point from int8 to float32\n",
    "batch_size = 1\n",
    "\n",
    "random_data_point = tf.reshape(random_data_point, (batch_size, mfcc_size[0], mfcc_size[1], 1))\n",
    "print(random_data_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-120  120]]\n"
     ]
    }
   ],
   "source": [
    "# Set input data to the interpreter.\n",
    "interpreter.set_tensor(input_details[0]['index'], random_data_point)\n",
    "\n",
    "# Run inference.\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output data from the interpreter.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n",
      "True label:  tf.Tensor([0 1], shape=(2,), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "# Process output data.\n",
    "# For example, if your output is classification probabilities:\n",
    "predicted_class = np.argmax(output_data)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"True label: \", random_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
