{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  1672\n",
      "validation files:  456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  1672\n",
      "dataset validation size:  456\n",
      "labels train size:  1672\n",
      "labels validation size:  456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ita': 0, 'eng': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "print(class_to_index)\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (1672, 349, 12, 1)\n",
      "Validation features shape: (456, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 150\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12, 1)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.002,\n",
    "    decay_steps=1500,\n",
    "    end_learning_rate=1e-4,\n",
    "    power=0.5\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 345, 12, 16)       96        \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 172, 12, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 170, 12, 16)       784       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 85, 12, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 83, 10, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 41, 5, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 1, 1, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4866 (19.01 KB)\n",
      "Trainable params: 4866 (19.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=16, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    #layers.Conv2D(filters=64, kernel_size=(5, 1), activation='relu'),\n",
    "\t#layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 1), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "\tlayers.AveragePooling2D(pool_size=(41, 5)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 349, 12, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 349, 12, 16)       96        \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 174, 12, 16)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 174, 12, 16)       1296      \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 87, 12, 16)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 87, 12, 16)        2320      \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 43, 6, 16)         0         \n",
      "                                                                 \n",
      " avg_pool (AveragePooling2D  (None, 2, 3, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64)                6208      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 32)                2080      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12066 (47.13 KB)\n",
      "Trainable params: 12066 (47.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create new CNN model\n",
    "input_layer = tf.keras.layers.Input(shape=mfcc_shape, name='input_layer')\n",
    "conv1 = tf.keras.layers.Conv2D(16, (5, 1), activation='relu', padding='same', name='conv1')(input_layer)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2, 1), name='pool1')(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(16, (1, 5), activation='relu', padding='same', name='conv2')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2, 1), name='pool2')(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv3')(pool2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(conv3)\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(16, 2), name='avg_pool')(pool3)\n",
    "flatten = tf.keras.layers.Flatten(name='flatten')(avg_pool)\n",
    "dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1', kernel_regularizer='l2')(flatten)\n",
    "dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2', kernel_regularizer='l2')(dense1)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')(dense2)\n",
    "\n",
    "model_2 = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 3s 12ms/step - loss: 0.7451 - accuracy: 0.5401 - lr: 0.0018 - val_loss: 0.6813 - val_accuracy: 0.5504 - val_lr: 0.0018\n",
      "Epoch 2/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6872 - accuracy: 0.5365 - lr: 0.0018 - val_loss: 0.6878 - val_accuracy: 0.5285 - val_lr: 0.0018\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6771 - accuracy: 0.5628 - lr: 0.0018 - val_loss: 0.6761 - val_accuracy: 0.5943 - val_lr: 0.0018\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6852 - accuracy: 0.5622 - lr: 0.0018 - val_loss: 0.6623 - val_accuracy: 0.6623 - val_lr: 0.0018\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6787 - accuracy: 0.5562 - lr: 0.0018 - val_loss: 0.6643 - val_accuracy: 0.6053 - val_lr: 0.0018\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.6762 - accuracy: 0.5700 - lr: 0.0018 - val_loss: 0.6612 - val_accuracy: 0.6689 - val_lr: 0.0018\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.6190 - lr: 0.0018 - val_loss: 0.6211 - val_accuracy: 0.6996 - val_lr: 0.0018\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6608 - accuracy: 0.6035 - lr: 0.0018 - val_loss: 0.6300 - val_accuracy: 0.6974 - val_lr: 0.0018\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.6645 - lr: 0.0018 - val_loss: 0.6563 - val_accuracy: 0.5833 - val_lr: 0.0018\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.6441 - lr: 0.0018 - val_loss: 0.6098 - val_accuracy: 0.6820 - val_lr: 0.0018\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6164 - accuracy: 0.6621 - lr: 0.0018 - val_loss: 0.5713 - val_accuracy: 0.7215 - val_lr: 0.0018\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5911 - accuracy: 0.6800 - lr: 0.0018 - val_loss: 0.5693 - val_accuracy: 0.7281 - val_lr: 0.0018\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5575 - accuracy: 0.7207 - lr: 0.0018 - val_loss: 0.5389 - val_accuracy: 0.7171 - val_lr: 0.0018\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5906 - accuracy: 0.6675 - lr: 0.0018 - val_loss: 0.5691 - val_accuracy: 0.7434 - val_lr: 0.0018\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5427 - accuracy: 0.7207 - lr: 0.0018 - val_loss: 0.5443 - val_accuracy: 0.7083 - val_lr: 0.0018\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.7524 - lr: 0.0018 - val_loss: 0.5028 - val_accuracy: 0.7632 - val_lr: 0.0018\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5301 - accuracy: 0.7303 - lr: 0.0018 - val_loss: 0.5456 - val_accuracy: 0.7237 - val_lr: 0.0018\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5598 - accuracy: 0.7141 - lr: 0.0018 - val_loss: 0.5277 - val_accuracy: 0.7456 - val_lr: 0.0018\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5272 - accuracy: 0.7350 - lr: 0.0018 - val_loss: 0.5059 - val_accuracy: 0.7500 - val_lr: 0.0018\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4839 - accuracy: 0.7703 - lr: 0.0018 - val_loss: 0.4811 - val_accuracy: 0.7632 - val_lr: 0.0018\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5180 - accuracy: 0.7261 - lr: 0.0018 - val_loss: 0.6012 - val_accuracy: 0.6798 - val_lr: 0.0018\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4827 - accuracy: 0.7650 - lr: 0.0018 - val_loss: 0.4736 - val_accuracy: 0.7851 - val_lr: 0.0018\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4565 - accuracy: 0.7799 - lr: 0.0018 - val_loss: 0.5004 - val_accuracy: 0.7456 - val_lr: 0.0018\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4510 - accuracy: 0.7787 - lr: 0.0018 - val_loss: 0.4608 - val_accuracy: 0.7829 - val_lr: 0.0018\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4718 - accuracy: 0.7703 - lr: 0.0018 - val_loss: 0.4904 - val_accuracy: 0.7675 - val_lr: 0.0018\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8122 - lr: 0.0018 - val_loss: 0.5813 - val_accuracy: 0.7237 - val_lr: 0.0018\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.8074 - lr: 0.0018 - val_loss: 0.4702 - val_accuracy: 0.7741 - val_lr: 0.0018\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3992 - accuracy: 0.8074 - lr: 0.0018 - val_loss: 0.4408 - val_accuracy: 0.7807 - val_lr: 0.0018\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.8014 - lr: 0.0018 - val_loss: 0.4813 - val_accuracy: 0.7588 - val_lr: 0.0018\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4585 - accuracy: 0.7775 - lr: 0.0018 - val_loss: 0.4780 - val_accuracy: 0.7741 - val_lr: 0.0018\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.8080 - lr: 0.0018 - val_loss: 0.4273 - val_accuracy: 0.7939 - val_lr: 0.0018\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8403 - lr: 0.0018 - val_loss: 0.4906 - val_accuracy: 0.7675 - val_lr: 0.0018\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.7990 - lr: 0.0018 - val_loss: 0.6395 - val_accuracy: 0.6579 - val_lr: 0.0018\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.8074 - lr: 0.0018 - val_loss: 0.4564 - val_accuracy: 0.7851 - val_lr: 0.0018\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3811 - accuracy: 0.8140 - lr: 0.0018 - val_loss: 0.4348 - val_accuracy: 0.8048 - val_lr: 0.0018\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3703 - accuracy: 0.8403 - lr: 0.0018 - val_loss: 0.4214 - val_accuracy: 0.7982 - val_lr: 0.0018\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3506 - accuracy: 0.8391 - lr: 0.0018 - val_loss: 0.4098 - val_accuracy: 0.8092 - val_lr: 0.0018\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3323 - accuracy: 0.8529 - lr: 0.0018 - val_loss: 0.4810 - val_accuracy: 0.7763 - val_lr: 0.0018\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3386 - accuracy: 0.8529 - lr: 0.0018 - val_loss: 0.5408 - val_accuracy: 0.7544 - val_lr: 0.0018\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3403 - accuracy: 0.8481 - lr: 0.0018 - val_loss: 0.5147 - val_accuracy: 0.7588 - val_lr: 0.0018\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3600 - accuracy: 0.8367 - lr: 0.0018 - val_loss: 0.4395 - val_accuracy: 0.8070 - val_lr: 0.0018\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2832 - accuracy: 0.8858 - lr: 0.0018 - val_loss: 0.4442 - val_accuracy: 0.7982 - val_lr: 0.0018\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2698 - accuracy: 0.8900 - lr: 0.0018 - val_loss: 0.4182 - val_accuracy: 0.8092 - val_lr: 0.0018\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2653 - accuracy: 0.8864 - lr: 0.0018 - val_loss: 0.5043 - val_accuracy: 0.7697 - val_lr: 0.0018\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2623 - accuracy: 0.8822 - lr: 0.0018 - val_loss: 0.4027 - val_accuracy: 0.8202 - val_lr: 0.0018\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2752 - accuracy: 0.8834 - lr: 0.0018 - val_loss: 0.4304 - val_accuracy: 0.8070 - val_lr: 0.0018\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2874 - accuracy: 0.8726 - lr: 0.0018 - val_loss: 0.4863 - val_accuracy: 0.7654 - val_lr: 0.0018\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2462 - accuracy: 0.8971 - lr: 0.0018 - val_loss: 0.3945 - val_accuracy: 0.8311 - val_lr: 0.0018\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2363 - accuracy: 0.9007 - lr: 0.0018 - val_loss: 0.4052 - val_accuracy: 0.8224 - val_lr: 0.0018\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2721 - accuracy: 0.8840 - lr: 0.0018 - val_loss: 0.4150 - val_accuracy: 0.8224 - val_lr: 0.0018\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2331 - accuracy: 0.9001 - lr: 0.0018 - val_loss: 0.3818 - val_accuracy: 0.8355 - val_lr: 0.0018\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2038 - accuracy: 0.9228 - lr: 0.0018 - val_loss: 0.4767 - val_accuracy: 0.7982 - val_lr: 0.0018\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.9097 - lr: 0.0018 - val_loss: 0.3953 - val_accuracy: 0.8377 - val_lr: 0.0018\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2169 - accuracy: 0.9109 - lr: 0.0018 - val_loss: 0.4296 - val_accuracy: 0.8026 - val_lr: 0.0018\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.9061 - lr: 0.0018 - val_loss: 0.4808 - val_accuracy: 0.8092 - val_lr: 0.0018\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.2646 - accuracy: 0.8906 - lr: 0.0018 - val_loss: 0.3957 - val_accuracy: 0.8311 - val_lr: 0.0018\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2112 - accuracy: 0.9199 - lr: 0.0018 - val_loss: 0.4147 - val_accuracy: 0.8158 - val_lr: 0.0018\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2101 - accuracy: 0.9097 - lr: 0.0018 - val_loss: 0.4330 - val_accuracy: 0.8180 - val_lr: 0.0018\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.9031 - lr: 0.0018 - val_loss: 0.3805 - val_accuracy: 0.8289 - val_lr: 0.0018\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1652 - accuracy: 0.9354 - lr: 0.0018 - val_loss: 0.4159 - val_accuracy: 0.8114 - val_lr: 0.0018\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1602 - accuracy: 0.9396 - lr: 0.0018 - val_loss: 0.4864 - val_accuracy: 0.7917 - val_lr: 0.0018\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1562 - accuracy: 0.9426 - lr: 0.0018 - val_loss: 0.4780 - val_accuracy: 0.8224 - val_lr: 0.0018\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1849 - accuracy: 0.9288 - lr: 0.0018 - val_loss: 0.5192 - val_accuracy: 0.8048 - val_lr: 0.0018\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2523 - accuracy: 0.8995 - lr: 0.0018 - val_loss: 0.4570 - val_accuracy: 0.8136 - val_lr: 0.0018\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9019 - lr: 0.0018 - val_loss: 0.3946 - val_accuracy: 0.8377 - val_lr: 0.0018\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9366 - lr: 0.0018 - val_loss: 0.3921 - val_accuracy: 0.8421 - val_lr: 0.0018\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1320 - accuracy: 0.9516 - lr: 0.0018 - val_loss: 0.4799 - val_accuracy: 0.8114 - val_lr: 0.0018\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1515 - accuracy: 0.9378 - lr: 0.0018 - val_loss: 0.4118 - val_accuracy: 0.8377 - val_lr: 0.0018\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 0.9539 - lr: 0.0018 - val_loss: 0.4525 - val_accuracy: 0.8333 - val_lr: 0.0018\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1348 - accuracy: 0.9462 - lr: 0.0018 - val_loss: 0.4317 - val_accuracy: 0.8421 - val_lr: 0.0018\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.9384 - lr: 0.0018 - val_loss: 0.4691 - val_accuracy: 0.8246 - val_lr: 0.0018\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1055 - accuracy: 0.9629 - lr: 0.0018 - val_loss: 0.5152 - val_accuracy: 0.8004 - val_lr: 0.0018\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.9480 - lr: 0.0018 - val_loss: 0.5020 - val_accuracy: 0.8246 - val_lr: 0.0018\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1632 - accuracy: 0.9318 - lr: 0.0018 - val_loss: 0.4688 - val_accuracy: 0.8158 - val_lr: 0.0018\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1437 - accuracy: 0.9384 - lr: 0.0018 - val_loss: 0.8488 - val_accuracy: 0.7237 - val_lr: 0.0018\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2920 - accuracy: 0.8690 - lr: 0.0018 - val_loss: 0.4582 - val_accuracy: 0.8092 - val_lr: 0.0018\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1517 - accuracy: 0.9372 - lr: 0.0018 - val_loss: 0.4831 - val_accuracy: 0.8114 - val_lr: 0.0018\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1110 - accuracy: 0.9611 - lr: 0.0018 - val_loss: 0.4376 - val_accuracy: 0.8311 - val_lr: 0.0018\n",
      "Epoch 79/100\n",
      "50/53 [===========================>..] - ETA: 0s - loss: 0.0896 - accuracy: 0.9675 - lr: 0.0018Restoring model weights from the end of the best epoch: 59.\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0887 - accuracy: 0.9683 - lr: 0.0018 - val_loss: 0.4691 - val_accuracy: 0.8224 - val_lr: 0.0018\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdc8c117fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 3s 14ms/step - loss: 2.1836 - accuracy: 0.5096 - lr: 0.0020 - val_loss: 1.5022 - val_accuracy: 0.5526 - val_lr: 0.0020\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 1.3682 - accuracy: 0.5861 - lr: 0.0019 - val_loss: 1.2851 - val_accuracy: 0.6294 - val_lr: 0.0019\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 1.2218 - accuracy: 0.6489 - lr: 0.0019 - val_loss: 1.2730 - val_accuracy: 0.5746 - val_lr: 0.0019\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 1.1411 - accuracy: 0.6812 - lr: 0.0019 - val_loss: 1.2948 - val_accuracy: 0.5395 - val_lr: 0.0019\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 1.1071 - accuracy: 0.6740 - lr: 0.0018 - val_loss: 1.0888 - val_accuracy: 0.6798 - val_lr: 0.0018\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 1.0092 - accuracy: 0.7368 - lr: 0.0018 - val_loss: 1.0235 - val_accuracy: 0.7193 - val_lr: 0.0018\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.9199 - accuracy: 0.7811 - lr: 0.0018 - val_loss: 0.9628 - val_accuracy: 0.7368 - val_lr: 0.0017\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.8692 - accuracy: 0.7937 - lr: 0.0017 - val_loss: 0.9277 - val_accuracy: 0.7325 - val_lr: 0.0017\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.7642 - accuracy: 0.8337 - lr: 0.0017 - val_loss: 0.8730 - val_accuracy: 0.7763 - val_lr: 0.0017\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.7133 - accuracy: 0.8487 - lr: 0.0016 - val_loss: 0.8285 - val_accuracy: 0.7829 - val_lr: 0.0016\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.6485 - accuracy: 0.8720 - lr: 0.0016 - val_loss: 0.8305 - val_accuracy: 0.7895 - val_lr: 0.0016\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.6179 - accuracy: 0.8744 - lr: 0.0016 - val_loss: 0.7968 - val_accuracy: 0.7917 - val_lr: 0.0015\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.5752 - accuracy: 0.8923 - lr: 0.0015 - val_loss: 0.7266 - val_accuracy: 0.8136 - val_lr: 0.0015\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.5183 - accuracy: 0.9097 - lr: 0.0015 - val_loss: 0.6877 - val_accuracy: 0.8289 - val_lr: 0.0015\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.4619 - accuracy: 0.9306 - lr: 0.0014 - val_loss: 0.6972 - val_accuracy: 0.8355 - val_lr: 0.0014\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4370 - accuracy: 0.9384 - lr: 0.0014 - val_loss: 0.7372 - val_accuracy: 0.8092 - val_lr: 0.0014\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4242 - accuracy: 0.9366 - lr: 0.0013 - val_loss: 0.6368 - val_accuracy: 0.8399 - val_lr: 0.0013\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.3790 - accuracy: 0.9486 - lr: 0.0013 - val_loss: 0.6182 - val_accuracy: 0.8509 - val_lr: 0.0012\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.3577 - accuracy: 0.9533 - lr: 0.0012 - val_loss: 0.6126 - val_accuracy: 0.8553 - val_lr: 0.0012\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3299 - accuracy: 0.9683 - lr: 0.0012 - val_loss: 0.7932 - val_accuracy: 0.8070 - val_lr: 0.0011\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2993 - accuracy: 0.9755 - lr: 0.0011 - val_loss: 0.6290 - val_accuracy: 0.8531 - val_lr: 0.0011\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2732 - accuracy: 0.9809 - lr: 0.0010 - val_loss: 0.6209 - val_accuracy: 0.8618 - val_lr: 9.9790e-04\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.3301 - accuracy: 0.9468 - lr: 9.6069e-04 - val_loss: 0.7247 - val_accuracy: 0.8158 - val_lr: 9.2382e-04\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2566 - accuracy: 0.9868 - lr: 8.8304e-04 - val_loss: 0.6207 - val_accuracy: 0.8553 - val_lr: 8.4238e-04\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2287 - accuracy: 0.9970 - lr: 7.9674e-04 - val_loss: 0.6256 - val_accuracy: 0.8531 - val_lr: 7.5083e-04\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2173 - accuracy: 0.9994 - lr: 6.9803e-04 - val_loss: 0.6143 - val_accuracy: 0.8575 - val_lr: 6.4408e-04\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2092 - accuracy: 0.9994 - lr: 5.7912e-04 - val_loss: 0.6462 - val_accuracy: 0.8465 - val_lr: 5.1045e-04\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.2030 - accuracy: 1.0000 - lr: 4.1618e-04 - val_loss: 0.6328 - val_accuracy: 0.8618 - val_lr: 3.0227e-04\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1981 - accuracy: 1.0000 - lr: 1.4116e-04 - val_loss: 0.6383 - val_accuracy: 0.8662 - val_lr: 1.0000e-04\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1968 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6386 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6427 - val_accuracy: 0.8640 - val_lr: 1.0000e-04\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1948 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6416 - val_accuracy: 0.8662 - val_lr: 1.0000e-04\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1937 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6379 - val_accuracy: 0.8640 - val_lr: 1.0000e-04\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1930 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6384 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1918 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6409 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1907 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6390 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1897 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6397 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1887 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6428 - val_accuracy: 0.8662 - val_lr: 1.0000e-04\n",
      "Epoch 39/150\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 1.0000 - lr: 1.0000e-04Restoring model weights from the end of the best epoch: 19.\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1873 - accuracy: 1.0000 - lr: 1.0000e-04 - val_loss: 0.6388 - val_accuracy: 0.8684 - val_lr: 1.0000e-04\n",
      "Epoch 39: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdd2c6d9e10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model 2\n",
    "model_2.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8750 - lr: 0.0018"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8289 - lr: 0.0018\n",
      "{'loss': 0.38049131631851196, 'accuracy': 0.8289473652839661, 'lr': 0.0017641539452597499}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4134 - accuracy: 0.9688 - lr: 1.0000e-04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.8553 - lr: 1.0000e-04\n",
      "{'loss': 0.6125695109367371, 'accuracy': 0.8552631735801697, 'lr': 9.999997564591467e-05}\n"
     ]
    }
   ],
   "source": [
    "evaluation_2 = model_2.evaluate(val_dataset, batch_size=32)\n",
    "evaluation_2 = dict(zip(model_2.metrics_names, evaluation_2))\n",
    "print(evaluation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model_2.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 17:05:54.873209: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-19 17:05:54.873307: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-19 17:05:54.885952: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-19 17:05:54.889585: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-19 17:05:54.889618: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-19 17:05:54.902240: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-19 17:05:54.983588: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-19 17:05:55.004180: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 118242 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_dataset(num_samples = x_train.shape[0]):\n",
    "    for x, y in train_dataset.take(num_samples):\n",
    "    \tyield [tf.cast(x, dtype=tf.float32)]\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 25, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the TFLite model into a TFMicro model using the bash script below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simon/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate quantized model on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_model_evaluation(x_test, y_onehot_test):\n",
    "\n",
    "\t# convert test set into int8\n",
    "\tx_test_int8 = tf.convert_to_tensor(tf.cast(x_test, tf.int8))\n",
    "\ty_test_int8 = tf.convert_to_tensor(tf.cast(y_onehot_test, tf.int8))\n",
    "\t# Convert the random data point from int8 to float32\n",
    "\tbatch_size = len(x_test_int8)\n",
    "\n",
    "\teval_shape = (1, mfcc_size[0], mfcc_size[1], 1)\n",
    "\tprint(\"x shape = \", x_test_int8.shape)\n",
    "\tprint(\"y shape =\", y_test_int8.shape)\n",
    "\n",
    "\tpredictions = np.empty( (y_test_int8.shape) )\n",
    "\n",
    "\tfor i in range(batch_size):\n",
    "\t\t# Set input data to the interpreter.\n",
    "\t\tinterpreter.set_tensor(input_details[0]['index'], tf.reshape(x_test_int8[i], eval_shape) )\n",
    "\n",
    "\t\t# Run inference.\n",
    "\t\tinterpreter.invoke()\n",
    "\n",
    "\t\t# Get output data from the interpreter.\n",
    "\t\toutput_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "\t\t# get quantization parameters from output_details\n",
    "\t\toutput_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "\t\t# scale and zero point dequantization to get probabilities\n",
    "\t\toutput_probability = tf.math.softmax(output_data / output_scale + output_zero_point)\n",
    "\t\tpredictions[i] = output_probability.numpy()\n",
    "\n",
    "\taccuracy = np.sum( np.argmax(predictions, axis=1) == np.argmax(y_test_int8, axis=1) ) / batch_size\n",
    "\tprint(\"Accuracy in test set of quantized TFLite model: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape =  (456, 349, 12, 1)\n",
      "y shape = (456, 2)\n",
      "Accuracy in test set of quantized TFLite model: 0.8509\n"
     ]
    }
   ],
   "source": [
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_validation, y_onehot_test = y_onehot_validation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
