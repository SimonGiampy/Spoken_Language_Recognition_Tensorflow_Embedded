{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network to classify images of MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files:  1672\n",
      "validation files:  456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_train = [directory + \"/train/\" + f for f in os.listdir(directory + \"train/\") if f.endswith('.csv')]\n",
    "csv_files_validation = [directory + \"/validation/\" + f for f in os.listdir(directory + \"validation/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"training files: \", len(csv_files_train))\n",
    "print(\"validation files: \", len(csv_files_validation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test import of csv datasets into tensorflow datasets\n",
    "\n",
    "import every csv file as a single matrix with one label associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset train size:  1672\n",
      "dataset validation size:  456\n",
      "labels train size:  1672\n",
      "labels validation size:  456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_train = []\n",
    "dataset_validation = []\n",
    "labels_train = []\n",
    "labels_validation = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_train:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_train.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_train.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_validation:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_validation.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_validation.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset train size: \", len(dataset_train))\n",
    "print(\"dataset validation size: \", len(dataset_validation))\n",
    "print(\"labels train size: \", len(labels_train))\n",
    "print(\"labels validation size: \", len(labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_train[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ita': 0, 'eng': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "print(class_to_index)\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_train = np.array([class_to_index[label] for label in labels_train], dtype=np.int8)\n",
    "integer_labels_validation = np.array([class_to_index[label] for label in labels_validation], dtype=np.int8)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(integer_labels_train, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_validation = tf.keras.utils.to_categorical(integer_labels_validation, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (1672, 349, 12, 1)\n",
      "Validation features shape: (456, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = tf.reshape(dataset_train, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_validation = tf.reshape(dataset_validation, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"Training features shape:\", x_train.shape)\n",
    "print(\"Validation features shape:\", x_validation.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_onehot_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_validation, y_onehot_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 150\n",
    "mfcc_shape = (mfcc_size[0], mfcc_size[1], 1)\n",
    "\n",
    "# shuffle and batch\n",
    "train_dataset = train_dataset.shuffle(len(x_train))\n",
    "\n",
    "# apply batching to the datasets\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC batch input feature shape:  (32, 349, 12, 1)\n",
      "MFCC labels shape:  (32, 2)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "\tprint(\"MFCC batch input feature shape: \", image_batch.shape)\n",
    "\tprint(\"MFCC labels shape: \", labels_batch.shape)\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints learning rate during training\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "# learning rate scheduler with polynomial decay\n",
    "learning_rate_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.00012,\n",
    "    decay_steps=6000,\n",
    "    end_learning_rate=7e-5,\n",
    "    power=0.3\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_scheduler)\n",
    "lr_metric = get_lr_metric(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 345, 12, 16)       96        \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPooli  (None, 172, 12, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 172, 8, 16)        1296      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPooli  (None, 86, 8, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 82, 6, 16)         3856      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPooli  (None, 41, 3, 16)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " average_pooling2d_10 (Aver  (None, 1, 1, 16)          0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5282 (20.63 KB)\n",
      "Trainable params: 5282 (20.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Create a basic CNN model\n",
    "model = models.Sequential([\n",
    "\tlayers.Conv2D(filters=16, kernel_size=(5, 1), activation='relu', input_shape=mfcc_shape),\n",
    "\tlayers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(1, 5), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(5, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    #layers.GlobalAveragePooling2D(),\n",
    "\tlayers.AveragePooling2D(pool_size=(41, 3)),\n",
    "\tlayers.Flatten(),\n",
    "\t#layers.Dense(32, activation='relu'),\n",
    "    #layers.Dense(32, activation='relu'),\n",
    "\tlayers.Dense(2, activation='softmax')  # Two classes\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 349, 12, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 349, 12, 16)       96        \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 174, 12, 16)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 174, 12, 16)       1296      \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 87, 12, 16)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 87, 12, 16)        2320      \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 43, 6, 16)         0         \n",
      "                                                                 \n",
      " avg_pool (AveragePooling2D  (None, 2, 3, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 194       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3906 (15.26 KB)\n",
      "Trainable params: 3906 (15.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create new CNN model\n",
    "input_layer = tf.keras.layers.Input(shape=mfcc_shape, name='input_layer')\n",
    "conv1 = tf.keras.layers.Conv2D(16, (5, 1), activation='relu', padding='same', name='conv1')(input_layer)\n",
    "pool1 = tf.keras.layers.MaxPooling2D((2, 1), name='pool1')(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(16, (1, 5), activation='relu', padding='same', name='conv2')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D((2, 1), name='pool2')(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv3')(pool2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D((2, 2), name='pool3')(conv3)\n",
    "avg_pool = tf.keras.layers.AveragePooling2D(pool_size=(21, 2), name='avg_pool')(pool3)\n",
    "flatten = tf.keras.layers.Flatten(name='flatten')(avg_pool)\n",
    "# dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1', kernel_regularizer='l2')(flatten)\n",
    "# dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2', kernel_regularizer='l2')(dense1)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')(flatten)\n",
    "\n",
    "model_2 = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 3s 14ms/step - loss: 1.6900 - accuracy: 0.5263 - lr: 7.0000e-05 - val_loss: 0.7719 - val_accuracy: 0.5395 - val_lr: 7.0000e-05\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6877 - accuracy: 0.5981 - lr: 7.0000e-05 - val_loss: 0.7079 - val_accuracy: 0.5724 - val_lr: 7.0000e-05\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6949 - accuracy: 0.5969 - lr: 7.0000e-05 - val_loss: 0.7115 - val_accuracy: 0.5702 - val_lr: 7.0000e-05\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.6560 - accuracy: 0.6334 - lr: 7.0000e-05 - val_loss: 0.7152 - val_accuracy: 0.5724 - val_lr: 7.0000e-05\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.6507 - lr: 7.0000e-05 - val_loss: 0.6931 - val_accuracy: 0.5965 - val_lr: 7.0000e-05\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.5845 - accuracy: 0.6878 - lr: 7.0000e-05 - val_loss: 0.6155 - val_accuracy: 0.6754 - val_lr: 7.0000e-05\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6016 - accuracy: 0.6711 - lr: 7.0000e-05 - val_loss: 0.5996 - val_accuracy: 0.6930 - val_lr: 7.0000e-05\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5246 - accuracy: 0.7440 - lr: 7.0000e-05 - val_loss: 0.5732 - val_accuracy: 0.7171 - val_lr: 7.0000e-05\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.7685 - lr: 7.0000e-05 - val_loss: 0.5879 - val_accuracy: 0.7039 - val_lr: 7.0000e-05\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5136 - accuracy: 0.7428 - lr: 7.0000e-05 - val_loss: 0.5697 - val_accuracy: 0.7281 - val_lr: 7.0000e-05\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4639 - accuracy: 0.7877 - lr: 7.0000e-05 - val_loss: 0.7543 - val_accuracy: 0.5965 - val_lr: 7.0000e-05\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.7638 - lr: 7.0000e-05 - val_loss: 0.5180 - val_accuracy: 0.7346 - val_lr: 7.0000e-05\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4168 - accuracy: 0.8248 - lr: 7.0000e-05 - val_loss: 0.4909 - val_accuracy: 0.7610 - val_lr: 7.0000e-05\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8026 - lr: 7.0000e-05 - val_loss: 0.4845 - val_accuracy: 0.7478 - val_lr: 7.0000e-05\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8391 - lr: 7.0000e-05 - val_loss: 0.5138 - val_accuracy: 0.7873 - val_lr: 7.0000e-05\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8164 - lr: 7.0000e-05 - val_loss: 0.5348 - val_accuracy: 0.7061 - val_lr: 7.0000e-05\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8463 - lr: 7.0000e-05 - val_loss: 0.4468 - val_accuracy: 0.8180 - val_lr: 7.0000e-05\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.8505 - lr: 7.0000e-05 - val_loss: 0.4300 - val_accuracy: 0.8114 - val_lr: 7.0000e-05\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3476 - accuracy: 0.8559 - lr: 7.0000e-05 - val_loss: 0.4263 - val_accuracy: 0.8246 - val_lr: 7.0000e-05\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3334 - accuracy: 0.8642 - lr: 7.0000e-05 - val_loss: 0.4124 - val_accuracy: 0.8268 - val_lr: 7.0000e-05\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3150 - accuracy: 0.8744 - lr: 7.0000e-05 - val_loss: 0.4386 - val_accuracy: 0.7785 - val_lr: 7.0000e-05\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3012 - accuracy: 0.8792 - lr: 7.0000e-05 - val_loss: 0.4668 - val_accuracy: 0.7544 - val_lr: 7.0000e-05\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2994 - accuracy: 0.8744 - lr: 7.0000e-05 - val_loss: 0.4026 - val_accuracy: 0.8004 - val_lr: 7.0000e-05\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3061 - accuracy: 0.8678 - lr: 7.0000e-05 - val_loss: 0.3890 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2754 - accuracy: 0.8971 - lr: 7.0000e-05 - val_loss: 0.3913 - val_accuracy: 0.8289 - val_lr: 7.0000e-05\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2809 - accuracy: 0.8834 - lr: 7.0000e-05 - val_loss: 0.4023 - val_accuracy: 0.8114 - val_lr: 7.0000e-05\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2823 - accuracy: 0.8816 - lr: 7.0000e-05 - val_loss: 0.3868 - val_accuracy: 0.8333 - val_lr: 7.0000e-05\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2432 - accuracy: 0.8971 - lr: 7.0000e-05 - val_loss: 0.3723 - val_accuracy: 0.8443 - val_lr: 7.0000e-05\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.9043 - lr: 7.0000e-05 - val_loss: 0.7093 - val_accuracy: 0.6974 - val_lr: 7.0000e-05\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.3124 - accuracy: 0.8624 - lr: 7.0000e-05 - val_loss: 0.3814 - val_accuracy: 0.8224 - val_lr: 7.0000e-05\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2362 - accuracy: 0.9109 - lr: 7.0000e-05 - val_loss: 0.5542 - val_accuracy: 0.7325 - val_lr: 7.0000e-05\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2374 - accuracy: 0.9061 - lr: 7.0000e-05 - val_loss: 0.3835 - val_accuracy: 0.8114 - val_lr: 7.0000e-05\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1941 - accuracy: 0.9372 - lr: 7.0000e-05 - val_loss: 0.3616 - val_accuracy: 0.8553 - val_lr: 7.0000e-05\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1974 - accuracy: 0.9211 - lr: 7.0000e-05 - val_loss: 0.3650 - val_accuracy: 0.8640 - val_lr: 7.0000e-05\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2087 - accuracy: 0.9121 - lr: 7.0000e-05 - val_loss: 0.3745 - val_accuracy: 0.8509 - val_lr: 7.0000e-05\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1765 - accuracy: 0.9414 - lr: 7.0000e-05 - val_loss: 0.5780 - val_accuracy: 0.7412 - val_lr: 7.0000e-05\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.9157 - lr: 7.0000e-05 - val_loss: 0.3588 - val_accuracy: 0.8618 - val_lr: 7.0000e-05\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1772 - accuracy: 0.9366 - lr: 7.0000e-05 - val_loss: 0.4798 - val_accuracy: 0.7763 - val_lr: 7.0000e-05\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1761 - accuracy: 0.9378 - lr: 7.0000e-05 - val_loss: 0.3795 - val_accuracy: 0.8399 - val_lr: 7.0000e-05\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1510 - accuracy: 0.9426 - lr: 7.0000e-05 - val_loss: 0.4352 - val_accuracy: 0.7873 - val_lr: 7.0000e-05\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2908 - accuracy: 0.8666 - lr: 7.0000e-05 - val_loss: 0.3667 - val_accuracy: 0.8443 - val_lr: 7.0000e-05\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.9444 - lr: 7.0000e-05 - val_loss: 0.3820 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9492 - lr: 7.0000e-05 - val_loss: 0.3526 - val_accuracy: 0.8596 - val_lr: 7.0000e-05\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1545 - accuracy: 0.9450 - lr: 7.0000e-05 - val_loss: 0.3452 - val_accuracy: 0.8662 - val_lr: 7.0000e-05\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 0.9444 - lr: 7.0000e-05 - val_loss: 0.4496 - val_accuracy: 0.7895 - val_lr: 7.0000e-05\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 0.9432 - lr: 7.0000e-05 - val_loss: 0.3958 - val_accuracy: 0.8421 - val_lr: 7.0000e-05\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1316 - accuracy: 0.9557 - lr: 7.0000e-05 - val_loss: 0.4205 - val_accuracy: 0.8246 - val_lr: 7.0000e-05\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1477 - accuracy: 0.9426 - lr: 7.0000e-05 - val_loss: 0.3356 - val_accuracy: 0.8684 - val_lr: 7.0000e-05\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.9539 - lr: 7.0000e-05 - val_loss: 0.3455 - val_accuracy: 0.8728 - val_lr: 7.0000e-05\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1221 - accuracy: 0.9569 - lr: 7.0000e-05 - val_loss: 0.5382 - val_accuracy: 0.7785 - val_lr: 7.0000e-05\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1289 - accuracy: 0.9522 - lr: 7.0000e-05 - val_loss: 0.3696 - val_accuracy: 0.8509 - val_lr: 7.0000e-05\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1009 - accuracy: 0.9731 - lr: 7.0000e-05 - val_loss: 0.3247 - val_accuracy: 0.8816 - val_lr: 7.0000e-05\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9701 - lr: 7.0000e-05 - val_loss: 0.3566 - val_accuracy: 0.8575 - val_lr: 7.0000e-05\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0972 - accuracy: 0.9695 - lr: 7.0000e-05 - val_loss: 0.4651 - val_accuracy: 0.8092 - val_lr: 7.0000e-05\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9462 - lr: 7.0000e-05 - val_loss: 1.2361 - val_accuracy: 0.6667 - val_lr: 7.0000e-05\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1825 - accuracy: 0.9205 - lr: 7.0000e-05 - val_loss: 0.3411 - val_accuracy: 0.8706 - val_lr: 7.0000e-05\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0990 - accuracy: 0.9725 - lr: 7.0000e-05 - val_loss: 0.3803 - val_accuracy: 0.8421 - val_lr: 7.0000e-05\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9791 - lr: 7.0000e-05 - val_loss: 0.4498 - val_accuracy: 0.8333 - val_lr: 7.0000e-05\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0941 - accuracy: 0.9677 - lr: 7.0000e-05 - val_loss: 0.6645 - val_accuracy: 0.7741 - val_lr: 7.0000e-05\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1171 - accuracy: 0.9575 - lr: 7.0000e-05 - val_loss: 0.4024 - val_accuracy: 0.8509 - val_lr: 7.0000e-05\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0911 - accuracy: 0.9683 - lr: 7.0000e-05 - val_loss: 0.3719 - val_accuracy: 0.8509 - val_lr: 7.0000e-05\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9695 - lr: 7.0000e-05 - val_loss: 0.3349 - val_accuracy: 0.9013 - val_lr: 7.0000e-05\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1512 - accuracy: 0.9408 - lr: 7.0000e-05 - val_loss: 0.4296 - val_accuracy: 0.8487 - val_lr: 7.0000e-05\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9797 - lr: 7.0000e-05 - val_loss: 0.4427 - val_accuracy: 0.8158 - val_lr: 7.0000e-05\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1537 - accuracy: 0.9366 - lr: 7.0000e-05 - val_loss: 0.3566 - val_accuracy: 0.8750 - val_lr: 7.0000e-05\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0670 - accuracy: 0.9856 - lr: 7.0000e-05 - val_loss: 0.3629 - val_accuracy: 0.8684 - val_lr: 7.0000e-05\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9815 - lr: 7.0000e-05 - val_loss: 0.3593 - val_accuracy: 0.8684 - val_lr: 7.0000e-05\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0715 - accuracy: 0.9791 - lr: 7.0000e-05 - val_loss: 0.3919 - val_accuracy: 0.8531 - val_lr: 7.0000e-05\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 0.9749 - lr: 7.0000e-05 - val_loss: 0.3452 - val_accuracy: 0.8772 - val_lr: 7.0000e-05\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.2100 - accuracy: 0.8995 - lr: 7.0000e-05 - val_loss: 0.3319 - val_accuracy: 0.8904 - val_lr: 7.0000e-05\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9850 - lr: 7.0000e-05 - val_loss: 0.3535 - val_accuracy: 0.8838 - val_lr: 7.0000e-05\n",
      "Epoch 72/150\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9892 - lr: 7.0000e-05Restoring model weights from the end of the best epoch: 52.\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9892 - lr: 7.0000e-05 - val_loss: 0.3400 - val_accuracy: 0.8904 - val_lr: 7.0000e-05\n",
      "Epoch 72: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9784d18ed0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 3s 15ms/step - loss: 1.1877 - accuracy: 0.5413 - lr: 1.1993e-04 - val_loss: 1.0954 - val_accuracy: 0.5088 - val_lr: 1.1987e-04\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.9359 - accuracy: 0.5538 - lr: 1.1980e-04 - val_loss: 0.9732 - val_accuracy: 0.5000 - val_lr: 1.1974e-04\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.8437 - accuracy: 0.5628 - lr: 1.1967e-04 - val_loss: 0.9163 - val_accuracy: 0.5022 - val_lr: 1.1960e-04\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.7835 - accuracy: 0.5640 - lr: 1.1953e-04 - val_loss: 0.8387 - val_accuracy: 0.5044 - val_lr: 1.1947e-04\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.7414 - accuracy: 0.5760 - lr: 1.1940e-04 - val_loss: 0.8035 - val_accuracy: 0.5110 - val_lr: 1.1933e-04\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.7104 - accuracy: 0.5975 - lr: 1.1926e-04 - val_loss: 0.7773 - val_accuracy: 0.5241 - val_lr: 1.1919e-04\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6807 - accuracy: 0.6166 - lr: 1.1912e-04 - val_loss: 0.7679 - val_accuracy: 0.5285 - val_lr: 1.1905e-04\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.6632 - accuracy: 0.6184 - lr: 1.1898e-04 - val_loss: 0.7446 - val_accuracy: 0.5636 - val_lr: 1.1892e-04\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.6553 - accuracy: 0.6298 - lr: 1.1884e-04 - val_loss: 0.7681 - val_accuracy: 0.5614 - val_lr: 1.1878e-04\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6347 - accuracy: 0.6406 - lr: 1.1870e-04 - val_loss: 0.7179 - val_accuracy: 0.5811 - val_lr: 1.1863e-04\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.6141 - accuracy: 0.6627 - lr: 1.1856e-04 - val_loss: 0.7077 - val_accuracy: 0.5943 - val_lr: 1.1849e-04\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6103 - accuracy: 0.6693 - lr: 1.1842e-04 - val_loss: 0.7104 - val_accuracy: 0.5877 - val_lr: 1.1835e-04\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.6054 - accuracy: 0.6675 - lr: 1.1828e-04 - val_loss: 0.7203 - val_accuracy: 0.5943 - val_lr: 1.1821e-04\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5867 - accuracy: 0.6920 - lr: 1.1813e-04 - val_loss: 0.7275 - val_accuracy: 0.6118 - val_lr: 1.1806e-04\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5831 - accuracy: 0.6926 - lr: 1.1799e-04 - val_loss: 0.6713 - val_accuracy: 0.6294 - val_lr: 1.1792e-04\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5552 - accuracy: 0.7016 - lr: 1.1784e-04 - val_loss: 0.6706 - val_accuracy: 0.6338 - val_lr: 1.1777e-04\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5447 - accuracy: 0.7231 - lr: 1.1769e-04 - val_loss: 0.6653 - val_accuracy: 0.6316 - val_lr: 1.1762e-04\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5316 - accuracy: 0.7285 - lr: 1.1754e-04 - val_loss: 0.6536 - val_accuracy: 0.6447 - val_lr: 1.1747e-04\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5244 - accuracy: 0.7291 - lr: 1.1740e-04 - val_loss: 0.6493 - val_accuracy: 0.6513 - val_lr: 1.1732e-04\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.5187 - accuracy: 0.7434 - lr: 1.1724e-04 - val_loss: 0.6394 - val_accuracy: 0.6535 - val_lr: 1.1717e-04\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.5115 - accuracy: 0.7494 - lr: 1.1709e-04 - val_loss: 0.6430 - val_accuracy: 0.6623 - val_lr: 1.1702e-04\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.5060 - accuracy: 0.7470 - lr: 1.1694e-04 - val_loss: 0.6507 - val_accuracy: 0.6579 - val_lr: 1.1686e-04\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4909 - accuracy: 0.7614 - lr: 1.1679e-04 - val_loss: 0.6215 - val_accuracy: 0.6645 - val_lr: 1.1671e-04\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4845 - accuracy: 0.7679 - lr: 1.1663e-04 - val_loss: 0.6146 - val_accuracy: 0.6754 - val_lr: 1.1655e-04\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4811 - accuracy: 0.7644 - lr: 1.1647e-04 - val_loss: 0.6098 - val_accuracy: 0.6689 - val_lr: 1.1640e-04\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4718 - accuracy: 0.7799 - lr: 1.1632e-04 - val_loss: 0.6084 - val_accuracy: 0.6842 - val_lr: 1.1624e-04\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4665 - accuracy: 0.7829 - lr: 1.1616e-04 - val_loss: 0.6017 - val_accuracy: 0.6908 - val_lr: 1.1608e-04\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4617 - accuracy: 0.7739 - lr: 1.1600e-04 - val_loss: 0.5964 - val_accuracy: 0.6886 - val_lr: 1.1592e-04\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4544 - accuracy: 0.7859 - lr: 1.1584e-04 - val_loss: 0.5931 - val_accuracy: 0.6930 - val_lr: 1.1576e-04\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4489 - accuracy: 0.7877 - lr: 1.1567e-04 - val_loss: 0.5870 - val_accuracy: 0.6952 - val_lr: 1.1559e-04\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4358 - accuracy: 0.8008 - lr: 1.1551e-04 - val_loss: 0.5908 - val_accuracy: 0.7061 - val_lr: 1.1543e-04\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4327 - accuracy: 0.8020 - lr: 1.1534e-04 - val_loss: 0.5891 - val_accuracy: 0.7039 - val_lr: 1.1526e-04\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4263 - accuracy: 0.8098 - lr: 1.1517e-04 - val_loss: 0.5743 - val_accuracy: 0.7171 - val_lr: 1.1509e-04\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4225 - accuracy: 0.8092 - lr: 1.1501e-04 - val_loss: 0.5712 - val_accuracy: 0.7171 - val_lr: 1.1492e-04\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4126 - accuracy: 0.8164 - lr: 1.1484e-04 - val_loss: 0.5783 - val_accuracy: 0.7215 - val_lr: 1.1475e-04\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4258 - accuracy: 0.8008 - lr: 1.1466e-04 - val_loss: 0.6061 - val_accuracy: 0.7061 - val_lr: 1.1458e-04\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.4041 - accuracy: 0.8218 - lr: 1.1449e-04 - val_loss: 0.5783 - val_accuracy: 0.7127 - val_lr: 1.1441e-04\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3975 - accuracy: 0.8319 - lr: 1.1432e-04 - val_loss: 0.5534 - val_accuracy: 0.7259 - val_lr: 1.1423e-04\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3958 - accuracy: 0.8325 - lr: 1.1414e-04 - val_loss: 0.5470 - val_accuracy: 0.7412 - val_lr: 1.1405e-04\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3875 - accuracy: 0.8385 - lr: 1.1396e-04 - val_loss: 0.5432 - val_accuracy: 0.7456 - val_lr: 1.1387e-04\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3825 - accuracy: 0.8397 - lr: 1.1378e-04 - val_loss: 0.5348 - val_accuracy: 0.7500 - val_lr: 1.1369e-04\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.3784 - accuracy: 0.8511 - lr: 1.1360e-04 - val_loss: 0.5341 - val_accuracy: 0.7544 - val_lr: 1.1351e-04\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3738 - accuracy: 0.8463 - lr: 1.1342e-04 - val_loss: 0.5479 - val_accuracy: 0.7434 - val_lr: 1.1333e-04\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3709 - accuracy: 0.8409 - lr: 1.1323e-04 - val_loss: 0.5277 - val_accuracy: 0.7522 - val_lr: 1.1314e-04\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.3697 - accuracy: 0.8475 - lr: 1.1305e-04 - val_loss: 0.5222 - val_accuracy: 0.7522 - val_lr: 1.1295e-04\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.3652 - accuracy: 0.8523 - lr: 1.1286e-04 - val_loss: 0.5217 - val_accuracy: 0.7412 - val_lr: 1.1276e-04\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3553 - accuracy: 0.8517 - lr: 1.1267e-04 - val_loss: 0.5222 - val_accuracy: 0.7610 - val_lr: 1.1257e-04\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3471 - accuracy: 0.8612 - lr: 1.1247e-04 - val_loss: 0.5103 - val_accuracy: 0.7610 - val_lr: 1.1238e-04\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3458 - accuracy: 0.8642 - lr: 1.1228e-04 - val_loss: 0.5175 - val_accuracy: 0.7654 - val_lr: 1.1218e-04\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3423 - accuracy: 0.8648 - lr: 1.1208e-04 - val_loss: 0.5053 - val_accuracy: 0.7741 - val_lr: 1.1198e-04\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3341 - accuracy: 0.8678 - lr: 1.1188e-04 - val_loss: 0.5034 - val_accuracy: 0.7500 - val_lr: 1.1178e-04\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3270 - accuracy: 0.8756 - lr: 1.1168e-04 - val_loss: 0.4945 - val_accuracy: 0.7654 - val_lr: 1.1158e-04\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3239 - accuracy: 0.8780 - lr: 1.1148e-04 - val_loss: 0.4995 - val_accuracy: 0.7719 - val_lr: 1.1138e-04\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3260 - accuracy: 0.8780 - lr: 1.1127e-04 - val_loss: 0.4972 - val_accuracy: 0.7654 - val_lr: 1.1117e-04\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3187 - accuracy: 0.8816 - lr: 1.1106e-04 - val_loss: 0.4864 - val_accuracy: 0.7632 - val_lr: 1.1096e-04\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3121 - accuracy: 0.8828 - lr: 1.1085e-04 - val_loss: 0.4899 - val_accuracy: 0.7829 - val_lr: 1.1075e-04\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3085 - accuracy: 0.8882 - lr: 1.1064e-04 - val_loss: 0.4843 - val_accuracy: 0.7654 - val_lr: 1.1053e-04\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3096 - accuracy: 0.8852 - lr: 1.1042e-04 - val_loss: 0.5025 - val_accuracy: 0.7719 - val_lr: 1.1031e-04\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3045 - accuracy: 0.8911 - lr: 1.1020e-04 - val_loss: 0.4775 - val_accuracy: 0.7632 - val_lr: 1.1009e-04\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2988 - accuracy: 0.8923 - lr: 1.0998e-04 - val_loss: 0.4753 - val_accuracy: 0.7610 - val_lr: 1.0987e-04\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3085 - accuracy: 0.8750 - lr: 1.0975e-04 - val_loss: 0.4824 - val_accuracy: 0.7763 - val_lr: 1.0964e-04\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3010 - accuracy: 0.8834 - lr: 1.0953e-04 - val_loss: 0.4805 - val_accuracy: 0.7939 - val_lr: 1.0941e-04\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2918 - accuracy: 0.8888 - lr: 1.0930e-04 - val_loss: 0.4977 - val_accuracy: 0.7763 - val_lr: 1.0918e-04\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2813 - accuracy: 0.9049 - lr: 1.0906e-04 - val_loss: 0.4668 - val_accuracy: 0.7851 - val_lr: 1.0895e-04\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2886 - accuracy: 0.8900 - lr: 1.0882e-04 - val_loss: 0.4620 - val_accuracy: 0.7785 - val_lr: 1.0871e-04\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.2848 - accuracy: 0.8929 - lr: 1.0858e-04 - val_loss: 0.4696 - val_accuracy: 0.7895 - val_lr: 1.0846e-04\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2812 - accuracy: 0.8977 - lr: 1.0834e-04 - val_loss: 0.4723 - val_accuracy: 0.7807 - val_lr: 1.0822e-04\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2821 - accuracy: 0.8935 - lr: 1.0809e-04 - val_loss: 0.4813 - val_accuracy: 0.7807 - val_lr: 1.0797e-04\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2618 - accuracy: 0.9085 - lr: 1.0784e-04 - val_loss: 0.4591 - val_accuracy: 0.7895 - val_lr: 1.0771e-04\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2598 - accuracy: 0.9049 - lr: 1.0758e-04 - val_loss: 0.4557 - val_accuracy: 0.7939 - val_lr: 1.0746e-04\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2620 - accuracy: 0.9019 - lr: 1.0732e-04 - val_loss: 0.4493 - val_accuracy: 0.7829 - val_lr: 1.0719e-04\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2564 - accuracy: 0.9055 - lr: 1.0706e-04 - val_loss: 0.4489 - val_accuracy: 0.7895 - val_lr: 1.0693e-04\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2482 - accuracy: 0.9199 - lr: 1.0679e-04 - val_loss: 0.4474 - val_accuracy: 0.7873 - val_lr: 1.0666e-04\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2484 - accuracy: 0.9187 - lr: 1.0652e-04 - val_loss: 0.4523 - val_accuracy: 0.7917 - val_lr: 1.0638e-04\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2419 - accuracy: 0.9211 - lr: 1.0624e-04 - val_loss: 0.4684 - val_accuracy: 0.7917 - val_lr: 1.0610e-04\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2427 - accuracy: 0.9169 - lr: 1.0596e-04 - val_loss: 0.4420 - val_accuracy: 0.7917 - val_lr: 1.0581e-04\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2402 - accuracy: 0.9157 - lr: 1.0567e-04 - val_loss: 0.4421 - val_accuracy: 0.7939 - val_lr: 1.0552e-04\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2388 - accuracy: 0.9199 - lr: 1.0537e-04 - val_loss: 0.4645 - val_accuracy: 0.7895 - val_lr: 1.0523e-04\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2311 - accuracy: 0.9228 - lr: 1.0507e-04 - val_loss: 0.4495 - val_accuracy: 0.8004 - val_lr: 1.0492e-04\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2314 - accuracy: 0.9246 - lr: 1.0477e-04 - val_loss: 0.4506 - val_accuracy: 0.7982 - val_lr: 1.0461e-04\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2265 - accuracy: 0.9276 - lr: 1.0445e-04 - val_loss: 0.4427 - val_accuracy: 0.8048 - val_lr: 1.0430e-04\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2292 - accuracy: 0.9205 - lr: 1.0413e-04 - val_loss: 0.4442 - val_accuracy: 0.7982 - val_lr: 1.0398e-04\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2221 - accuracy: 0.9330 - lr: 1.0381e-04 - val_loss: 0.4483 - val_accuracy: 0.7982 - val_lr: 1.0365e-04\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2189 - accuracy: 0.9264 - lr: 1.0347e-04 - val_loss: 0.4332 - val_accuracy: 0.8092 - val_lr: 1.0331e-04\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2183 - accuracy: 0.9318 - lr: 1.0313e-04 - val_loss: 0.4344 - val_accuracy: 0.8026 - val_lr: 1.0296e-04\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2211 - accuracy: 0.9264 - lr: 1.0278e-04 - val_loss: 0.4681 - val_accuracy: 0.7982 - val_lr: 1.0261e-04\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2135 - accuracy: 0.9318 - lr: 1.0242e-04 - val_loss: 0.4293 - val_accuracy: 0.8070 - val_lr: 1.0224e-04\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2095 - accuracy: 0.9324 - lr: 1.0205e-04 - val_loss: 0.4310 - val_accuracy: 0.8070 - val_lr: 1.0187e-04\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2079 - accuracy: 0.9324 - lr: 1.0167e-04 - val_loss: 0.4448 - val_accuracy: 0.7982 - val_lr: 1.0148e-04\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2008 - accuracy: 0.9402 - lr: 1.0128e-04 - val_loss: 0.4307 - val_accuracy: 0.8136 - val_lr: 1.0109e-04\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.2037 - accuracy: 0.9372 - lr: 1.0088e-04 - val_loss: 0.4240 - val_accuracy: 0.8180 - val_lr: 1.0068e-04\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1960 - accuracy: 0.9426 - lr: 1.0047e-04 - val_loss: 0.4228 - val_accuracy: 0.8180 - val_lr: 1.0026e-04\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1990 - accuracy: 0.9408 - lr: 1.0004e-04 - val_loss: 0.4234 - val_accuracy: 0.8180 - val_lr: 9.9825e-05\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1965 - accuracy: 0.9432 - lr: 9.9597e-05 - val_loss: 0.4195 - val_accuracy: 0.8136 - val_lr: 9.9375e-05\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1906 - accuracy: 0.9408 - lr: 9.9139e-05 - val_loss: 0.4296 - val_accuracy: 0.8136 - val_lr: 9.8908e-05\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1903 - accuracy: 0.9396 - lr: 9.8662e-05 - val_loss: 0.4317 - val_accuracy: 0.8114 - val_lr: 9.8423e-05\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1849 - accuracy: 0.9474 - lr: 9.8167e-05 - val_loss: 0.4274 - val_accuracy: 0.8092 - val_lr: 9.7917e-05\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1858 - accuracy: 0.9432 - lr: 9.7650e-05 - val_loss: 0.4292 - val_accuracy: 0.8092 - val_lr: 9.7390e-05\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1840 - accuracy: 0.9414 - lr: 9.7110e-05 - val_loss: 0.4196 - val_accuracy: 0.8114 - val_lr: 9.6837e-05\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1793 - accuracy: 0.9510 - lr: 9.6544e-05 - val_loss: 0.4462 - val_accuracy: 0.8070 - val_lr: 9.6257e-05\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1803 - accuracy: 0.9462 - lr: 9.5948e-05 - val_loss: 0.4383 - val_accuracy: 0.8092 - val_lr: 9.5645e-05\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9510 - lr: 9.5318e-05 - val_loss: 0.4229 - val_accuracy: 0.8114 - val_lr: 9.4997e-05\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9486 - lr: 9.4649e-05 - val_loss: 0.4138 - val_accuracy: 0.8289 - val_lr: 9.4307e-05\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1769 - accuracy: 0.9432 - lr: 9.3935e-05 - val_loss: 0.4299 - val_accuracy: 0.8136 - val_lr: 9.3568e-05\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1715 - accuracy: 0.9528 - lr: 9.3167e-05 - val_loss: 0.4296 - val_accuracy: 0.8136 - val_lr: 9.2770e-05\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1675 - accuracy: 0.9504 - lr: 9.2335e-05 - val_loss: 0.4104 - val_accuracy: 0.8202 - val_lr: 9.1902e-05\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1687 - accuracy: 0.9533 - lr: 9.1423e-05 - val_loss: 0.4098 - val_accuracy: 0.8355 - val_lr: 9.0945e-05\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1625 - accuracy: 0.9533 - lr: 9.0410e-05 - val_loss: 0.4217 - val_accuracy: 0.8092 - val_lr: 8.9873e-05\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1659 - accuracy: 0.9522 - lr: 8.9264e-05 - val_loss: 0.4150 - val_accuracy: 0.8158 - val_lr: 8.8647e-05\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1595 - accuracy: 0.9569 - lr: 8.7930e-05 - val_loss: 0.4136 - val_accuracy: 0.8246 - val_lr: 8.7196e-05\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9545 - lr: 8.6312e-05 - val_loss: 0.4132 - val_accuracy: 0.8158 - val_lr: 8.5385e-05\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1581 - accuracy: 0.9528 - lr: 8.4188e-05 - val_loss: 0.4043 - val_accuracy: 0.8158 - val_lr: 8.2865e-05\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 1s 9ms/step - loss: 0.1595 - accuracy: 0.9575 - lr: 8.0738e-05 - val_loss: 0.4188 - val_accuracy: 0.8158 - val_lr: 7.7750e-05\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1564 - accuracy: 0.9593 - lr: 7.1257e-05 - val_loss: 0.4066 - val_accuracy: 0.8202 - val_lr: 7.0000e-05\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1517 - accuracy: 0.9593 - lr: 7.0000e-05 - val_loss: 0.4183 - val_accuracy: 0.8158 - val_lr: 7.0000e-05\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1499 - accuracy: 0.9629 - lr: 7.0000e-05 - val_loss: 0.4146 - val_accuracy: 0.8180 - val_lr: 7.0000e-05\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1497 - accuracy: 0.9563 - lr: 7.0000e-05 - val_loss: 0.4048 - val_accuracy: 0.8158 - val_lr: 7.0000e-05\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1489 - accuracy: 0.9623 - lr: 7.0000e-05 - val_loss: 0.4012 - val_accuracy: 0.8202 - val_lr: 7.0000e-05\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1491 - accuracy: 0.9611 - lr: 7.0000e-05 - val_loss: 0.4006 - val_accuracy: 0.8246 - val_lr: 7.0000e-05\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1495 - accuracy: 0.9599 - lr: 7.0000e-05 - val_loss: 0.4013 - val_accuracy: 0.8289 - val_lr: 7.0000e-05\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9635 - lr: 7.0000e-05 - val_loss: 0.3971 - val_accuracy: 0.8268 - val_lr: 7.0000e-05\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1450 - accuracy: 0.9629 - lr: 7.0000e-05 - val_loss: 0.4401 - val_accuracy: 0.8268 - val_lr: 7.0000e-05\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1476 - accuracy: 0.9599 - lr: 7.0000e-05 - val_loss: 0.4287 - val_accuracy: 0.8202 - val_lr: 7.0000e-05\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9635 - lr: 7.0000e-05 - val_loss: 0.3999 - val_accuracy: 0.8202 - val_lr: 7.0000e-05\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9617 - lr: 7.0000e-05 - val_loss: 0.3969 - val_accuracy: 0.8224 - val_lr: 7.0000e-05\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9629 - lr: 7.0000e-05 - val_loss: 0.3982 - val_accuracy: 0.8224 - val_lr: 7.0000e-05\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1430 - accuracy: 0.9599 - lr: 7.0000e-05 - val_loss: 0.3986 - val_accuracy: 0.8224 - val_lr: 7.0000e-05\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1341 - accuracy: 0.9713 - lr: 7.0000e-05 - val_loss: 0.3989 - val_accuracy: 0.8246 - val_lr: 7.0000e-05\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1354 - accuracy: 0.9641 - lr: 7.0000e-05 - val_loss: 0.3959 - val_accuracy: 0.8180 - val_lr: 7.0000e-05\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1321 - accuracy: 0.9677 - lr: 7.0000e-05 - val_loss: 0.3961 - val_accuracy: 0.8289 - val_lr: 7.0000e-05\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1335 - accuracy: 0.9677 - lr: 7.0000e-05 - val_loss: 0.3938 - val_accuracy: 0.8224 - val_lr: 7.0000e-05\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9683 - lr: 7.0000e-05 - val_loss: 0.3923 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1304 - accuracy: 0.9707 - lr: 7.0000e-05 - val_loss: 0.3964 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1341 - accuracy: 0.9683 - lr: 7.0000e-05 - val_loss: 0.4024 - val_accuracy: 0.8377 - val_lr: 7.0000e-05\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1279 - accuracy: 0.9689 - lr: 7.0000e-05 - val_loss: 0.3928 - val_accuracy: 0.8268 - val_lr: 7.0000e-05\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9665 - lr: 7.0000e-05 - val_loss: 0.4227 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1258 - accuracy: 0.9713 - lr: 7.0000e-05 - val_loss: 0.3947 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9677 - lr: 7.0000e-05 - val_loss: 0.3993 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9707 - lr: 7.0000e-05 - val_loss: 0.3886 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.9695 - lr: 7.0000e-05 - val_loss: 0.3882 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1204 - accuracy: 0.9737 - lr: 7.0000e-05 - val_loss: 0.3896 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1246 - accuracy: 0.9719 - lr: 7.0000e-05 - val_loss: 0.3904 - val_accuracy: 0.8289 - val_lr: 7.0000e-05\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1241 - accuracy: 0.9677 - lr: 7.0000e-05 - val_loss: 0.4058 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1247 - accuracy: 0.9689 - lr: 7.0000e-05 - val_loss: 0.3970 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1169 - accuracy: 0.9725 - lr: 7.0000e-05 - val_loss: 0.3850 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1171 - accuracy: 0.9785 - lr: 7.0000e-05 - val_loss: 0.3871 - val_accuracy: 0.8311 - val_lr: 7.0000e-05\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9731 - lr: 7.0000e-05 - val_loss: 0.3881 - val_accuracy: 0.8333 - val_lr: 7.0000e-05\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1144 - accuracy: 0.9791 - lr: 7.0000e-05 - val_loss: 0.3860 - val_accuracy: 0.8355 - val_lr: 7.0000e-05\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1168 - accuracy: 0.9731 - lr: 7.0000e-05 - val_loss: 0.3892 - val_accuracy: 0.8377 - val_lr: 7.0000e-05\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9755 - lr: 7.0000e-05 - val_loss: 0.3876 - val_accuracy: 0.8377 - val_lr: 7.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f97e0448ed0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model 2\n",
    "model_2.compile(optimizer = optimizer,\n",
    "\t\t\t  loss='categorical_crossentropy',  # Use 'categorical_crossentropy' for one-hot encoded labels\n",
    "\t\t\t  metrics=['accuracy', lr_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(x=train_dataset, epochs=num_epochs, callbacks=callbacks_list, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2476 - accuracy: 0.9062 - lr: 7.0000e-05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3247 - accuracy: 0.8816 - lr: 7.0000e-05\n",
      "{'loss': 0.32469314336776733, 'accuracy': 0.8815789222717285, 'lr': 6.999999459367245e-05}\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "\n",
    "evaluation = model.evaluate(val_dataset, batch_size=32)\n",
    "evaluation = dict(zip(model.metrics_names, evaluation))\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2020 - accuracy: 0.9062 - lr: 7.0000e-05"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8377 - lr: 7.0000e-05\n",
      "{'loss': 0.3876229524612427, 'accuracy': 0.8377193212509155, 'lr': 6.999999459367245e-05}\n"
     ]
    }
   ],
   "source": [
    "evaluation_2 = model_2.evaluate(val_dataset, batch_size=32)\n",
    "evaluation_2 = dict(zip(model_2.metrics_names, evaluation_2))\n",
    "print(evaluation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "model.save(filepath +  \"CNN_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conversion to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 12:45:30.146128: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-08-20 12:45:30.146174: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-08-20 12:45:30.146438: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-20 12:45:30.148166: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-08-20 12:45:30.148187: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-20 12:45:30.151703: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-08-20 12:45:30.229528: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /home/simon/Spoken_Language_Recognition_Tensorflow_Embedded/model_lite/CNN_model\n",
      "2023-08-20 12:45:30.256236: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 109800 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(filepath + \"CNN_model\")\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,  # enable TensorFlow Lite ops.\n",
    "    #tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def representative_dataset(num_samples = x_train.shape[0]):\n",
    "    for x, y in train_dataset.take(num_samples):\n",
    "    \tyield [tf.cast(x, dtype=tf.float32)]\n",
    "\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# write the converted model into a file\n",
    "with open(filepath + \"CNN_model.tflite\", 'wb') as f:\n",
    "\tf.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_27_input:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 19, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 349  12   1]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Assuming single input and output tensors.\n",
    "input_shape = input_details[0]['shape']\n",
    "output_shape = output_details[0]['shape']\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the TFLite model into a TFMicro model using the bash script below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/simon/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!xxd -i ./../model_lite/CNN_model.tflite > ./../model_lite/model_tflite_data.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate quantized model on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_model_evaluation(x_test, y_onehot_test):\n",
    "\n",
    "\t# convert test set into int8\n",
    "\tx_test_int8 = tf.convert_to_tensor(tf.cast(x_test, tf.int8))\n",
    "\ty_test_int8 = tf.convert_to_tensor(tf.cast(y_onehot_test, tf.int8))\n",
    "\t# Convert the random data point from int8 to float32\n",
    "\tbatch_size = len(x_test_int8)\n",
    "\n",
    "\teval_shape = (1, mfcc_size[0], mfcc_size[1], 1)\n",
    "\tprint(\"x shape = \", x_test_int8.shape)\n",
    "\tprint(\"y shape =\", y_test_int8.shape)\n",
    "\n",
    "\tpredictions = np.empty( (y_test_int8.shape) )\n",
    "\n",
    "\tfor i in range(batch_size):\n",
    "\t\t# Set input data to the interpreter.\n",
    "\t\tinterpreter.set_tensor(input_details[0]['index'], tf.reshape(x_test_int8[i], eval_shape) )\n",
    "\n",
    "\t\t# Run inference.\n",
    "\t\tinterpreter.invoke()\n",
    "\n",
    "\t\t# Get output data from the interpreter.\n",
    "\t\toutput_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "\t\t# get quantization parameters from output_details\n",
    "\t\toutput_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "\t\t# scale and zero point dequantization to get probabilities\n",
    "\t\toutput_probability = tf.math.softmax(output_data / output_scale + output_zero_point)\n",
    "\t\tpredictions[i] = output_probability.numpy()\n",
    "\n",
    "\tmse_loss = np.sqrt( np.sum( (y_test_int8 - predictions)**2 ) ) / batch_size\n",
    "\taccuracy = np.sum( np.argmax(predictions, axis=1) == np.argmax(y_test_int8, axis=1) ) / batch_size\n",
    "\tprint(\"Accuracy in test set of quantized TFLite model: {:.4f}\".format(accuracy))\n",
    "\tprint(\"MSE loss in test set of quantized TFLite model: {:.4f}\".format(mse_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape =  (456, 349, 12, 1)\n",
      "y shape = (456, 2)\n",
      "Accuracy in test set of quantized TFLite model: 0.8794\n",
      "MSE loss in test set of quantized TFLite model: 0.0229\n"
     ]
    }
   ],
   "source": [
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_validation, y_onehot_test = y_onehot_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_unheard_speakers files:  570\n",
      "test_known_speakers_noisy files:  480\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "directory = os.path.dirname(current_dir) + \"/datasets/\"\n",
    "csv_files_unheard = [directory + \"/test_unheard_speakers/\" + f for f in os.listdir(directory + \"test_unheard_speakers/\") if f.endswith('.csv')]\n",
    "csv_files_known = [directory + \"/test_known_speakers_noisy/\" + f for f in os.listdir(directory + \"test_known_speakers_noisy/\") if f.endswith('.csv')]\n",
    "\n",
    "print(\"test_unheard_speakers files: \", len(csv_files_unheard))\n",
    "print(\"test_known_speakers_noisy files: \", len(csv_files_known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if GPU is available and being used\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_test_known size:  480\n",
      "dataset_test_unheard size:  570\n",
      "labels_test_known size:  480\n",
      "labels_test_unheard size:  570\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create training and validation datasets\n",
    "dataset_test_known = []\n",
    "dataset_test_unheard = []\n",
    "labels_test_known = []\n",
    "labels_test_unheard = []\n",
    "\n",
    "# read csv files into lists\n",
    "# the label (language) is written in the file name\n",
    "\n",
    "for file in csv_files_known:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_test_known.append(data_array)\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    labels_test_known.append(file_name[5:8])\n",
    "\n",
    "for file in csv_files_unheard:\n",
    "    data_array = np.genfromtxt(file, delimiter=',', dtype=np.int8)\n",
    "    dataset_test_unheard.append(data_array)\n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "    labels_test_unheard.append(file_name[5:8])\n",
    "\n",
    "print(\"dataset_test_known size: \", len(dataset_test_known))\n",
    "print(\"dataset_test_unheard size: \", len(dataset_test_unheard))\n",
    "print(\"labels_test_known size: \", len(labels_test_known))\n",
    "print(\"labels_test_unheard size: \", len(labels_test_unheard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_size:  (349, 12)\n"
     ]
    }
   ],
   "source": [
    "# print size of one element of the dataset: feature size\n",
    "mfcc_size = dataset_test_known[0].shape\n",
    "print (\"mfcc_size: \", mfcc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ita': 0, 'eng': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = [\"ita\", \"eng\"]\n",
    "\n",
    "# Create a mapping from class names to integer labels\n",
    "class_to_index = {class_name: index for index, class_name in enumerate(classes)}\n",
    "print(class_to_index)\n",
    "\n",
    "# Convert labels to integer labels using the mapping\n",
    "integer_labels_test_unheard = np.array([class_to_index[label] for label in labels_test_unheard], dtype=np.int8)\n",
    "integer_labels_test_known = np.array([class_to_index[label] for label in labels_test_known], dtype=np.int8)\n",
    "\n",
    "y_onehot_test_unheard = tf.keras.utils.to_categorical(integer_labels_test_unheard, num_classes = len(classes)) # one hot encoding\n",
    "y_onehot_test_known = tf.keras.utils.to_categorical(integer_labels_test_known, num_classes = len(classes)) # one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unheard speakers features shape: (570, 349, 12, 1)\n",
      "known speakers with noisy audio features shape: (480, 349, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test_unheard = tf.reshape(dataset_test_unheard, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "x_test_known = tf.reshape(dataset_test_known, (-1, mfcc_size[0], mfcc_size[1], 1))\n",
    "\n",
    "print(\"unheard speakers features shape:\", x_test_unheard.shape)\n",
    "print(\"known speakers with noisy audio features shape:\", x_test_known.shape)\n",
    "\n",
    "# create tensorflow dataset from numpy arrays\n",
    "test_unheard_dataset = tf.data.Dataset.from_tensor_slices((x_test_unheard, y_onehot_test_unheard))\n",
    "test_known_dataset = tf.data.Dataset.from_tensor_slices((x_test_known, y_onehot_test_known))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([  1, 349,  12,   1], dtype=int32), 'shape_signature': array([ -1, 349,  12,   1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 25, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "filepath = parent_dir + \"/model_lite/\"\n",
    "\n",
    "model_path = filepath + \"CNN_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating accuracy of quantized model on test set: unheard speakers\n",
      "x shape =  (570, 349, 12, 1)\n",
      "y shape = (570, 2)\n",
      "Accuracy in test set of quantized TFLite model: 0.8246\n",
      "MSE loss in test set of quantized TFLite model: 0.0249\n",
      "\n",
      "evaluating accuracy of quantized model on test set: known speakers with noisy audio recordings\n",
      "x shape =  (480, 349, 12, 1)\n",
      "y shape = (480, 2)\n",
      "Accuracy in test set of quantized TFLite model: 0.7562\n",
      "MSE loss in test set of quantized TFLite model: 0.0318\n"
     ]
    }
   ],
   "source": [
    "print(\"evaluating accuracy of quantized model on test set: unheard speakers\")\n",
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_test_unheard, y_onehot_test = y_onehot_test_unheard)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"evaluating accuracy of quantized model on test set: known speakers with noisy audio recordings\")\n",
    "# evaluate validation set with post training quantized model\n",
    "tflite_model_evaluation(x_test = x_test_known, y_onehot_test = y_onehot_test_known)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
